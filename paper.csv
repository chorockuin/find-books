title,abstract,release,authors,publishers,url
RL for Consistency Models: Faster Reward Guided Text-to-Image Generation,"강화 학습 (RL)은 이미지 품질, 미학 및 지시 기능을 포착하는 보상을 직접 최적화함으로써 확산 모델로 가이드 이미지 생성을 개선했습니다.그러나 생성 된 생성 정책은 생성이 느리게 발생하는 확산 모델의 동일한 반복 샘플링 프로세스를 상속합니다.이러한 제한을 극복하기 위해 일관성 모델은 노이즈를 데이터에 직접 매핑하는 새로운 클래스의 생성 모델을 학습 할 것을 제안하여 하나의 샘플링 반복만큼 이미지를 생성 할 수있는 모델을 만들었습니다.이 작업에서 작업 별 보상을위한 텍스트-이미지 생성 모델을 최적화하고 빠른 교육 및 추론을 가능하게하기 위해 RL을 통해 미세 조정 일관성 모델을위한 프레임 워크를 제안합니다.RLCM (Renpercement Learning)이라고하는 우리의 프레임 워크는 일관성 모델의 반복 추론 프로세스를 RL 절차로 프레임합니다.RLCM은 텍스트-이미지 생성 기능에 대한 RL 미세 조정 확산 모델을 개선하고 샘플 품질에 대한 추론 시간 동안 계산을 거래합니다.실험적으로, 우리는 RLCM이 텍스트-이미지 일관성 모델을 이미지 압축성과 같은 프롬프트로 표현하기가 어렵고 미학적 품질과 같은 인간의 피드백에서 파생 된 목표에 적응할 수 있음을 보여줍니다.RLCM 트레인은 RL 미세 확산 모델과 비교하여 상당히 빠르게 열차를 만들고 보상 목표에서 측정 된 생성의 품질을 향상 시키며, 두 가지 추론 단계만으로 고품질 이미지를 생성하여 추론 절차를 가속화시킵니다.우리의 코드는 https url에서 사용할 수 있습니다",2024.03.25,Owen Oertell&&Jonathan D. Chang&&Yiyi Zhang&&Kianté Brantley&&Wen Sun,arxiv,https://arxiv.org/abs/2404.03673
Localizing Paragraph Memorization in Language Models,"우리는 언어 모델이 사용하는 무게와 메커니즘을 교육 데이터의 전체 단락을 암기하고 암송 할 수 있습니까?이 논문에서, 우리는 암기가 여러 계층과 모델 구성 요소에 걸쳐 퍼지는 동안 암기 된 단락의 그라디언트는 구별 가능한 공간 패턴을 가지며, 비-원형 예제의 그라디언트보다 낮은 모델 층에서 더 크다는 것을 보여준다.더욱이, 암기 된 예제는 고 그라디언트 가중치 만 미세 조정함으로써 배우지 못할 수있다.우리는 특히 단락 암기에 관여하는 것으로 보이는 저층 주의적 헤드를 현지화합니다.이 헤드는 주로 코퍼스 수준의 유니그램 분포에서 가장 빈번한 독특하고 희귀 한 토큰에 관심을 집중하고 있습니다.다음으로, 우리는 토큰을 교란시키고 디코딩의 원인 변화를 측정함으로써 접두사의 토큰을 가로 질러 국소화 된 암기가 어떻게 진행되는지 연구합니다.접두사 초기에 몇 가지 독특한 토큰은 종종 전체 연속을 손상시킬 수 있습니다.전반적으로, 암기 된 연속은 배우기가 더 어려울뿐만 아니라 무모하지 않은 것보다 손상되기에도 불구하고.",2024.03.28,Niklas Stoehr&&Mitchell Gordon&&Chiyuan Zhang&&Owen Lewis,arxiv,https://arxiv.org/abs/2403.19851
Jamba: A Hybrid Transformer-Mamba Language Model,"우리는 새로운 하이브리드 트랜스포머 -Mamba Mix-of-Experts (MOE) 아키텍처를 기반으로 새로운 기본 대형 언어 모델 인 Jamba를 제시합니다.구체적으로, Jamba는 변압기 및 Mamba 층의 블록을 인터리브하여 두 모델 패밀리의 이점을 누립니다.MOE는 이러한 레이어 중 일부에 추가되어 활성 매개 변수 사용을 유지하면서 모델 용량을 증가시킵니다.이 유연한 아키텍처는 리소스 및 객관적 특정 구성을 허용합니다.우리가 구현 한 특정 구성에서는 단일 80GB GPU에 적합한 강력한 모델로 끝납니다.Jamba는 대규모로 구축 된 바닐라 변압기에 비해 높은 처리량과 작은 메모리 풋 프린트를 제공하며 동시에 표준 언어 모델 벤치 마크 및 장기 텍스트 평가에서 최첨단 성능을 제공합니다.놀랍게도이 모델은 최대 256k 토큰 컨텍스트 길이에 대한 강력한 결과를 제공합니다.우리는 변압기와 Mamba 계층을 결합하는 방법과 전문가를 혼합하는 방법과 같은 다양한 건축 결정을 연구하고 일부는 대규모 모델링에서 중요하다는 것을 보여줍니다.우리는 또한 Jamba의 훈련과 평가가 공개 한이 아키텍처의 몇 가지 흥미로운 속성을 설명하고,이 새로운 건축에 대한 추가 탐색을 장려하기 위해 다양한 절제 실행에서 검문소를 공개 할 계획입니다.우리는 jamba 구현의 가중치를 허용 라이센스로 공개적으로 제공합니다.",2024.03.28,Opher Lieber&&Barak Lenz&&Hofit Bata&&Gal Cohen&&Jhonathan Osin&&Itay Dalmedigos&&Erez Safahi&&Shaked Meirom&&Yonatan Belinkov&&Shai Shalev-Shwartz&&Omri Abend&&Raz Alon&&Tomer Asida&&Amir Bergman&&Roman Glozman&&Michael Gokhman&&Avashalom Manevich&&Nir Ratner&&Noam Rozen&&Erez Shwartz&&Mor Zusman&&Yoav Shoham,arxiv,https://arxiv.org/abs/2403.19887
ReALM: Reference Resolution As Language Modeling,"참조 해상도는 중요한 문제로, 다른 종류의 맥락을 이해하고 성공적으로 처리하는 데 필수적인 문제입니다.이러한 컨텍스트에는 사용자 화면의 엔터티 또는 백그라운드에서 실행되는 것과 같은 비 변환 엔티티와 관련된 이전 회전 및 컨텍스트가 모두 포함됩니다.LLM은 다양한 작업에 대해 매우 강력한 것으로 나타 났지만, 참조 해상도, 특히 비 변환 엔티티의 경우 사용은 여전히 활용되지 않았습니다.이 논문은 전통적으로 도움이되지 않는 화면의 엔터티 형태를 포함하더라도 LLMS가 다양한 유형의 참조를 해결하기 위해 매우 효과적인 시스템을 만들기 위해 다양한 유형의 참조를 해결하는 데 사용되는 방법을 보여줍니다.텍스트 전용 양식으로 줄어 듭니다.우리는 다양한 유형의 참조에 걸쳐 유사한 기능을 갖춘 기존 시스템에 비해 크게 개선되었으며, 가장 작은 모델은 화면 참조에 대해 5% 이상의 절대 이득을 얻습니다.우리는 또한 GPT-3.5 및 GPT-4에 대한 벤치 마크를 벤치마킹하며, 가장 작은 모델은 GPT-4의 성능과 비교할 수있는 성능을 달성하고 더 큰 모델이 실질적으로 성능이 우수합니다.",2024.03.29,Joel Ruben Antony Moniz&&Soundarya Krishnan&&Melis Ozyildirim&&Prathamesh Saraf&&Halim Cagri Ates&&Yuan Zhang&&Hong Yu&&Nidhi Rajshree,arxiv,https://arxiv.org/abs/2403.20329
"Snap-it, Tap-it, Splat-it: Tactile-Informed 3D Gaussian Splatting for Reconstructing Challenging Surfaces","터치와 비전은 손을 잡고 세상을 이해하는 능력을 상호 향상시킵니다.연구 관점에서, 터치와 비전을 믹싱하는 문제는 미숙 한 것이며 흥미로운 도전을 제시합니다.이를 위해, 우리는 표면 재구성 및 새로운 뷰 합성을 달성하기 위해 다중 뷰 비전 데이터와 함께 터치 데이터 (로컬 깊이 맵)를 포함하는 새로운 접근법 인 촉각 정보 3DG를 제안합니다.우리의 방법은 3D 가우시안 프리미티브를 최적화하여 접촉 지점에서 물체의 형상을 정확하게 모델링합니다.터치 위치에서의 전송을 감소시키는 프레임 워크를 만들어 정제 된 표면 재구성을 달성하여 균일하게 부드러운 깊이 맵을 보장합니다.현대의 방법은 충실도 스펙 하이라이트로 재구성하는 경향이 있기 때문에 터치는 비 램버트 물체 (예 : 반짝 반응 또는 반사 표면)를 고려할 때 특히 유용합니다.시력과 촉각 감지를 결합하여 이전 방법보다 이미지가 적은 정확한 지오메트리 재구성을 달성합니다.우리는 광택과 반사 표면이있는 물체에 대한 평가를 수행하고 접근 방식의 효과를 보여 주며 재구성 품질이 크게 향상됩니다.",2024.03.29,Mauro Comi&&Alessio Tonioni&&Max Yang&&Jonathan Tremblay&&Valts Blukis&&Yijiong Lin&&Nathan F. Lepora&&Laurence Aitchison,arxiv,https://arxiv.org/abs/2403.20275
Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models,"이 논문은 해결할 수없는 문제 탐지 (UPD)라고 불리는 VLMS (Vision Language Models)에 대한 참신하고 중요한 도전을 소개합니다.UPD는 VQA (Visual Turysing Answering) 작업의 맥락에서 해결할 수없는 문제에 직면 할 때 VLM의 답변을 보류하는 능력을 조사합니다.Upd는 세 가지 별개의 설정을 포함합니다 : AAD (Assent Answer Detection), 호환되지 않는 답변 세트 감지 (IASD) 및 호환되지 않는 시각적 질문 감지 (IVQD)가 포함됩니다.Upd 문제를 깊이 조사하기 위해 광범위한 실험에 따르면 GPT-4V 및 LLAVA-NEXT-34B를 포함한 대부분의 VLM은 벤치 마크와 다양한 범위로 고생하여 개선을위한 중요한 공간을 강조합니다.UPD를 해결하기 위해 우리는 교육이없는 교육 기반 솔루션을 모두 탐색하여 효과와 한계에 대한 새로운 통찰력을 제공합니다.제안 된 UPD 설정 내에서 미래의 노력과 함께 우리의 통찰력이보다 실용적이고 신뢰할 수있는 VLM의 광범위한 이해와 개발을 향상시키기를 바랍니다.",2024.03.29,Atsuyuki Miyai&&Jingkang Yang&&Jingyang Zhang&&Yifei Ming&&Qing Yu&&Go Irie&&Yixuan Li&&Hai Li&&Ziwei Liu&&Kiyoharu Aizawa,arxiv,https://arxiv.org/abs/2403.20331
MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection,"딥 러닝의 최근 발전은 주로 데이터 의존성과 규모로 학습 능력으로 인해 변압기에 의존했습니다.그러나 이러한 아키텍처의주의 모듈은 입력 크기의 2 차 시간과 공간을 보여 주어 긴 시퀀스 모델링에 대한 확장 성을 제한합니다.이미지 및 다변량 시계열과 같은 다차원 데이터에 대한 효율적이고 효과적인 아키텍처 백본을 설계하려는 최근의 시도에도 불구하고 기존 모델은 데이터 독립적이거나 차원 내 및 차원 내 통신을 허용하지 못합니다.최근에, SSMS (State Space Models),보다 구체적으로 선택적인 상태 공간 모델은 효율적인 하드웨어 인식 구현을 통해 긴 시퀀스 모델링에 대한 유망한 잠재력을 보여 주었다.SSMS의 성공에 의해 동기 부여 된 우리는 선택적 토큰 및 채널 믹서라고하는 토큰 및 채널에서 이중 선택 메커니즘을 사용하는 데이터 의존성 가중치를 가진 새로운 아키텍처 인 Mambamixer를 제시합니다.Mambamixer는 가중 평균화 메커니즘을 사용하여 선택적 믹서를 연결하여 층이 초기 기능에 직접 액세스 할 수 있도록합니다.개념 증명으로서, 우리는 Mambamixer 블록을 기반으로 한 Vision Mambamixer (VIM2) 및 시계열 Mambamixer (TSM2) 아키텍처를 설계하고 다양한 비전 및 시계열 예측 작업에서 성능을 탐색합니다.우리의 결과는 토큰과 채널에서 선택적 혼합의 중요성을 강조합니다.ImageNet 분류, 객체 감지 및 시맨틱 세분화 작업에서 VIM2는 잘 확립 된 비전 모델과 SSM 기반 비전 모델보다 경쟁력있는 성능을 달성합니다.시계열 예측에서 TSM2는 최첨단 방법에 비해 뛰어난 성능을 달성하면서 계산 비용이 크게 향상되었습니다.이러한 결과는 변압기, 교차 채널주의 및 MLP가 시계열 예측에서 우수한 성능에 충분하지만 필요하지 않다는 것을 보여줍니다.",2024.03.29,Ali Behrouz&&Michele Santacatterina&&Ramin Zabih,arxiv,https://arxiv.org/abs/2403.19888
InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds,"NVS (Novel View Synthesis)는 3D 컴퓨터 비전에서 상당한 진전을 보였지만, 일반적으로 조밀 한 관점에서 카메라 내재 및 외계의 초기 추정이 필요합니다.이 사전 처리는 일반적으로 SFM (structure-from-motion) 파이프 라인을 통해 수행됩니다. 특히 정확한 재구성을 위해 일치하는 기능이 불충분 한 드문 뷰 시나리오에서 느리고 신뢰할 수없는 절차입니다.이 작업에서는 포인트 기반 표현의 강점 (예 : 3D 가우시안 스플릿, 3D-GS)을 엔드 투 엔드 빽빽한 스테레오 모델 (Dust3R)과 통합하여 구속되지 않은 설정에서 NVS에서 복잡하지만 해결되지 않은 문제를 해결합니다.포즈가없고 드문 뷰 도전을 포함합니다.우리의 프레임 워크 인 instantsplat는 3D-GS로 밀집된 스테레오 프라이어를 통합하여 Sparseview와 Pose-Free 이미지에서 대규모 장면의 3D 가우시안을 1 분 이내에 구축합니다.구체적으로, InstantSPlat은 사전 훈련 된 조밀 한 스테레오 파이프 라인에서 파생 된 전 세계적으로 정렬 된 3D 포인트 맵을 활용하여 모든 훈련보기에서 예비 장면 구조와 카메라 매개 변수를 신속하게 설정하는 CGI (Cuarse Geometric Anitiblization) 모듈로 구성됩니다.그 다음에는 3D 가우시안 속성과 초기화 된 포즈를 포즈 정규화로 최적화하는 빠른 3D-Gaussian 최적화 (F-3DGO) 모듈이 이어집니다.대규모 실외 탱크 및 사원 데이터 세트에서 수행 된 실험은 InstantSPlat이 SSIM (32%)을 크게 향상시키는 동시에 절대 궤적 오류 (ATE)를 80%감소 시킨다는 것을 보여줍니다.이들은 인스턴트 플랫을 포즈프리 및 드문 뷰 조건과 관련된 시나리오에 대한 실행 가능한 솔루션으로 설정합니다.프로젝트 페이지 :이 HTTP URL.",2024.03.29,Zhiwen Fan&&Wenyan Cong&&Kairun Wen&&Kevin Wang&&Jian Zhang&&Xinghao Ding&&Danfei Xu&&Boris Ivanovic&&Marco Pavone&&Georgios Pavlakos&&Zhangyang Wang&&Yue Wang,arxiv,https://arxiv.org/abs/2403.20309
DiJiang: Efficient Large Language Models through Compact Kernelization,"변압기의 계산 부하를 줄이기 위해 선형주의에 대한 연구는 상당한 추진력을 얻었습니다.그러나주의 메커니즘에 대한 개선 전략은 일반적으로 광범위한 재교육을 필요로하며, 이는 광범위한 매개 변수를 가진 대형 언어 모델에 비현실적입니다.이 논문에서, 우리는 미리 훈련 된 바닐라 변압기를 훈련 비용이 거의없는 선형 복잡성 모델로 변환 할 수있는 새로운 주파수 도메인 커널 화 접근법 인 Dijiang을 제시한다.샘플링을위한 가중 준 몬테 카를로 방법을 사용함으로써, 제안 된 접근법은 이론적으로 우수한 근사 효율을 제공합니다.훈련 계산 복잡성을 추가로 줄이기 위해, 우리의 커널은 DCT (Decrete Cosine Transform) 작업을 기반으로합니다.광범위한 실험은 제안 된 방법이 원래 변압기와 비슷한 성능을 달성하지만 훈련 비용이 크게 줄어들고 추론 속도가 훨씬 빨라짐을 보여줍니다.우리의 Dijiang-7b는 다양한 벤치 마크에서 LLAMA2-7B와 비슷한 성능을 달성하는 반면 약 1/50 교육 비용 만 필요합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.03.29,Hanting Chen&&Zhicheng Liu&&Xutao Wang&&Yuchuan Tian&&Yunhe Wang,arxiv,https://arxiv.org/abs/2403.19928
Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs,"LLM (Lange Language Model)은 지능적인 비서, 텍스트 요약, 번역 및 휴대 전화의 다중 유체와 같은 작업에 널리 사용됩니다.그러나 현재 기기 LLM 배포에 대한 현재 방법은 느린 추론 속도를 유지하여 사용자 경험이 좋지 않습니다.장치 GPU에 대한 고효율 LLM 배치를 촉진하기 위해, 우리는 4 가지 최적화 기술을 제안합니다. (a) 동적 모양 모델 추론을 지원하기위한 상징적 표현 기반 접근;(b) 추론 속도를 높이고 전화 지연을 줄이기위한 운영자 최적화 및 실행 우선 순위 설정;(c) Dequantization 오버 헤드를 감소시키기 위해 M0E4라고 불리는 FP4 양자화 방법;(d) LLM 추론 후 KV 캐시를 복사 할 필요가 없도록 하위 기관 기반 기술.또한 Qualcomm 및 MTK 프로세서와 호환되는 모바일 추론 엔진 인 Transformer-Lite에서 이러한 방법을 구현합니다.우리는 2B에서 14B 범위의 다양한 아키텍처 및 매개 변수를 갖춘 LLM을 사용하여 Transformer-Lite의 성능을 평가했습니다.구체적으로, 우리는 ChatGLM2 6B의 경우 121 토큰 및 14 토큰/s의 프리 필드 및 디코딩 속도, 작은 젬마 2B의 경우 각각 330 개의 토큰/s 및 30 토큰/s를 달성했습니다.CPU 기반 Fastllm 및 GPU 기반 MLC-LLM과 비교하여 엔진은 프리 필 속도를 위해 10 배 이상의 속도를 높이고 디코딩 속도의 2 ~ 3 배 속도를 달성합니다.",2024.03.29,Luchang Li&&Sheng Qian&&Jie Lu&&Lunxi Yuan&&Rui Wang&&Qin Xie,arxiv,https://arxiv.org/abs/2403.20041
Gecko: Versatile Text Embeddings Distilled from Large Language Models,"우리는 Gecko, 작고 다재다능한 텍스트 임베딩 모델을 제시합니다.Gecko는 대형 언어 모델 (LLM)의 지식을 리트리버로 증류시켜 핵심 아이디어를 활용하여 강력한 검색 성능을 달성합니다.우리의 2 단계 증류 프로세스는 LLM을 사용하여 다양한 합성 쌍 데이터를 생성하는 것으로 시작합니다.다음으로, 우리는 각 쿼리에 대한 후보 구절 세트를 검색하고 동일한 LLM을 사용하여 긍정적이고 단단한 음수 구절을 재사용하여 데이터 품질을 더욱 개선합니다.우리의 접근 방식의 효과는 Gecko의 작품에 의해 입증됩니다.MTEB (Massive Text Embedding Benchmark)에서 256 개의 임베딩 치수를 가진 Gecko는 768 개의 임베딩 크기로 기존의 모든 항목을 능가합니다.768 개의 임베딩 치수를 가진 Gecko는 평균 점수 66.31을 달성하여 7 배 큰 모델과 5 배 높은 차원 임베딩과 경쟁합니다.",2024.03.29,Jinhyuk Lee&&Zhuyun Dai&&Xiaoqi Ren&&Blair Chen&&Daniel Cer&&Jeremy R. Cole&&Kai Hui&&Michael Boratko&&Rajvi Kapadia&&Wen Ding&&Yi Luan&&Sai Meher Karthik Duddu&&Gustavo Hernandez Abrego&&Weiqiang Shi&&Nithi Gupta&&Aditya Kusupati&&Prateek Jain&&Siddhartha Reddy Jonnalagadda&&Ming-Wei Chang&&Iftekhar Naim,arxiv,https://arxiv.org/abs/2403.20327
LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model,"우리는 최근 출시 된 Gemma Family of Langer Language Models (LLM)와 함께 인기있는 LLAVA 프레임 워크를 사용하여 MMFM (Multimodal Foundation Models)을 훈련시킵니다.특히 관심있는 2B 매개 변수 Gemma 모델은 유능한 소규모 MMFM을 구성 할 수있는 기회를 제공합니다.이 공간의 다른 논문의 결과에 따라, 우리는 세 가지 디자인 기능을 절제하는 효과를 테스트하고, 커넥터 전망,보다 강력한 이미지 백본을 활용하며 언어 백본의 크기를 높입니다.Llava-Gemma라고 부르는 결과 모델은 다양한 평가에서 중간 정도의 성능을 보여 주지만 현재 비교적 크기의 SOTA 모델을 지나서 개선하지 못합니다.성능에 대한 면밀한 분석은 혼합 효과를 보여줍니다.프리 트레인을 건너 뛰는 것은 성능을 줄이는 경향이 있으며, 더 큰 비전 모델은 때때로 성능을 향상 시키며 언어 모델 크기를 증가시키는 것은 일관성이없는 영향을 미칩니다.우리는 Llava-Gemma 모델의 모델에 대한 교육 레시피, 코드 및 가중치를 공개적으로 출시합니다.",2024.03.29,Musashi Hinck&&Matthew L. Olson&&David Cobbley&&Shao-Yen Tseng&&Vasudev Lal,arxiv,https://arxiv.org/abs/2404.01331
Multi-Conditional Ranking with Large Language Models,"LLM (Large Language Model)을 사용하여 일련의 항목 세트를 순위에 올리는 것은 추천 및 검색 시스템에서 일반적인 접근 방식이되었습니다.일반적으로 이러한 시스템은 주어진 쿼리를 기반으로 단조로운 순서로 상당수의 문서를 주문하는 데 중점을 둡니다.그러나 실제 시나리오는 종종 다른 도전을 제시합니다. 비교적 작은 항목 세트를 평가하지만 다양한 다양하고 때로는 상충되는 조건에 따라.이 논문에서는 다양한 항목 유형 및 조건에서 다중 조건수 순위를 평가하기위한 벤치 마크 인 McRank를 소개하여 다중 조건수 순위의 작업을 정의하고 탐색합니다.McRank를 사용한 LLM에 대한 우리의 분석은 항목과 조건의 수와 복잡성이 증가함에 따라 성능이 크게 감소 함을 나타냅니다.이 제한을 극복하기 위해 조건을 추출하고 분류하는 것으로 구성된 새로운 분해 된 추론 방법을 제안한 다음 항목 (EXSIR)을 반복적으로 순위를 매 깁니다.우리의 광범위한 실험에 따르면이 분해 된 추론 방법은 LLM의 성능을 크게 향상시켜 기존 LLM에 비해 최대 12% 개선을 달성합니다.또한 다양한 조건 범주에서 LLMS 성능에 대한 자세한 분석을 제공하고 분해 단계의 효과를 조사합니다.또한, 우리는 방법을 사슬의 사슬 및 인코더 유형 순위 모델과 같은 기존 접근법과 비교하여 MCR 작업의 접근 방식의 우수성을 보여줍니다.우리는 데이터 세트와 코드를 출시했습니다.",2024.03.30,Pouya Pezeshkpour&&Estevam Hruschka,arxiv,https://arxiv.org/abs/2404.00211
Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order,"사전 예방 된 언어 모델은 여러 AI 애플리케이션을 뒷받침하지만 훈련에 대한 높은 계산 비용은 접근성을 제한합니다.Bloom 및 Starcoder와 같은 이니셔티브는 공동 커뮤니티 개발을위한 사전 간 모델에 대한 접근을 민주화하는 것을 목표로합니다.그러나 이러한 기존 모델은 제한된 다국어 기능, 지속적인 사전 여겨지는 치명적인 잊어 버린 반면, 처음부터의 사전 조정은 계산적으로 비싸고 AI 안전 및 개발 법칙을 준수하는 데 어려움을 겪고 있습니다.이 논문은 영어, 핀란드, 힌디어, 일본어, 베트남어 및 코드에 대해 훈련 된 15b 매개 변수 다국어 오픈 소스 모델 인 Aurora-M을 제시합니다.StarcoderPlus에서 지속적으로 4 억 3,500 억 명의 추가 토큰으로 사전에 사전에 Aurora-M은 총 훈련 토큰 수에서 2 조 토큰을 능가합니다.인간 검토 된 안전 지침에 미세 조정 된 최초의 오픈 소스 다국어 모델이므로 기존의 적색 팀 조정 고려 사항뿐만 아니라 안전에 대한 Biden-Harris 행정 명령에 명시된 특정 문제와도 개발을 조정합니다.인공 지능의 안전하고 신뢰할 수있는 개발 및 사용.Aurora-M은 다양한 작업과 언어에 걸쳐 엄격하게 평가되며, 특히 안전 평가에서 다국어 설정에서 대안을 잊어 버리고 성능이 우수한 대안에 대한 견고성을 보여줍니다.책임있는 오픈 소스 LLM 개발을 촉진하기 위해 Aurora-M과 그 변형은 HTTPS URL에서 출시됩니다.",2024.03.30,Taishi Nakamura&&Mayank Mishra&&Simone Tedeschi&&Yekun Chai&&Jason T Stillerman&&Felix Friedrich&&Prateek Yadav&&Tanmay Laud&&Vu Minh Chien&&Terry Yue Zhuo&&Diganta Misra&&Ben Bogin&&Xuan-Son Vu&&Marzena Karpinska&&Arnav Varma Dantuluri&&Wojciech Kusa&&Tommaso Furlanello&&Rio Yokota&&Niklas Muennighoff&&Suhas Pai&&Tosin Adewumi&&Veronika Laippala&&Xiaozhe Yao&&Adalberto Junior&&Alpay Ariyak&&Aleksandr Drozd&&Jordan Clive&&Kshitij Gupta&&Liangyu Chen&&Qi Sun&&Ken Tsui&&Noah Persaud&&Nour Fahmy&&Tianlong Chen&&Mohit Bansal&&Nicolo Monti&&Tai Dang&&Ziyang Luo&&Tien-Tung Bui&&Roberto Navigli&&Virendra Mehta&&Matthew Blumberg&&Victor May&&Huu Nguyen&&Sampo Pyysalo,arxiv,https://arxiv.org/abs/2404.00399
"MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview and Text","사용자 지정 조건에서 3D 장면의 생성은 3D 애플리케이션에서 생산 부담을 완화하기위한 유망한 길을 제공합니다.이전 연구는 제한된 제어 조건으로 인해 원하는 장면을 실현하기 위해 상당한 노력이 필요했습니다.부분 이미지, 상단보기에 표시된 레이아웃 정보 및 텍스트 프롬프트를 사용하여 멀티 모달 조건에서 3D 장면을 제어하고 생성하는 방법을 제안합니다.이러한 조건을 결합하여 3D 장면을 생성하려면 다음과 같은 중요한 어려움이 필요합니다. (1) 큰 데이터 세트 생성, (2) 복합 조건의 상호 작용에 대한 반사 및 (3) 레이아웃 조건의 도메인 의존성.3D 장면 생성 프로세스를 주어진 조건에서 2D 이미지 생성 및 2D 이미지에서 3D 장면 생성으로 분해합니다.2D 이미지 생성은 부분 이미지 및 레이아웃의 작은 인공 데이터 세트로 사전 각화 된 텍스트-이미지 모델을 미세 조정하여 달성되며, 3D 장면 생성은 레이아웃 조건 깊이 추정 및 NERF (Neural Radiance Fields)에 의해 달성되므로 피하십시오.큰 데이터 세트의 생성.360도 이미지를 사용하여 공간 정보의 공통적 표현을 사용하면 다중 모드 조건 상호 작용을 고려하고 레이아웃 제어의 도메인 의존성을 감소시킵니다.실험 결과는 질적으로 그리고 정량적으로 제안 된 방법이 다중 모드 조건에 따라 실내에서 실외에 이르기까지 다양한 영역에서 3D 장면을 생성 할 수 있음을 입증했습니다.",2024.03.30,Takayuki Hara&&Tatsuya Harada,arxiv,https://arxiv.org/abs/2404.00345
Noise-Aware Training of Layout-Aware Language Models,"시각적으로 풍부한 문서 (VRD)는 언어 적 신호와 함께 시각적 기능을 사용하여 정보를 전파합니다.문서에서 명명 된 엔티티를 식별하는 사용자 정의 추출기 훈련 텍스트 및 시각적 모드에 주석이 달린 대상 문서 유형의 많은 인스턴스가 필요합니다.이것은 엔터프라이즈 시나리오에서 고가의 병목 현상으로, 수천 가지의 다양한 문서 유형에 대한 커스텀 추출기를 확장 가능한 방식으로 훈련시키고 자합니다.대상 문서 유형의 표지되지 않은 인스턴스에 대한 추출기 모델을 사전 훈련하고, 인간으로 표지 된 인스턴스의 미세 조정 단계는 이러한 시나리오에서는 작동하지 않으므로 추출기에 할당 된 최대 허용 훈련 시간을 능가합니다.우리는이 논문에서 소음 인식 훈련 방법 또는 NAT를 제안 하여이 시나리오를 다룹니다.NAT는 값 비싼 인간의 표지 된 문서를 인수하는 대신 약하게 레이블이 지정된 문서를 사용하여 추출기를 확장 가능한 방식으로 훈련시킵니다.Nat은 시끄럽고 약하게 레이블이 지정된 샘플로 인해 모델의 품질의 저하를 피하기 위해 각 훈련 샘플의 신뢰를 추정하고 훈련 중 불확실성 측정으로 통합합니다.우리는 NAT를 사용하여 여러 최첨단 추출기 모델을 훈련시킵니다.공개적으로 이용 가능한 여러 및 사내 데이터 세트에 대한 실험에 따르면 NAT 훈련 모델은 성능이 강력 할뿐만 아니라 매크로 -F1 점수 측면에서 전송 학습 기준을 최대 6% 능가하는 것으로 나타났습니다.더 많은 레이블 효율적-비슷한 성능을 얻는 데 필요한 인간 효율의 양을 최대 73%감소시킵니다.",2024.03.30,Ritesh Sarkhel&&Xiaoqi Ren&&Lauro Beltrao Costa&&Guolong Su&&Vincent Perot&&Yanan Xie&&Emmanouil Koukoumidis&&Arnab Nandi,arxiv,https://arxiv.org/abs/2404.00488
ST-LLM: Large Language Models Are Effective Temporal Learners,"LLMS (Lange Language Models)는 텍스트 이해와 생성에서 인상적인 기능을 보여 주었으며 비디오 수준에서 인간 AI 상호 작용을 촉진하기 위해 비디오 LLM에 대한 연구 노력을 촉구했습니다.그러나 비디오 기반 대화 시스템에서 비디오를 효과적으로 인코딩하고 이해하는 방법은 여전히 해결되어야합니다.이 논문에서는 간단하지만 탐구되지 않은 질문을 조사합니다. 모든 공간-시간 토큰을 LLM에 공급하여 LLM에 비디오 시퀀스 모델링 작업을 위임 할 수 있습니까?놀랍게도이 간단한 접근 방식은 비디오 이해의 상당한 개선을 제공합니다.이를 바탕으로, 우리는 LLM 내부의 공간-시간 서열 모델링을 갖춘 효과적인 비디오 LLM 기준 인 ST-LLM을 제안합니다.또한 LLM 내에서 압축되지 않은 비디오 토큰이 도입 한 오버 헤드 및 안정성 문제를 해결하기 위해 맞춤형 훈련 목표를 가진 동적 마스킹 전략을 개발합니다.특히 긴 비디오의 경우 효율성과 효율성의 균형을 맞추기 위해 글로벌 로컬 입력 모듈을 설계했습니다.결과적으로, 우리는 효율성과 안정성을 유지하면서 능숙한 공간-시간 모델링을 위해 LLM을 활용합니다.광범위한 실험 결과는 우리의 방법의 효과를 증명합니다.보다 간결한 모델 및 교육 파이프 라인을 통해 ST-LLM은 Videochatgpt-Bench 및 MVBench에 대한 새로운 최첨단 결과를 설정합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.03.30,Ruyang Liu&&Chen Li&&Haoran Tang&&Yixiao Ge&&Ying Shan&&Ge Li,arxiv,https://arxiv.org/abs/2404.00308
WavLLM: Towards Robust and Adaptive Speech Large Language Model,"LLM (Large Language Models)의 최근 발전은 자연 언어 처리 분야에 혁명을 일으켜 멀티 모달 인식과 세대로의 범위를 점차 확대했습니다.그러나, 청취 기능을 LLM에 효과적으로 통합하면 특히 다양한 상황에 걸쳐 일반화하고 복잡한 청각 과제를 실행하는 것과 관련하여 상당한 어려움이 있습니다.이 작업에서 우리는 듀얼 인코더가있는 강력하고 적응 형 스피치 큰 언어 모델 인 Wavllm과 2 단계 커리큘럼 학습 방식으로 최적화 된 신속한 인식 LORA 무게 어댑터를 소개합니다.듀얼 인코더를 활용하여 우리는 다른 유형의 음성 정보를 분리하여 Whisper Encoder를 사용하여 음성의 의미 론적 내용을 처리하고 Wavlm 인코더를 사용하여 스피커의 고유 한 특성을 포착합니다.커리큘럼 학습 프레임 워크 내에서 WAVLLM은 먼저 혼합 기본 단일 작업을 최적화 한 다음 기본 작업의 조합과 같은보다 복잡한 작업에 대한 고급 멀티 태스킹 교육을 통해 기본 기능을 구축합니다.다양한 작업 및 지침에 대한 유연성과 준수를 향상시키기 위해 두 번째 고급 멀티 태스크 교육 단계에서 신속한 인식 LORA 중량 어댑터가 도입됩니다.우리는 ASR, ST, SV, ER과 같은 작업을 포함한 Universal Speech 벤치 마크에서 제안 된 모델을 검증하고 SQA를위한 Gaokao English Listencrehension 세트 및 Speech Chain-of Thought (COT) 평가 세트와 같은 전문 데이터 세트에도 적용합니다.실험에 따르면 제안 된 모델은 동일한 모델 크기의 다양한 음성 작업에서 최첨단 성능을 달성하여 COT 접근법을 사용하여 복잡한 작업을 실행하는 데 강력한 일반화 기능을 보여줍니다.또한, 우리의 모델은 전문 교육없이 Gaokao 작업을 성공적으로 완료합니다.코드, 모델, 오디오 및 Gaokao 평가 세트는 \ url {this http url}에서 액세스 할 수 있습니다.",2024.03.31,Shujie Hu&&Long Zhou&&Shujie Liu&&Sanyuan Chen&&Hongkun Hao&&Jing Pan&&Xunying Liu&&Jinyu Li&&Sunit Sivasankaran&&Linquan Liu&&Furu Wei,arxiv,https://arxiv.org/abs/2404.00656
FlexiDreamer: Single Image-to-3D Generation with FlexiCubes,"텍스트 프롬프트 또는 단일 이미지의 3D 컨텐츠 생성은 최근 품질과 속도에서 놀라운 진전을 보였습니다.지배적 인 패러다임 중 하나는 일관된 멀티 뷰 이미지를 생성 한 다음 희박한 뷰 재구성을 포함하는 것입니다.그러나, 대상 토폴로지에 접근하기 위해 메쉬 표현을 직접 변형시키는 과제로 인해, 대부분의 방법론은 희소 뷰 재구성 동안 암시 적 표현 (예 : NERF)을 배우고 후 처리 후 추출에 의해 대상 메쉬를 획득한다.암시 적 표현은 풍부한 3D 정보를 효과적으로 모델링 할 수 있지만, 교육은 일반적으로 긴 수렴 시간을 수반합니다.또한, 암시 적 필드로부터의 추출 후 작동은 바람직하지 않은 시각적 유물로 이어진다.이 논문에서 우리는 목표 메시를 엔드 투 엔드 방식으로 재구성하는 새로운 단일 이미지-3D 생성 프레임 워크 인 FlexIdReamer를 제안합니다.Flexicubes로 알려진 유연한 그라디언트 기반 추출을 활용하여, 우리의 방법은 사후 처리에 의해 가져온 결함을 피하고 대상 메쉬의 직접 획득을 용이하게한다.더욱이, 우리는 인코딩 레벨을 플렉시 큐브에서 암시 적 필드로 점진적으로 활성화하여 단계별 최적화를위한 기하학적 세부 사항을 캡처하는 데 도움이되는 다중 해석 해시 그리드 인코딩 체계를 통합합니다.특히 FlexIdReamer는 단일 NVIDIA A100 GPU에서 약 1 분 안에 단일 뷰 이미지에서 밀도가 높은 3D 구조를 복구하여 이전 방법론을 큰 마진으로 능가합니다.",2024.04.01,Ruowen Zhao&&Zhengyi Wang&&Yikai Wang&&Zihan Zhou&&Jun Zhu,arxiv,https://arxiv.org/abs/2404.00987
Streaming Dense Video Captioning,"비디오에서 일시적으로 현지화 된 캡션을 예측하는 고밀도 비디오 캡션을위한 이상적인 모델은 긴 입력 비디오를 처리하고 풍부하고 세부적인 텍스트 설명을 예측하며 전체 비디오를 처리하기 전에 출력을 생성 할 수 있어야합니다.그러나 현재 최첨단 모델은 고정 된 수의 다운 샘플링 프레임을 처리하고 전체 비디오를 본 후 하나의 전체 예측을 만듭니다.우리는 두 가지 새로운 구성 요소로 구성된 스트리밍 밀도가 높은 비디오 캡션 모델을 제안합니다. 첫째, 메모리가 고정 된 크기 일 때 자의적으로 긴 비디오를 처리 할 수있는 클러스터링 토큰을 기반으로 새로운 메모리 모듈을 제안합니다.둘째, 전체 비디오가 처리되기 전에 모델이 예측할 수있는 스트리밍 디코딩 알고리즘을 개발합니다.우리의 모델은 이러한 스트리밍 능력을 달성하고 ActivityNet, YouCook2 및 Vitt의 3 가지 조밀 한 비디오 캡션 벤치 마크에서 최신의 ART를 크게 향상시킵니다.우리의 코드는 https url에서 릴리스됩니다.",2024.04.01,Xingyi Zhou&&Anurag Arnab&&Shyamal Buch&&Shen Yan&&Austin Myers&&Xuehan Xiong&&Arsha Nagrani&&Cordelia Schmid,arxiv,https://arxiv.org/abs/2404.01297
CosmicMan: A Text-to-Image Foundation Model for Humans,"우리는 우연한 인간 이미지를 생성하는 데 특화된 텍스트-이미지 파운데이션 모델 인 Cosmicman을 제시합니다.인간을위한 열등한 품질 및 텍스트 이미지 오정렬의 딜레마에 갇힌 현재의 일반 목적 파운데이션 모델과는 달리, Cosmicman은 세심한 외관, 합리적인 구조 및 상세한 조밀 한 내용으로 정확한 텍스트 이미지 정렬을 가진 사진 현실적인 인간 이미지를 생성 할 수 있습니다.Cosmicman의 성공의 핵심에는 데이터 및 모델에 대한 새로운 반사와 관점이 있습니다. (1) 우리는 데이터 품질과 확장 가능한 데이터 생산 흐름이 훈련 된 모델의 최종 결과에 필수적이라는 것을 발견했습니다.따라서, 우리는 새로운 데이터 생산 패러다임을 제안하고, 다른 사람을 주석을 달아라.이를 바탕으로, 우리는 대규모 데이터 세트 인 Cosmicman-HQ 1.0을 구축했으며, 평균 해상도는 1488x1255의 평균 해상도로 6 백만 개의 고품질의 실제 인간 이미지를 구성했으며, 다양한 과립 화에서 1,1500 만 개의 속성에서 유래 한 정확한 텍스트 주석으로 첨부했습니다.(2) 우리는 인간을위한 전문화 된 텍스트-이미지 기초 모델이 실용적이어야한다고 주장합니다. 고품질의 인간 이미지를 생성하는 데 효과적이지만 다운 스트리밍 작업에 쉽게 통합 할 수 있습니다.따라서, 우리는 고밀도 텍스트 설명과 이미지 픽셀 사이의 관계를 분해 방식으로 모델링하고 분해 된 분해 중심 반복 (대담한) 훈련 프레임 워크를 제시 할 것을 제안합니다.기존 텍스트-이미지 확산 모델의 교차 내역 기능을 원활하게 분해하고 추가 모듈을 추가하지 않고 주목을 다시 시작합니다.대담한 것을 통해, 우리는 연속 텍스트 공간을 인체 구조와 일치하는 여러 기본 그룹으로 명시 적으로 분산시키는 것이 바람에서 오정렬 문제를 해결하는 열쇠임을 보여줍니다.",2024.04.01,Shikai Li&&Jianglin Fu&&Kaiyuan Liu&&Wentao Wang&&Kwan-Yee Lin&&Wayne Wu,arxiv,https://arxiv.org/abs/2404.01294
Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward,"직접 선호도 최적화 (DPO)와 같은 선호도 모델링 기술은 LLM (Lange Language Model)의 일반화 능력을 향상시키는 데 효과적이었습니다.그러나 비디오 교육을 따르는 과제에서, 특히 생성 된 응답에서 환각을 감지하기위한 유익한 피드백을 제공하는 것은 여전히 중요한 과제입니다.이전의 연구는 선호도 모델링을 안내하기위한 대형 대형 멀티 모달 모델 (LMMS)을 보상 모델로 사용하여 탐구했지만 해당 비디오와 비교하여 생성 된 응답의 사실을 정확하게 평가하는 능력은 결정적으로 확립되지 않았습니다.이 논문은 비디오 컨텐츠의 대리로 자세한 비디오 캡션을 사용하는 새로운 프레임 워크를 소개하여 언어 모델 이이 정보를 비디오 질문 답변 (QA) 예측 점수를 얻기위한 증거로 통합 할 수 있도록합니다.우리의 접근 방식은 OpenAI GPT-4V 모델의 보상 메커니즘과의 강력한 정렬을 보여줍니다. 이는 비디오 프레임을 입력으로 직접 가져옵니다.또한 DPO를 통해이 맞춤형 보상을 적용하면 비디오 QA 작업에서 비디오 LMM의 성능이 크게 향상됨을 보여줍니다.",2024.04.01,Ruohong Zhang&&Liangke Gui&&Zhiqing Sun&&Yihao Feng&&Keyang Xu&&Yuanhan Zhang&&Di Fu&&Chunyuan Li&&Alexander Hauptmann&&Yonatan Bisk&&Yiming Yang,arxiv,https://arxiv.org/abs/2404.01258
Condition-Aware Neural Network for Controlled Image Generation,"우리는 이미지 생성 모델에 제어를 추가하는 새로운 방법 인 CAN (Condition-Aware Neural Network)을 제시합니다.이전 조건부 제어 방법과 병행하여 신경망의 가중치를 동적으로 조작하여 이미지 생성 프로세스를 제어 할 수 있습니다.이는 입력 조건에 따라 컨볼 루션/선형 레이어에 대한 조건부 가중치를 생성하는 조건증 중량 생성 모듈을 도입하여 달성됩니다.우리는 Imagenet의 클래스 조건 이미지 생성 및 Coco의 텍스트-이미지 생성에 대해 테스트합니다.DIT 및 UVIT를 포함한 확산 변압기 모델에 대해 지속적으로 크게 개선 할 수 있습니다.특히, 효율성 VIT (CAT)와 결합 할 수 있습니다. imagenet 512x512에서 2.78 FID를 달성하여 DIT-XL/2를 능가하면서 샘플링 단계 당 52 배 적은 MAC를 요구합니다.",2024.04.01,Han Cai&&Muyang Li&&Zhuoyang Zhang&&Qinsheng Zhang&&Ming-Yu Liu&&Song Han,arxiv,https://arxiv.org/abs/2404.01143
Measuring Style Similarity in Diffusion Models,"생성 모델은 이제 그래픽 디자이너와 아티스트가 널리 사용합니다.이전의 작품은 이러한 모델이 세대 동안 교육 데이터에서 컨텐츠를 기억하고 복제하는 것으로 나타났습니다.따라서 확산이 증가함에 따라 생성 된 이미지가 전문적인 목적으로 사용되기 전에 매번 이미지의 속성이 특정 교육 데이터에 기인한지 여부를 결정하기 위해 데이터베이스 검색을 수행하는 것이 중요해졌습니다.이 목적을위한 기존 도구는 유사한 시맨틱 컨텐츠의 이미지를 검색하는 데 중점을 둡니다.한편, 많은 예술가들은 텍스트-이미지 모델의 스타일 복제에 관심이 있습니다.우리는 이미지에서 스타일 디스크립터를 이해하고 추출하기위한 프레임 워크를 제시합니다.우리의 프레임 워크는 스타일이 색상, 텍스처, 모양 등을 포함하여 복잡하지만 의미있는 요소를 캡처하는 이미지의 주관적인 속성이라는 통찰력을 사용하여 큐 레이트 된 새로운 데이터 세트로 구성됩니다. 또한 스타일 디스크립터를 추출하는 방법을 제안합니다.생성 된 이미지의 스타일을 텍스트-이미지 모델의 교육 데이터 세트에 사용 된 이미지에 속하는 데 사용할 수 있습니다.우리는 다양한 스타일의 검색 작업에서 유망한 결과를 보여줍니다.우리는 또한 스타일 속성과 안정적인 확산 모델에서 일치하는 스타일 속성을 정 성적으로 그리고 정 성적으로 분석합니다.코드 및 아티팩트는 HTTPS URL에서 사용할 수 있습니다.",2024.04.01,Gowthami Somepalli&&Anubhav Gupta&&Kamal Gupta&&Shramay Palta&&Micah Goldblum&&Jonas Geiping&&Abhinav Shrivastava&&Tom Goldstein,arxiv,https://arxiv.org/abs/2404.01292
Getting it Right: Improving Spatial Consistency in Text-to-Image Models,"현재 T2I (Text-to-Image) 모델의 주요 단점 중 하나는 텍스트 프롬프트에 지정된 공간 관계를 충실히 따르는 이미지를 지속적으로 생성 할 수 없다는 것입니다.이 논문에서는이 제한에 대한 포괄적 인 조사를 제공하는 동시에 최첨단 성능을 달성하는 데이터 세트 및 방법을 개발합니다.첫째, 우리는 현재의 비전 언어 데이터 세트가 공간 관계를 충분히 나타내지 않는다는 것을 발견했다.이 병목 현상을 완화하기 위해, 우리는 널리 사용되는 4 개의 비전 데이터 세트에서 6 백만 이미지를 다시 캡션하여 최초의 공간 중심의 대규모 데이터 세트 인 Spright를 만듭니다.3 배 평가 및 분석 파이프 라인을 통해 Spright는 공간 관계를 캡처 할 때 기존 데이터 세트를 크게 향상 시킨다는 것을 알게됩니다.그 효능을 입증하기 위해, 우리는 Spright의 ~ 0.25% 만 활용하고 공간적으로 정확한 이미지를 생성하는 동시에 FID 및 CMMD 점수를 향상시키는 데 22% 개선을 달성합니다.둘째, 우리는 많은 수의 물체를 포함하는 이미지에 대한 훈련이 공간 일관성이 상당히 개선된다는 것을 발견했습니다.특히, 우리는 <500 이미지를 미세 조정하여 0.2133의 공간 점수로 T2I-Compbench에서 최첨단을 달성합니다.마지막으로, 통제 된 실험과 절제 세트를 통해 텍스트-이미지 모델의 공간 일관성에 영향을 미치는 요소에 대한 이해를 향상시킬 수있는 여러 결과를 기록합니다.우리는이 분야에 대한 추가 연구를 촉진하기 위해 데이터 세트와 모델을 공개적으로 발표합니다.",2024.04.01,Agneet Chatterjee&&Gabriela Ben Melech Stan&&Estelle Aflalo&&Sayak Paul&&Dhruba Ghosh&&Tejas Gokhale&&Ludwig Schmidt&&Hannaneh Hajishirzi&&Vasudev Lal&&Chitta Baral&&Yezhou Yang,arxiv,https://arxiv.org/abs/2404.01197
Are large language models superhuman chemists?,"대형 언어 모델 (LLM)은 인간 언어를 처리하고 명시 적으로 교육을받지 않은 작업을 수행 할 수있는 능력으로 인해 광범위한 관심을 끌었습니다.이것은 텍스트 형태로 자주있는 작고 다양한 데이터 세트의 문제에 직면하는 화학 과학과 관련이 있습니다.LLMS는 이러한 문제를 해결하는 약속을 보여 주었으며 화학적 특성을 예측하고 반응을 최적화하며 실험을 자율적으로 설계하고 수행하기 위해 점점 더 활용되고 있습니다.그러나, 우리는 여전히 LLM의 화학적 추론 능력에 대한 체계적인 이해를 가지고 있으며, 이는 모델을 개선하고 잠재적 피해를 완화하는 데 필요합니다.여기, 우리는 인간 화학자의 전문 지식에 대한 최첨단 LLM의 화학 지식과 추론 능력을 엄격하게 평가하기 위해 설계된 자동화 된 프레임 워크 인 ""Chembench""를 소개합니다.우리는 화학 과학의 광범위한 서브 필드를 위해 7,000 개 이상의 질문 응답 쌍을 선별했으며, 개방 및 폐쇄 소스 LLM을 선도하는 선도적 인 개방 및 폐쇄 소스 LLM을 평가했으며, 최고의 모델이 평균적으로 최고의 인간 화학자보다 우수한 것으로 나타났습니다.그러나이 모델은 인간 전문가가 쉬운 일부 화학적 추론 작업으로 어려움을 겪고 화학 물질의 안전 프로파일과 같은 과도하게 자신감 있고 오해의 소지가있는 예측을 제공합니다.이러한 결과는 LLM이 화학 작업에서 놀라운 능력을 보여 주지만 화학 과학에서 안전성과 유용성을 향상시키는 데 더 많은 연구가 중요하다는 이중 현실을 강조합니다.우리의 연구 결과는 또한 화학 커리큘럼에 대한 적응의 필요성을 나타내며 안전하고 유용한 LLM을 개선하기 위해 평가 프레임 워크를 지속적으로 개발하는 것의 중요성을 강조합니다.",2024.04.01,Adrian Mirza&&Nawaf Alampara&&Sreekanth Kunchapu&&Benedict Emoekabu&&Aswanth Krishnan&&Mara Wilhelmi&&Macjonathan Okereke&&Juliane Eberhardt&&Amir Mohammad Elahi&&Maximilian Greiner&&Caroline T. Holick&&Tanya Gupta&&Mehrdad Asgari&&Christina Glaubitz&&Lea C. Klepsch&&Yannik Köster&&Jakob Meyer&&Santiago Miret&&Tim Hoffmann&&Fabian Alexander Kreth&&Michael Ringleb&&Nicole Roesner&&Ulrich S. Schubert&&Leanne M. Stafast&&Dinga Wonanke&&Michael Pieler&&Philippe Schwaller&&Kevin Maik Jablonka,arxiv,https://arxiv.org/abs/2404.01475
Bigger is not Always Better: Scaling Properties of Latent Diffusion Models,"우리는 샘플링 효율에 중점을 둔 잠재 확산 모델 (LDMS)의 스케일링 특성을 연구합니다.개선 된 네트워크 아키텍처 및 추론 알고리즘은 확산 모델의 샘플링 효율을 효과적으로 향상시키는 것으로 나타 났지만, 샘플링 효율의 중요한 결정 요인 인 모델 크기의 역할은 철저히 조사되지 않았습니다.확립 된 텍스트-이미지 확산 모델에 대한 경험적 분석을 통해, 우리는 다양한 샘플링 단계에서 모델 크기가 샘플링 효율에 어떤 영향을 미치는지에 대한 심층적 인 조사를 수행합니다.우리의 연구 결과는 놀라운 추세를 공개합니다. 주어진 추론 예산에 따라 운영 될 때 소규모 모델은 종종 고품질 결과를 생성하는 데 더 큰 동등성을 능가합니다.또한, 우리는 다양한 확산 샘플러를 적용하고 다양한 다운 스트림 작업을 탐색하고, 이지화 후 모델을 평가하고, 훈련 컴퓨팅에 대한 성능을 비교함으로써 이러한 결과의 일반화 가능성을 보여주기 위해 연구를 확장했습니다.이러한 결과는 제한된 추론 예산 내에서 생성 기능을 향상시키기 위해 사용할 수있는 LDM 스케일링 전략의 개발을위한 새로운 경로를 열어줍니다.",2024.04.01,Kangfu Mei&&Zhengzhong Tu&&Mauricio Delbracio&&Hossein Talebi&&Vishal M. Patel&&Peyman Milanfar,arxiv,https://arxiv.org/abs/2404.01367
Stream of Search (SoS): Learning to Search in Language,"언어 모델은 훈련하는 동안 유익한 실수를 거의 나타내지 않습니다.그런 다음 그들은 다음 토큰을 넘어서 오류의 눈덩이로 고통 받고 몇 단계 앞서 자신의 행동의 결과를 예측하기 위해 고군분투하는 데 어려움을 겪고 있습니다.이 논문에서는 언어 검색 프로세스를 평평한 문자열 (SOS)으로 표현하여 언어 모델을 검색하는 방법을 보여줍니다.우리는 다양한 상징적 검색 전략을 캡처하는 검색을위한 통일 된 언어를 제안합니다.우리는 단순하면서도 어려운 카운트 다운 게임을 사용하여 접근 방식을 보여줍니다. 여기서 목표는 입력 번호를 산술 작업과 결합하여 대상 번호에 도달하는 것입니다.우리는 Heuristic Solvers에 의해 생성 된 검색 스트림 데이터 세트에서 Transformer 기반 언어 모델을 처음부터 사전에 전제합니다.우리는 SOS 사전 조정이 최적의 검색 궤적 만 예측하도록 훈련 된 모델보다 검색 정확도를 25% 증가 시킨다는 것을 발견했습니다.우리는이 모델을 두 가지 정책 개선 방법, 즉 APA (Advantage-Senseed Policy Alignment)와 자체 가르침 추론 (StAR)으로 추가로 제공합니다.Finetuned SOS 모델은 휴리스틱 솔버가 해결할 수없는 문제를 포함하여 이전에 해결되지 않은 문제의 36%를 해결합니다.우리의 결과는 언어 모델이 검색을 통해 문제를 해결하고, 다른 검색 전략을 유연하게 사용하도록 자체적으로 처리하고, 잠재적으로 새로운 것을 발견 할 수 있음을 나타냅니다.",2024.04.01,Kanishk Gandhi&&Denise Lee&&Gabriel Grand&&Muxin Liu&&Winson Cheng&&Archit Sharma&&Noah D. Goodman,arxiv,https://arxiv.org/abs/2404.03683
Poro 34B and the Blessing of Multilinguality,"최첨단 대형 언어 모델의 사전 조정에는 이제 대부분의 언어에서 사용할 수있는 것보다 훨씬 많은 수조 단어의 텍스트가 필요합니다.하나 이상의 언어로 텍스트를 포함시키는 것은 더 많은 사전화 데이터를 얻는 명백한 방법이지만, 다국어는 종종 저주로 간주되며, 대부분의 모델 훈련 노력은 개별 대형 언어에 계속해서 독점적으로 초점을 맞추고 있습니다.우리는 다국어가 축복이 될 수 있으며 다국어 교육을 통해 소규모 언어에 대한 단일 언어 모델의 능력을 크게 개선 할 수 있어야한다고 생각합니다.이 연구에서 우리는 핀란드어, 영어 및 프로그래밍 언어의 1 조의 토큰을 위해 훈련 된 340 억 개의 매개 변수 모델 인 PORO 34B를 소개하고 다국어 교육 접근법이 기존 모델의 기능보다 실질적으로 발전 할뿐만 아니라 모델을 생성 할 수 있음을 보여줍니다.핀란드의 경우도 번역이 뛰어나며 영어 및 프로그래밍 언어를 생성하는 데있어 수업 시간에 경쟁력이 있습니다.HTTPS URL에서 공개 라이센스 아래 모델 매개 변수, 스크립트 및 데이터를 해제합니다.",2024.04.02,Risto Luukkonen&&Jonathan Burdge&&Elaine Zosa&&Aarne Talman&&Ville Komulainen&&Väinö Hatanpää&&Peter Sarlin&&Sampo Pyysalo,arxiv,https://arxiv.org/abs/2404.01856
HyperCLOVA X Technical Report,"우리는 영어, 수학 및 코딩의 경쟁력과 함께 한국어 및 문화에 맞는 대형 언어 모델 (LLM) 제품군 인 Hyperclova X를 소개합니다.Hyperclova X는 한국, 영어 및 코드 데이터의 균형 잡힌 혼합에 대해 교육을 받았으며, 책임있는 AI에 대한 우리의 약속을 반영하는 엄격한 안전 지침을 준수하면서 고품질의 인간이 주어진 데이터 세트를 사용하여 교육을 조정했습니다.이 모델은 한국과 영어 모두에서 포괄적 인 추론, 지식, 상식, 사실, 코딩, 수학, 채팅, 지시 금고 및 무해 함을 포함한 다양한 벤치 마크에서 평가됩니다.Hyperclova X는 언어와 문화적 뉘앙스에 대한 깊은 이해로 한국에서 강력한 추론 능력을 보여줍니다.고유 한 이중 언어 특성과 다국어에 대한 확장에 대한 추가 분석은 여러 언어 쌍과 교차 언어 추론 작업 사이의 기계 번역을 포함하여 모델의 교차 숙련성과 표적화되지 않은 언어에 대한 강력한 일반화 능력을 강조합니다.우리는 Hyperclova X가 주권 LLM을 개발하는 지역이나 국가에 유용한 지침을 제공 할 수 있다고 생각합니다.",2024.04.02,Kang Min Yoo&&Jaegeun Han&&Sookyo In&&Heewon Jeon&&Jisu Jeong&&Jaewook Kang&&Hyunwook Kim&&Kyung-Min Kim&&Munhyong Kim&&Sungju Kim&&Donghyun Kwak&&Hanock Kwak&&Se Jung Kwon&&Bado Lee&&Dongsoo Lee&&Gichang Lee&&Jooho Lee&&Baeseong Park&&Seongjin Shin&&Joonsang Yu&&Seolki Baek&&Sumin Byeon&&Eungsup Cho&&Dooseok Choe&&Jeesung Han&&Youngkyun Jin&&Hyein Jun&&Jaeseung Jung&&Chanwoong Kim&&Jinhong Kim&&Jinuk Kim&&Dokyeong Lee&&Dongwook Park&&Jeong Min Sohn&&Sujung Han&&Jiae Heo&&Sungju Hong&&Mina Jeon&&Hyunhoon Jung&&Jungeun Jung&&Wangkyo Jung&&Chungjoon Kim&&Hyeri Kim&&Jonghyun Kim&&Min Young Kim&&Soeun Lee&&Joonhee Park&&Jieun Shin&&Sojin Yang&&Jungsoon Yoon&&Hwaran Lee&&Sanghwan Bae&&Jeehwan Cha&&Donghoon Ham&&Youngki Hong&&Yunki Hong&&Myunggeun Ji&&Yeguk Jin&&Chansong Jo&&Shinyoung Joo&&Seunghwan Jung&&Hyomin Kim&&Jungwhan Kim&&Minkyoung Kim&&Minseung Kim&&Sungdong Kim&&Yonghee Kim&&Youngjun Kim&&Donghyeon Ko&&Dughyun Lee&&Jaehong Lee&&Jieun Lee&&Jongjin Lee&&Min Young Lee&&Yehbin Lee&&Taehong Min&&Kiyoon Moon&&Jaesun Park&&Kyuyon Park&&Seunghyun Seo&&Gyubin Son&&Wonjoon Yoo&&Myungin You&&Doheon Ahn&&Homin Ahn&&Joohee Ahn&&Seongmin Ahn&&Chanwoo An&&Hyeryun An&&Junho An&&Sang-Min An&&Boram Byun&&Jongho Cha&&Minji Chang&&Seunggyu Chang&&Haesong Cho&&Youngdo Cho&&Dalnim Choi&&Daseul Choi&&Hyoseok Choi&&Minseong Choi&&Sangho Choi&&Seongjae Choi&&Wooyong Choi&&Sewhan Chun&&Dong Young Go&&Chiheon Ham&&Danbi Han&&Jaemin Han&&Mihak Hong&&Moonyoung Hong&&Sung Bum Hong&&Seongchan Hwang&&Eunbin Hyun&&Jinbae Im&&Jaehyung Jang&&Jaeni Jang&&Sihyeon Jang&&Sungwon Jang&&Joonha Jeon&&Yujin Jeon&&Daun Jeong&&Joonhyun Jeong&&Kyeongseok Jeong&&Mini Jeong&&Yeji Jeong&&Sol Jin&&Hanbyeol Jo&&Hanju Jo&&Minjung Jo&&Lee Jonghyun&&Chaeyoon Jung&&Hyungsik Jung&&Jaeuk Jung&&Ju Hwan Jung&&Kwangsun Jung&&Seungjae Jung&&Soonwon Ka&&Donghan Kang&&Soyoung Kang&&Taeho Kil&&Areum Kim&&Beomyoung Kim&&Byeongwook Kim&&Daehee Kim&&Dong-Gyun Kim&&Donggook Kim&&Donghyun Kim&&Euna Kim&&Eunchul Kim&&Geewook Kim&&Gyu Ri Kim&&Hanbyul Kim&&Heesu Kim&&Isaac Kim&&Jeonghoon Kim&&Jihye Kim&&Joonghoon Kim&&Minjae Kim&&Minsub Kim&&Pil Hwan Kim&&Sammy Kim&&Seokhun Kim&&Seonghyeon Kim&&Soojin Kim&&Soong Kim&&Soyoon Kim&&Sunyoung Kim&&Taeho Kim&&Wonho Kim&&Yoonsik Kim&&You Jin Kim&&Yuri Kim&&Beomseok Kwon&&Ohsung Kwon&&Yoo-Hwan Kwon&&Anna Lee&&Byungwook Lee&&Changho Lee&&Daun Lee&&Dongjae Lee&&Ha-Ram Lee&&Hodong Lee&&Hwiyeong Lee&&Hyunmi Lee&&Injae Lee&&Jaeung Lee&&Jeongsang Lee&&Jisoo Lee&&Joongjae Lee&&Juhan Lee&&Jung Hyun Lee&&Junghoon Lee&&Junwoo Lee&&Se Yun Lee&&Sujin Lee&&Sungjae Lee&&Sungwoo Lee&&Wonjae Lee&&Zoo Hyun Lee&&Jong Kun Lim&&Kun Lim&&Taemin Lim&&Yuri Min&&Nuri Na&&Jeongyeon Nam&&Kyeong-Min Nam&&Yeonseog Noh&&Biro Oh&&Hyangnam Oh&&Jung-Sik Oh&&Solgil Oh&&Yeontaek Oh&&Boyoun Park&&Cheonbok Park&&Dongju Park&&Hyeonjin Park&&Hyun Tae Park&&Hyunjung Park&&Jihye Park&&Jooseok Park&&Junghwan Park&&Jungsoo Park&&Miru Park&&Sang Hee Park&&Seunghyun Park&&Taerim Park&&Wonkyeong Park&&Hyunjoon Ryu&&Jeonghun Ryu&&Nahyeon Ryu&&Soonshin Seo&&Suk Min Seo&&Yoonjeong Shim&&Kyuyong Shin&&Wonkwang Shin&&Hyun Sim&&Mihyun Sim&&Woongseob Sim&&Hyejin Soh&&Bokyoung Son&&Hyunjun Son&&Seulah Son&&Chi-Yun Song&&Chiyoung Song&&Ka Yeon Song&&Minchul Song&&Seungmin Song&&Jisung Wang&&Matt Yeo&&Yonggoo Yeo&&Myeong Yeon Yi&&Moon Bin Yim&&Taehwan Yoo&&Youngjoon Yoo&&Sungmin Yoon&&Young Jin Yoon&&Hangyeol Yu&&Ui Seon Yu&&Xingdong Zuo&&Jeongin Bae&&Joungeun Bae&&Hyunsoo Cho&&Seonghyun Cho&&Yongjin Cho&&Taekyoon Choi&&Yera Choi&&Jiwan Chung&&Zhenghui Han&&Byeongho Heo&&Euisuk Hong&&Taebaek Hwang&&Seonyeol Im&&Sumin Jegal&&Sumin Jeon&&Yelim Jeong&&Yonghyun Jeong&&Can Jiang&&Juyong Jiang&&Jiho Jin&&Ara Jo&&Younghyun Jo&&Hoyoun Jung&&Juyoung Jung&&Dae Hee Kim&&Ginam Kim&&Hangyeol Kim&&Heeseung Kim&&Hyojin Kim&&Hyojun Kim&&Hyun-Ah Kim&&Jeehye Kim&&Jin-Hwa Kim&&Jiseon Kim&&Jonghak Kim&&Jung Yoon Kim&&Rak Yeong Kim&&Seoyoon Kim&&Sewon Kim&&Sooyoung Kim&&Sukyoung Kim&&Taeyong Kim&&Naeun Ko&&Bonseung Koo&&Heeyoung Kwak&&Haena Kwon&&Youngjin Kwon&&Boram Lee&&Bruce W. Lee&&Dagyeong Lee&&Erin Lee&&Euijin Lee&&Ha Gyeong Lee&&Hyojin Lee&&Hyunjeong Lee&&Jeeyoon Lee&&Jeonghyun Lee&&Jongheok Lee&&Joonhyung Lee&&Junhyuk Lee&&Mingu Lee&&Nayeon Lee&&Sangkyu Lee&&Se Young Lee&&Seulgi Lee&&Seung Jin Lee&&Suhyeon Lee&&Yeonjae Lee&&Yesol Lee&&Youngbeom Lee&&Yujin Lee&&Shaodong Li&&Tianyu Liu&&Seong-Eun Moon&&Taehong Moon&&Max-Lasse Nihlenramstroem&&Wonseok Oh&&Yuri Oh&&Hongbeen Park&&Hyekyung Park&&Nohil Park&&Sangjin Park&&Jiwon Ryu&&Miru Ryu&&Simo Ryu&&Ahreum Seo&&Hee Seo&&Kangdeok Seo&&Jamin Shin&&Seungyoun Shin&&Heetae Sin&&Jiangping Wang&&Lei Wang&&Ning Xiang&&Longxiang Xiao&&Jing Xu&&Seonyeong Yi&&Haanju Yoo&&Haneul Yoo&&Hwanhee Yoo&&Liang Yu&&Youngjae Yu&&Weijie Yuan&&Bo Zeng&&Qian Zhou&&Kyunghyun Cho&&Jung-Woo Ha&&Joonsuk Park&&Jihyun Hwang&&Hyoung Jo Kwon&&Soonyong Kwon&&Jungyeon Lee&&Seungho Lee&&Seungho Choi&&Sang-Woo Lee&&Jung Hwa Lim&&Nako Sung&&et al. (277 additional authors not shown),arxiv,https://arxiv.org/abs/2404.01954
LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models,"LLM (Lange Language Models)의 생성 기능을 활용하여 다양한 네트워크 특성에 맞게 조정 된 적응 형 비트 레이트 (ABR) 알고리즘을 자율적으로 설계하는 LLM-ABR을 제시합니다.강화 학습 프레임 워크 내에서 운영되는 LLM-ABR은 LLM이 상태 및 신경망 아키텍처와 같은 주요 구성 요소를 설계 할 수 있도록합니다.광대역, 위성, 4G 및 5G를 포함한 다양한 네트워크 설정에서 LLM-ABR을 평가합니다.LLM-ABR은 기본 ABR 알고리즘을 지속적으로 능가합니다.",2024.04.02,Zhiyuan He&&Aashish Gottipati&&Lili Qiu&&Francis Y. Yan&&Xufang Luo&&Kenuo Xu&&Yuqing Yang,arxiv,https://arxiv.org/abs/2404.01617
Long-context LLMs Struggle with Long In-context Learning,"대형 언어 모델 (LLM)은 32k 토큰을 초과하는 긴 시퀀스를 처리하는 데 큰 진전을 이루었습니다.그러나 그들의 성과 평가는 당황 및 합성 작업과 같은 지표에 크게 국한되었으며, 이는 미묘한 실제 시나리오에서 능력을 완전히 포착하지 못할 수 있습니다.이 연구는 극도의 라벨 분류 영역 내에서 긴 컨텍스트 학습에 중점을 둔 전문화 된 벤치 마크 (Longiclbench)를 소개합니다.우리는 2k에서 50k 토큰의 다른 입력 (몇 가지 샷 데모) 길이를 다루는 28 ~ 174 개의 클래스에 걸친 레이블 범위를 가진 6 개의 데이터 세트를 세 심하게 선택했습니다.우리의 벤치 마크는 LLM이 전체 입력을 이해하여 거대한 레이블 공간을 인식하여 올바른 예측을 할 필요가 있습니다.벤치 마크에서 13 개의 장거리 LLM을 평가합니다.긴 컨텍스트 LLM은 긴 컨텍스트 창을 효과적으로 활용하여 데모 길이가 짧은 덜 도전적인 작업에서 비교적 잘 수행한다는 것을 발견했습니다.그러나 174 개의 레이블을 사용한 가장 어려운 작업 발견에서 모든 LLM은 작업 정의를 이해하기 위해 노력하여 0에 가까운 성능에 도달합니다.이는 길고 컨텍스트가 풍부한 시퀀스를 처리하고 이해하기위한 현재 LLM 기능에서 주목할만한 간격을 시사합니다.추가 분석은 서열의 끝을 향해 제시된 라벨에 대한 예측을 선호하는 모델들 사이의 경향을 보여 주었다.긴 시퀀스에서 여러 조각에 대한 추론 능력은 아직 개선되지 않았습니다.우리의 연구는 긴 맥락의 이해와 추론이 여전히 기존 LLM들에게 어려운 과제임을 보여줍니다.우리는 Longiclbench가 미래의 장기 텍스트 LLM에 대한보다 현실적인 평가 역할을 할 수 있다고 생각합니다.",2024.04.02,Tianle Li&&Ge Zhang&&Quy Duc Do&&Xiang Yue&&Wenhu Chen,arxiv,https://arxiv.org/abs/2404.02060
Advancing LLM Reasoning Generalists with Preference Trees,"우리는 추론을 위해 최적화 된 대형 언어 모델 (LLMS) 제품군 인 Eurus를 소개합니다.Mistral-7b 및 Codellama-70B에서 Finetuned 인 Eurus 모델은 수학, 코드 생성 및 논리적 추론 문제를 다루는 다양한 벤치 마크 세트에서 오픈 소스 모델 중 최첨단 결과를 달성합니다.특히 EURUS-70B는 5 개의 작업을 다루는 12 개의 테스트에서 포괄적 인 벤치마킹을 통해 추론에서 GPT-3.5 터보를 이겼으며 Leetcode에서 33.3% 패스@1 정확도를 달성하고 Theoremqa에서 32.6%를 달성하여 두 가지 도전적인 벤치 마크에서 32.6%를 달성합니다.마진에 의한 모델 13.3%이상.EURU의 강력한 성능은 주로 복잡한 추론 작업을 위해 특별히 설계된 새로 구축 된 대규모 고품질 정렬 데이터 세트 인 UltrainterAct에 기인 할 수 있습니다.UltrainterAct는 감독 된 미세 조정 및 선호도 학습에 모두 사용할 수 있습니다.각 명령에 대해 (1) 통합 형식의 다양한 계획 전략을 가진 추론 체인, (2) 환경 및 비판과의 다중 회전 상호 작용 궤적 및 (3) 선호도 학습을 용이하게하기위한 쌍별 데이터를 포함합니다..UltrainterAct를 사용하면 추론 작업을위한 선호도 학습에 대한 심층적 인 탐색을 수행 할 수 있습니다.우리의 조사에 따르면 잘 확립 된 선호도 학습 알고리즘은 일반적인 대화에서의 효과와 비교하여 추론 작업에 적합하지 않을 수 있습니다.이에 영감을 얻은 우리는 Ultrainteract와 함께 강력한 보상 모델로 이어지는 새로운 보상 모델링 목표를 도출합니다.",2024.04.02,Lifan Yuan&&Ganqu Cui&&Hanbin Wang&&Ning Ding&&Xingyao Wang&&Jia Deng&&Boji Shan&&Huimin Chen&&Ruobing Xie&&Yankai Lin&&Zhenghao Liu&&Bowen Zhou&&Hao Peng&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.02078
CameraCtrl: Enabling Camera Control for Text-to-Video Generation,제어 가능성은 사용자가 원하는 컨텐츠를 만들 수 있기 때문에 비디오 생성에서 중요한 역할을합니다.그러나 기존 모델은 더 깊은 이야기 뉘앙스를 표현하는 영화 언어 역할을하는 카메라 포즈의 정확한 제어를 간과했습니다.이 문제를 완화하기 위해 Cameractrl을 소개하여 T2V (Text-to-Video) 모델을위한 정확한 카메라 포즈 제어를 가능하게합니다.카메라 궤적을 정확하게 매개 변수화 한 후 플러그 앤 플레이 카메라 모듈은 T2V 모델로 교육을 받고 다른 사람들은 손대지 않습니다.또한 다양한 데이터 세트의 효과에 대한 포괄적 인 연구가 수행되어 다양한 카메라 배포와 유사한 외관이있는 비디오가 실제로 제어 가능성과 일반화를 향상시킬 수 있음을 시사합니다.실험 결과는 정확하고 도메인 적응 형 카메라 컨트롤을 달성하는 데있어 카메라 크트L의 효과를 보여줍니다.프로젝트 웹 사이트는 다음과 같습니다.이 HTTPS URL.,2024.04.02,Hao He&&Yinghao Xu&&Yuwei Guo&&Gordon Wetzstein&&Bo Dai&&Hongsheng Li&&Ceyuan Yang,arxiv,https://arxiv.org/abs/2404.02101
Octopus v2: On-device language model for super agent,"언어 모델은 다양한 소프트웨어 응용 프로그램, 특히 자동 워크 플로와 관련된 작업에서 효과를 보여주었습니다.이 모델은 기능을 호출하는 데 중요한 능력을 가지고 있으며, 이는 AI 에이전트를 만드는 데 필수적입니다.클라우드 환경에서 대규모 언어 모델의 고성능에도 불구하고 종종 개인 정보 및 비용에 대한 우려와 관련이 있습니다.대기 시간 및 정확도로 얼굴 문제를 호출하는 기능을위한 현재 기기 모델.우리의 연구는 정확도와 대기 시간 모두에서 GPT-4의 성능을 능가하기 위해 20 억 파라미터의 기기 모델을 강화하고 컨텍스트 길이를 95 \%줄이는 새로운 방법을 제시합니다.헝겊 기반 기능 호출 메커니즘과 LLAMA-7B와 비교할 때, 우리의 방법은 대기 시간을 35 배 향상시킵니다.이 방법은 대기 시간을 생산 환경에서 다양한 에지 장치에 걸쳐 배포하기에 적합한 레벨로 줄어들어 실제 애플리케이션에 대한 성능 요건과 일치합니다.",2024.04.02,Wei Chen&&Zhiyuan Li,arxiv,https://arxiv.org/abs/2404.01744
3D Congealing: 3D-Aware Image Alignment in the Wild,"우리는 의미 적으로 유사한 물체를 캡처하는 2D 이미지에 대한 3D 인식 정렬의 새로운 문제인 3D Congealing을 제안합니다.표지되지 않은 인터넷 이미지 모음이 주어지면, 우리의 목표는 공유 시맨틱 부분을 입력에서 연관시키고 2D 이미지에서 공유 된 3D 표준 공간으로 지식을 집계하는 것입니다.우리는 모양 템플릿, 포즈 또는 카메라 매개 변수를 가정하지 않고 작업을 해결하는 일반적인 프레임 워크를 소개합니다.그 핵심은 기하학적 및 의미 론적 정보를 캡슐화하는 표준 3D 표현이 있습니다.이 프레임 워크는 각 입력 이미지에 대한 포즈와 함께 표준 표현을 최적화하고, 2D 픽셀 좌표가 3D 표준 프레임으로 뒤틀리는 형상 일치를 설명하는 심각한 좌표 맵을 최적화합니다.최적화 절차는 미리 훈련 된 이미지 생성 모델과 입력 이미지의 의미 정보에서 사전 지식을 융합시킵니다.전자는이 제약 부족 작업에 대한 강력한 지식 지침을 제공하는 반면, 후자는 미리 훈련 된 모델에서 교육 데이터 편향을 완화하는 데 필요한 정보를 제공합니다.당사의 프레임 워크는 서신 일치, 포즈 추정 및 이미지 편집과 같은 다양한 작업에 사용될 수 있으며, 도전적인 조명 조건 및 온라인 온라인 이미지 컬렉션에서 실제 이미지 데이터 세트에 대한 강력한 결과를 얻을 수 있습니다.",2024.04.02,Yunzhi Zhang&&Zizhang Li&&Amit Raj&&Andreas Engelhardt&&Yuanzhen Li&&Tingbo Hou&&Jiajun Wu&&Varun Jampani,arxiv,https://arxiv.org/abs/2404.02125
Mixture-of-Depths: Dynamically allocating compute in transformer-based language models,"변압기 기반 언어 모델은 입력 시퀀스에 걸쳐 플롭을 균일하게 퍼뜨립니다.이 작업에서 우리는 변압기가 대신 분열의 특정 위치에 플롭을 동적으로 할당하는 법을 배울 수 있음을 보여줍니다.우리의 방법은 주어진 계층에서 자체 변환 및 MLP 계산에 참여할 수있는 토큰 수 (k) 수를 캡핑하여 총 컴퓨팅 예산을 시행합니다.처리 할 토큰은 최상위 원조 메커니즘을 사용하여 네트워크에 의해 결정됩니다.Kis는 선험적으로 정의 되었으므로이 간단한 절차는 다른 조건부 계산 기술과 달리 알려진 텐서 크기의 정적 계산 그래프를 사용합니다.그럼에도 불구하고, ktokens의 정체성은 유동적이기 때문에,이 방법은 시간에 걸쳐 균일하게 플롭을 소비 할 수 있으며 모델 깊이 치수.따라서 컴퓨팅 지출은 전체적으로 총계에서 예측 가능하지만 토큰 수준에서는 역동적이고 컨텍스트에 민감합니다.이러한 방식으로 훈련 된 모델은 컴퓨팅을 동적으로 할당하는 법을 배울뿐만 아니라 효율적으로 그렇게합니다.이 모델은 등가 플롭 및 벽 클록 타임에 대한 기준 성능과 일치하지만 전방 패스 당 플롭의 일부가 필요하며, 후 훈련 후 샘플링 중에 단계에 50% 더 빠르게 50 \% 이상이 될 수 있습니다.",2024.04.02,David Raposo&&Sam Ritter&&Blake Richards&&Timothy Lillicrap&&Peter Conway Humphreys&&Adam Santoro,arxiv,https://arxiv.org/abs/2404.02258
MuLan: A Study of Fact Mutability in Language Models,"사실은 비상 사태의 대상이되며 다른 상황에서는 사실 또는 거짓일 수 있습니다.그러한 비상 사태 중 하나는 시간이 지남에 따라 일부 사실이 주어진 기간에 걸쳐 돌연변이되는 시간, 예를 들어 국가 회장 또는 챔피언십의 우승자입니다.신뢰할 수있는 언어 모델은 변한 사실을 이상적으로 식별하여 그에 따라 처리합니다.우리는 1 : 1과 1 : N 관계를 모두 다루는 시간 소지를 예상하는 영어 모델의 능력을 평가하기위한 벤치 마크인 Mulan을 만듭니다.우리는 돌연변이 가능한 사실이 불변의 사실과 다르게 인코딩되어 업데이트하기가 더 쉽다는 가설을 세웁니다.6 가지 대중적인 대형 언어 모델에 대한 자세한 평가에서 사실의 돌연변이에 따라 LLMS의 신뢰, 표현 및 업데이트 동작의 차이를 지속적으로 발견합니다.우리의 연구 결과는 LLM에 대한 시간에 대한 지식의 주입 및 유도에 대한 미래의 작업을 알려야합니다.",2024.04.03,Constanza Fierro&&Nicolas Garneau&&Emanuele Bugliarello&&Yova Kementchedjhieva&&Anders Søgaard,arxiv,https://arxiv.org/abs/2404.03036
Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction,"우리는 시각적자가 회귀 모델링 (VAR)을 제시하는 새로운 세대 패러다임을 제시하는 새로운 세대 패러다임을 제시하는 새로운 세대 패러다임을 제시하는 시각적 패러다임을 제시합니다.이 패러다임은 표준 Raster-Scan ""Next-에서 분기되는 거친""차세대 예측 ""또는""차세 해상도 예측 ""으로 이미지에 대한 자동 회귀 학습을 재정의합니다.토큰 예측 "".이 간단하고 직관적 인 방법론을 통해 AR (Autoregreastive) 변압기는 시각적 분포를 빠르게 배우고 잘 일반화 할 수 있습니다. VAR, 처음으로 AR 모델은 이미지 생성에서 확산 변압기를 능가합니다.ImageNet 256X256 벤치 마크에서 VAR은 Frechet Inception Disting (FID)을 18.65에서 1.80으로 개선하여 AR 기준을 크게 향상시킵니다.VAR은 이미지 품질, 추론 속도, 데이터 효율 및 확장 성을 포함한 여러 차원에서 확산 변압기 (DIT)를 능가하는 것으로 경험적으로 확인됩니다.VAR 모델을 스케일링하면 LLM에서 관찰 된 것과 유사한 명확한 전력 법률 스케일링 법칙을 보여줍니다.VAR은 이미지 인 페인팅, 아웃 페인팅 및 편집을 포함하여 다운 스트림 작업에서 제로 샷 일반화 능력을 보여줍니다.이 결과는 VAR이 LLM의 두 가지 중요한 속성, 즉 스케일링 법률과 제로 샷 작업 일반화를 처음에 모방했음을 시사합니다.우리는 시각적 생성 및 통합 학습을위한 AR/VAR 모델의 탐색을 촉진하기 위해 모든 모델과 코드를 발표했습니다.",2024.04.03,Keyu Tian&&Yi Jiang&&Zehuan Yuan&&Bingyue Peng&&Liwei Wang,arxiv,https://arxiv.org/abs/2404.02905
ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline,"대형 언어 모델 (LLMS)은 인간 언어의 우수한 마스터 링을 보여 주었지만 수학적 문제 해결이 필요한 실제 응용 프로그램에서 여전히 어려움을 겪고 있습니다.LLM의 수학을 향상시키기위한 많은 전략과 데이터 세트가 개발되었지만, 배포 된 LLM에서 언어와 수학적 기능을 동시에 유지하고 개선하는 것은 여전히 HTTP URL이 작업을 수행하는 데 어려움을 겪고 있습니다.LLM 정렬 단계.우리는 먼저 LLM 자체에서 일반적인 수학 크리티컬 모델을 훈련시켜 피드백 신호를 제공합니다.그런 다음 데이터 수집을 위해 LLM 자체 세대에 대한 거부 미세 조정 및 직접 선호도 최적화를 순차적으로 사용합니다.ChatGLM3-32B를 기반으로, 우리는 학계와 새로 만든 도전적인 데이터 세트 인 MathusereVal에 대한 일련의 실험을 수행합니다.결과에 따르면 파이프 라인이 LLM의 수학적 문제 해결을 크게 향상시키면서 언어 능력을 향상시켜 LLM이 2 배 더 커질 수 있습니다.관련 기술은 온라인 서빙 LLM 인 ChatGlm \ Footnote {this https url}}에 배포되었습니다.관련 평가 데이터 세트 및 스크립트는 \ url {this https url}에서 릴리스됩니다.",2024.04.03,Yifan Xu&&Xiao Liu&&Xinghan Liu&&Zhenyu Hou&&Yueyan Li&&Xiaohan Zhang&&Zihan Wang&&Aohan Zeng&&Zhengxiao Du&&Wenyi Zhao&&Jie Tang&&Yuxiao Dong,arxiv,https://arxiv.org/abs/2404.02893
On the Scalability of Diffusion-based Text-to-Image Generation,"LLM의 진화에는 모델과 데이터 크기를 확장하는 것이 매우 성공적이었습니다.그러나 확산 기반 텍스트-이미지 (T2I) 모델의 스케일링 법은 완전히 탐색되지 않습니다.또한 저렴한 비용으로 더 나은 성능을 위해 모델을 효율적으로 확장하는 방법도 불분명합니다.다양한 교육 설정과 고가의 교육 비용으로 인해 공정한 모델 비교가 매우 어렵습니다.이 작업에서, 우리는 600m 이미지까지 데이터 세트에서 0.4b에서 4b 매개 변수의 훈련 스케일링 UNET 및 변압기 변이체를 포함하여 데노 이어스 백본 및 훈련 세트를 모두 스케일링하는 데있어 광범위하고 엄격한 절제를 수행함으로써 확산 기반 T2I 모델의 스케일링 특성을 경험적으로 연구합니다.모델 스케일링의 경우 크로스주의 위치와 양이 기존 UNET 디자인의 성능을 구별합니다.변압기 블록을 증가시키는 것은 채널 번호를 증가시키는 것보다 텍스트 이미지 정렬을 향상시키는 데 더 매개 변수 효율적입니다.그런 다음 SDXL UNET보다 45% 더 작고 28% 빠른 효율적인 UNET 변형을 식별합니다.데이터 스케일링 측면에서, 우리는 교육 세트의 품질과 다양성이 단순히 데이터 세트 크기 이상의 문제를 보여줍니다.캡션 밀도 및 다양성을 높이면 텍스트 이미지 정렬 성능과 학습 효율이 향상됩니다.마지막으로, 모델 크기, 컴퓨팅 및 데이터 세트 크기의 스케일의 함수로서 텍스트-이미지 정렬 성능을 예측하기 위해 스케일링 함수를 제공합니다.",2024.04.03,Hao Li&&Yang Zou&&Ying Wang&&Orchid Majumder&&Yusheng Xie&&R. Manmatha&&Ashwin Swaminathan&&Zhuowen Tu&&Stefano Ermon&&Stefano Soatto,arxiv,https://arxiv.org/abs/2404.02883
Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models,"이 연구는 텍스트-조건 확산 모델에서 추론하는 동안 교차 적분의 역할을 탐구합니다.우리는 몇 가지 추론 단계 후에 교차 출력이 고정점으로 수렴한다는 것을 발견했다.따라서 수렴의 시점은 전체 추론 프로세스를 자연스럽게 두 단계로 나눕니다. 초기 시맨틱 계획 단계로,이 기간 동안 모델은 텍스트 지향적 시각적 의미를 계획하기 위해 교차 변형에 의존하고 그 이후의 충실도 면화 단계를 계획합니다.그 동안이 모델은 이전에 계획된 의미론에서 이미지를 생성하려고합니다.놀랍게도, 충실도 면제 단계에서 텍스트 조건을 무시하면 계산 복잡성을 줄일뿐만 아니라 모델 성능을 유지합니다.이는 효율적인 생성을 위해 Tgate라는 간단하고 훈련이없는 방법을 생성하며, 이는 수렴 후 크로스-내 출력을 캐시하고 나머지 추론 단계에서 고정시킵니다.MS-Coco 검증 세트에 대한 경험적 연구는 그 효과를 확인합니다.tgate의 소스 코드는이 https url에서 사용할 수 있습니다.",2024.04.03,Wentian Zhang&&Haozhe Liu&&Jinheng Xie&&Francesco Faccio&&Mike Zheng Shou&&Jürgen Schmidhuber,arxiv,https://arxiv.org/abs/2404.02747
Freditor: High-Fidelity and Transferable NeRF Editing by Frequency Decomposition,"이 논문은 주파수 분해로 고 충실도, 전송 가능한 NERF 편집을 가능하게합니다.최근 NERF 편집 파이프 라인은 2D 스타일을 3D 장면으로 들어 올리면서 흐릿한 결과를 겪고 2D 편집 사이의 불일치로 인한 상세 구조를 캡처하지 못합니다.우리의 중요한 통찰력은 이미지의 저주파 구성 요소가 고주파 부품에 비해 편집 후 다중보기 일관성이 있다는 것입니다.또한 외관 스타일은 주로 저주파 구성 요소에 전시되며 컨텐츠 세부 사항은 특히 고주파 부품에 있습니다.이는 저주파 구성 요소에 대한 편집을 수행하도록 동기를 부여하여 고 충실도 편집 장면을 초래합니다.또한 편집은 저주파 기능 공간에서 수행되므로 안정적인 강도 제어 및 새로운 장면 전송이 가능합니다.사진 데이터 세트에서 수행 된 포괄적 인 실험은 고 충실도 및 전송 가능한 NERF 편집의 우수한 성능을 보여줍니다.프로젝트 페이지는 \ url {this https url}에 있습니다.",2024.04.03,Yisheng He&&Weihao Yuan&&Siyu Zhu&&Zilong Dong&&Liefeng Bo&&Qixing Huang,arxiv,https://arxiv.org/abs/2404.02514
InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation,"튜닝이없는 확산 기반 모델은 이미지 개인화 및 사용자 정의 영역에서 상당한 잠재력을 보여주었습니다.그러나 이러한 주목할만한 진보에도 불구하고 현재 모델은 스타일 관련 이미지 생성을 생성하는 데 몇 가지 복잡한 과제를 계속해서 맞이합니다.첫째, 스타일의 개념은 본질적으로 소외되어 색상, 재료, 대기, 디자인 및 구조와 같은 다양한 요소를 포함합니다.둘째, 반전 기반 방법은 스타일의 저하가 발생하기 쉽고, 종종 세밀한 세부 사항이 상실됩니다.마지막으로, 어댑터 기반 접근법은 종종 스타일 강도와 텍스트 제어 성 사이의 균형을 달성하기 위해 각 기준 이미지에 대해 세심한 무게 튜닝이 필요합니다.이 논문에서 우리는 몇 가지 강력하지만 자주 간과되는 관찰을 조사하여 시작합니다.그런 다음 두 가지 주요 전략을 구현하여 이러한 문제를 해결하도록 설계된 프레임 워크 인 InstantStyle을 소개합니다. 1) 피처 공간 내에서 참조 이미지에서 스타일과 컨텐츠를 분리하는 간단한 메커니즘, 동일한 공간 내의 기능을 전제로합니다.서로 추가하거나 빼낼 수 있습니다.2) 참조 이미지의 주입은 독점적으로 스타일 특정 블록에만 주입하여 스타일 누출을 방지하고 더 많은 매개 변수가 많은 디자인을 특징 짓는 번거로운 무게 튜닝의 필요성을 방해합니다.스타일의 강도와 텍스트 요소의 제어 가능성.우리의 코드는 https url에서 사용할 수 있습니다.",2024.04.03,Haofan Wang&&Matteo Spinelli&&Qixun Wang&&Xu Bai&&Zekui Qin&&Anthony Chen,arxiv,https://arxiv.org/abs/2404.02733
Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models,"알고리즘 추론은 문제의 복잡한 패턴을 이해하고 솔루션을 향한 일련의 추론 단계로 분해하는 능력을 말합니다.알고리즘 추론의 이러한 특성은 다른 추론 과제에서 유망한 성능을 보여 주 었음에도 불구하고 대형 언어 모델 (LLM)에 어려움을 겪습니다.이러한 맥락에서, 최근의 일부 연구는 프로그래밍 언어 (예 : 파이썬)를 사용하여 엄격하고 정확한 구문에서 영감을 얻은 주어진 인스턴스/질문 (예 : 생각 프로그램)을 해결하는 데 필요한 논리를 표현합니다.그러나 단일 추론 호출 내에서 올바른 논리를 즉시 표현하는 실행 가능한 코드를 작성하는 것은 사소하지 않습니다.또한 인스턴스를 위해 특별히 생성 된 코드는 동일한 작업에서 발생하고 동일한 논리가 필요하더라도 다른 사람에게는 재사용 될 수 없습니다.이 논문은 언어 모델의 추론 과정을 두 단계로 분해하는 새로운 프레임 워크 인 Think-and-Execute를 제시합니다.(1) Think에서, 우리는 주어진 작업을 해결하기 위해 모든 사례에서 공유되는 작업 수준 논리를 발견 한 다음 Pseudocode로 논리를 표현합니다.(2) 실행에서, 우리는 생성 된 의사 코드를 각 인스턴스에 추가로 조정하고 코드의 실행을 시뮬레이션합니다.7 가지 알고리즘 추론 작업에 대한 광범위한 실험을 통해 생각과 실행의 효과를 보여줍니다.우리의 접근 방식은 인스턴스 별 추론 (예 : COT 및 POT)을 수행하는 몇 가지 강력한 기준선에 비해 LMS의 추론을 더 잘 향상시켜 작업 수준 논리를 발견하는 데 도움이됩니다.또한 자연 언어와 비교할 때 의사 코드는 자연어 지침을 따르도록 훈련을 받았음에도 불구하고 LMS의 추론을 더 잘 안내 할 수 있음을 보여줍니다.",2024.04.03,Hyungjoo Chae&&Yeonghyeon Kim&&Seungone Kim&&Kai Tzu-iunn Ong&&Beong-woo Kwak&&Moohyeon Kim&&Seonghwan Kim&&Taeyoon Kwon&&Jiwan Chung&&Youngjae Yu&&Jinyoung Yeo,arxiv,https://arxiv.org/abs/2404.02575
LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models,"인공 지능의 빠르게 진화하는 환경에서 멀티 모달 대형 언어 모델은 상당한 관심 분야로 떠오르고 있습니다.다양한 형태의 데이터 입력을 결합한이 모델이 점점 인기를 얻고 있습니다.그러나 내부 메커니즘을 이해하는 것은 여전히 복잡한 작업입니다.설명 도구와 메커니즘 분야에서 수많은 발전이 이루어졌지만 여전히 탐구해야 할 것이 많습니다.이 연구에서 우리는 대규모 시력 모델의 내부 메커니즘을 이해하기위한 새로운 대화식 응용 프로그램을 제시합니다.우리의 인터페이스는 답변을 생성하는 데 도움이되는 이미지 패치의 해석 가능성을 향상시키고 이미지의 출력을 접지시키는 데 언어 모델의 효능을 평가하도록 설계되었습니다.응용 프로그램을 통해 사용자는 시스템을 체계적으로 조사하고 시스템 제한을 발견하여 시스템 기능 향상을위한 길을 열 수 있습니다.마지막으로, 우리는 응용 프로그램이 인기있는 대형 멀티 모달 모델 인 Llava에서 실패 메커니즘을 이해하는 데 도움이 될 수있는 방법에 대한 사례 연구를 제시합니다.",2024.04.03,Gabriela Ben Melech Stan&&Raanan Yehezkel Rohekar&&Yaniv Gurwicz&&Matthew Lyle Olson&&Anahita Bhiwandiwalla&&Estelle Aflalo&&Chenfei Wu&&Nan Duan&&Shao-Yen Tseng&&Vasudev Lal,arxiv,https://arxiv.org/abs/2404.03118
ReFT: Representation Finetuning for Language Models,"매개 변수 효율적인 미세 조정 (PEFT) 메소드는 소수의 가중치에 대한 업데이트를 통해 대형 모델을 조정하려고합니다.그러나 많은 이전의 해석 가능성 작업에 따르면 표현이 풍부한 의미 정보를 인코딩하여 편집 표현이 더 강력한 대안 일 수 있음을 시사합니다.여기서, 우리는 \ textbf {expresionation finetuning (reft)} 방법의 가족을 개발 함으로써이 가설을 추구합니다.REFT 방법은 냉동 기본 모델에서 작동하며 숨겨진 표현에 대한 작업 별 중재를 학습합니다.우리는 REFT 패밀리, 저 순위 선형 하위 공간 REFT (loreft)의 강력한 인스턴스를 정의합니다.Loreft는 기존 PEFTS의 드롭 인 교체품이며 이전 최첨단 PEFT보다 매개 변수 효율적인 10x-50x 더 많은 중재를 배웁니다.우리는 8 개의 상식 추론 작업, 4 개의 산술 추론 작업, Alpaca-Eval v1.0 및 접착제에 대해 Loreft를 보여줍니다.이러한 모든 평가에서 Loreft는 효율성과 성능의 최고의 균형을 제공하며 거의 항상 최첨단 PEFT를 능가합니다.우리는이 HTTPS URL에 일반적인 REFT 교육 라이브러리를 공개적으로 출시합니다.",2024.04.04,Zhengxuan Wu&&Aryaman Arora&&Zheng Wang&&Atticus Geiger&&Dan Jurafsky&&Christopher D. Manning&&Christopher Potts,arxiv,https://arxiv.org/abs/2404.03592
MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens,"이 논문은 비디오 이해를 위해 특별히 설계된 멀티 모달 대형 언어 모델 (LLM) 인 Minigpt4-Video를 소개합니다.이 모델은 시간적 시각적 및 텍스트 데이터를 모두 처리 할 수있어 비디오의 복잡성을 이해하는 데 능숙합니다.시각적 기능을 단일 이미지를 위해 LLM 공간으로 번역하고 다양한 이미지 텍스트 벤치 마크에서 인상적인 결과를 얻은 Minigpt-V2의 성공을 바탕으로 모델의 기능을 확장하여 일련의 프레임을 처리 할 수 있습니다.비디오.Minigpt4-Video는 시각적 콘텐츠를 고려할뿐만 아니라 텍스트 대화를 통합하여 모델이 시각적 및 텍스트 구성 요소와 관련된 쿼리에 효과적으로 답변 할 수 있습니다.제안 된 모델은 기존 최첨단 방법을 능가하여 MSVD, MSRVTT, TGIF 및 TVQA 벤치 마크에서 각각 4.22%, 1.13%, 20.82%및 13.1%의 이득을 기록합니다.우리의 모델과 코드는 공개적으로 이용 가능했습니다 Herethis https url",2024.04.04,Kirolos Ataallah&&Xiaoqian Shen&&Eslam Abdelrahman&&Essam Sleiman&&Deyao Zhu&&Jian Ding&&Mohamed Elhoseiny,arxiv,https://arxiv.org/abs/2404.03413
Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?,"LLM (Led-Team Langues) 모델 (LLM)에 다양한 탈옥 공격이 제안되었으며 LLM의 취약한 보호 조치가 밝혀졌습니다.게다가, 일부 방법은 텍스트 양식에 국한되지 않으며 시각적 입력을 교란시켜 MLLM (Multimodal Lange Language Models)으로 탈옥 공격을 확장합니다.그러나 보편적 평가 벤치 마크가 없으면 성과 재생산과 공정한 비교가 복잡해집니다.게다가, SOTA (Stop-Source 최첨단) 모델, 특히 GPT-4V와 같은 MLLM에 대한 포괄적 인 평가가 부족합니다.이러한 문제를 해결하기 위해이 작업은 먼저 11 가지 안전 정책을 다루는 1445 개의 유해한 질문으로 포괄적 인 탈옥 평가 데이터 세트를 구축합니다.이 데이터 세트를 기반으로, SOTA 독점 모델 및 오픈 소스 모델을 포함하여 11 개의 서로 다른 LLM 및 MLLM에 대해 광범위한 빨간 팀 실험이 수행됩니다.그런 다음 평가 된 결과에 대한 깊은 분석을 수행하고 (1) GPT4 및 GPT-4V는 오픈 소스 LLM 및 MLLM에 비해 탈옥 공격에 대한 더 나은 견고성을 보여줍니다.(2) LLAMA2 및 Qwen-VL-Chat은 다른 오픈 소스 모델에 비해 더 강력합니다.(3) 시각적 탈옥 방법의 양도성은 텍스트 탈옥 방법에 비해 비교적 제한적입니다.데이터 세트와 코드는 여기에서 https://anonymous.4open.science/r/red_teaming_gpt4-c1ce/readme.md를 참조하십시오.",2024.04.04,Shuo Chen&&Zhen Han&&Bailan He&&Zifeng Ding&&Wenqian Yu&&Philip Torr&&Volker Tresp&&Jindong Gu,arxiv,https://arxiv.org/abs/2404.03411
AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent,"대형 언어 모델 (LLMS)은 웹 탐색과 같은 많은 지능형 에이전트 작업에 연료를 공급했지만 대부분의 기존 에이전트는 세 가지 요소로 인해 실제 웹 페이지에서 만족하는 것과는 거리가 멀다.HTML 텍스트는 모델 처리 용량을 초과하고 (3) 웹의 개방형 도메인 특성으로 인한 의사 결정의 복잡성.도전에 비추어, 우리는 ChatGLM3-6B에 구축 된 GPT-4 외식 자동 웹 내비게이션 에이전트 인 AutoweBGLM을 개발합니다.인간 브라우징 패턴에서 영감을 얻은 우리는 웹 페이지를 나타내는 HTML 단순화 알고리즘을 설계하여 중요한 정보를 간결하게 보존합니다.우리는 교과 과정 훈련을위한 웹 브라우징 데이터를 구축하기 위해 하이브리드 휴먼 -AI 방법을 사용합니다.그런 다음 강화 학습 및 거부 샘플링을 통해 모델을 부트 스트랩하여 웹 페이지 이해력, 브라우저 작업 및 효율적인 작업 분해를 더욱 촉진합니다.테스트를 위해 실제 웹 브라우징 작업을위한 이중 언어 벤치 마크 (Autowebbench)를 설정합니다.우리는 다양한 웹 내비게이션 벤치 마크에서 AutoweBGLM을 평가하여 개선 사항을 밝히고 실제 환경을 다루는 데 있어서도 근본적인 과제를 보여줍니다.관련 코드, 모델 및 데이터는 \ url {this https url}에서 릴리스됩니다.",2024.04.04,Hanyu Lai&&Xiao Liu&&Iat Long Iong&&Shuntian Yao&&Yuxuan Chen&&Pengbo Shen&&Hao Yu&&Hanchen Zhang&&Xiaohan Zhang&&Yuxiao Dong&&Jie Tang,arxiv,https://arxiv.org/abs/2404.03648
CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching,확산 모델은 텍스트-이미지 생성 분야에서 큰 성공을 보여주었습니다.그러나 텍스트 프롬프트와 이미지 사이의 오정렬을 완화하는 것은 여전히 어려운 일입니다.오정렬의 근본 원인은 광범위하게 조사되지 않았습니다.우리는 잘못 정렬이 부적절한 토큰주의 활성화로 인해 발생한다는 것을 관찰합니다.우리는이 현상을 확산 모델의 불충분 한 조건 활용에도 추가로 평가합니다. 이는 훈련 패러다임으로 인해 발생합니다.이 문제를 해결하기 위해 이미지-텍스트 개념 매칭 메커니즘을 사용하여 엔드 투 엔드 확산 모델 미세 조정 전략 인 Comat을 제안합니다.이미지 캡션 모델을 활용하여 이미지-텍스트 정렬을 측정하고 확산 모델을 안내하여 무시 된 토큰을 다시 방문합니다.속성 바인딩 문제를 해결하기 위해 새로운 속성 농도 모듈도 제안됩니다.이미지 또는 사람의 선호도 데이터가 없으면 20k 텍스트 프롬프트 만 사용하여 SDXL을 미세 조정하여 COMAT-SDXL을 얻습니다.광범위한 실험에 따르면 COMAT-SDXL은 두 개의 텍스트-이미지 정렬 벤치 마크에서 기준 모델 SDXL을 훨씬 능가하고 시작 성능을 달성합니다.,2024.04.04,Dongzhi Jiang&&Guanglu Song&&Xiaoshi Wu&&Renrui Zhang&&Dazhong Shen&&Zhuofan Zong&&Yu Liu&&Hongsheng Li,arxiv,https://arxiv.org/abs/2404.03653
Training LLMs over Neurally Compressed Text,"이 논문에서는 고도로 압축 된 텍스트에 대한 대형 언어 모델 (LLM)을 훈련한다는 아이디어를 탐구합니다.표준 서브 워드 토큰 화제는 작은 요인으로 텍스트를 압축하지만 신경 텍스트 압축기는 훨씬 더 높은 압축률을 달성 할 수 있습니다.신경 압축 텍스트를 통해 LLM을 직접 훈련 할 수 있다면, 이는 긴 텍스트 스팬을 쉽게 처리 할뿐만 아니라 훈련 및 서비스 효율성의 장점을 부여합니다.이 목표의 주요 장애물은 강한 압축이 학습에 적합하지 않은 불투명 출력을 생성하는 경향이 있다는 것입니다.특히, 우리는 산술 코딩을 통해 순진하게 압축 된 텍스트가 LLM에 의해 쉽게 학습 할 수 없다는 것을 알았습니다.이를 극복하기 위해, 우리는 텍스트가 각각 동일한 비트 길이로 압축하는 블록으로 분할되는 새로운 압축 기술 인 Equal-Info Windows를 제안합니다.이 방법을 사용하여, 우리는 규모로 향상되는 신경 압축 텍스트에 대한 효과적인 학습을 보여주고, 수신성 및 추론 속도 벤치 마크에 대한 넓은 마진으로 바이트 수준 기준선보다 성능이 우수합니다.우리의 방법은 동일한 매개 변수 수로 훈련 된 모델에 대한 서브 워드 토큰 화제보다 당황 스러움을 더 많이 제공하지만 서열 길이가 짧은 이점이 있습니다.시퀀스 길이가 짧 으면 자동 회귀 생성 단계가 적고 대기 시간이 줄어 듭니다.마지막으로, 우리는 학습성에 기여하는 속성에 대한 광범위한 분석을 제공하고, 고압 토큰 화제의 성능을 더욱 향상시키는 방법에 대한 구체적인 제안을 제공합니다.",2024.04.04,Brian Lester&&Jaehoon Lee&&Alex Alemi&&Jeffrey Pennington&&Adam Roberts&&Jascha Sohl-Dickstein&&Noah Constant,arxiv,https://arxiv.org/abs/2404.03626
RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis,"우리는 텍스트 음성 (TTS) 합성을위한 강력한 언어 모델링 방법 인 Rall-E를 제시합니다.LLMS (Largin Language Models)를 기반으로 한 이전 작업은 제로 샷 TT에 대한 인상적인 성능을 보여 주지만, 이러한 방법은 불안정한 프로디 (이상한 피치 및 리듬/지속 시간) 및 높은 워드 오류율 (WER)과 같은 강력한 견고성으로 어려움을 겪고 있습니다.자가 회귀 예측 스타일의 언어 모델로 인해.Rall-e의 핵심 아이디어는 COT (Chain-of-Ethought) 프롬프트이며,이 작업은 LLM 기반 TTS의 견고성을 향상시키기 위해 작업을 더 간단한 단계로 분해합니다.이 아이디어를 달성하기 위해 Rall-E First는 입력 텍스트의 Prosody 기능 (피치 및 지속 시간)을 예측하고 COT 스타일의 음성 토큰을 예측하기 위해 중간 조건으로 사용합니다.둘째, Rall-E는 음성 토큰을 예측할 때 해당 음운 및 프로 시저 기능에 중점을 두도록 변압기에서 자체 소지 중량의 컴퓨팅을 안내하기 위해 예측 된 지속 시간 프롬프트를 사용합니다.포괄적 인 목표 및 주관적 평가 결과 강력한 기준선 방법 Vall-E와 비교하여 Rall-E는 6.3 \%(재실행없이) 및 2.1 \%(재실행 포함)에서 제로 샷 TTS의 WER을 크게 향상 시킨다는 것을 보여줍니다.각각 22.8 \%및 1.0 \%.또한, 우리는 Rall-E가 Vall-e에 어려운 문장을 올바르게 합성하고 오류율을 68 \%to4 \%에서 감소 시킨다는 것을 보여줍니다.",2024.04.04,Detai Xin&&Xu Tan&&Kai Shen&&Zeqian Ju&&Dongchao Yang&&Yuancheng Wang&&Shinnosuke Takamichi&&Hiroshi Saruwatari&&Shujie Liu&&Jinyu Li&&Sheng Zhao,arxiv,https://arxiv.org/abs/2404.03204
PointInfinity: Resolution-Invariant Point Diffusion Models,"우리는 효율적인 포인트 구름 확산 모델 인 PointInfinity를 제시합니다.우리의 핵심 아이디어는 고정 크기의 해상도 불변의 잠재적 표현으로 변압기 기반 아키텍처를 사용하는 것입니다.이를 통해 저해상도 포인트 클라우드로 효율적인 훈련을 가능하게하면서 추론 중에 고해상도 포인트 구름이 생성 될 수 있습니다.더 중요한 것은 훈련 분해능을 넘어 테스트 시간 해상도를 스케일링하면 생성 된 포인트 구름과 표면의 충실도가 향상됨을 보여줍니다.우리는이 현상을 분석하고 확산 모델에서 일반적으로 사용되는 분류기가없는 지침에 대한 링크를 그려서 추론 중에 충실도와 변동성을 거래 할 수 있음을 보여줍니다.CO3D에 대한 실험은 PointInfinity가 최첨단 품질로 고해상도 포인트 구름 (최대 131k 포인트, Point-E보다 31 배)을 효율적으로 생성 할 수 있음을 보여줍니다.",2024.04.04,Zixuan Huang&&Justin Johnson&&Shoubhik Debnath&&James M. Rehg&&Chao-Yuan Wu,arxiv,https://arxiv.org/abs/2404.03566
CodeEditorBench: Evaluating Code Editing Capability of Large Language Models,"코드의 LLM (Large Language Models)은 빠르게 발전하고 있으며 코드 편집은 중요한 기능으로 나타납니다.우리는 디버깅, 번역, 연마 및 요구 사항 전환을 포함하여 코드 편집 작업에서 LLM의 성능을 엄격하게 평가하도록 설계된 평가 프레임 워크 인 CodeeditorBench를 소개합니다.코드 생성에만 초점을 둔 기존 벤치 마크와 달리 Codeeditorbench는 실제 시나리오와 소프트웨어 개발의 실질적인 측면을 강조합니다.다양한 프로그래밍 언어, 복잡성 수준 및 편집 작업을 다루는 5 가지 소스에서 다양한 코딩 문제와 시나리오를 선별합니다.19 개의 LLM의 평가에 따르면 폐쇄 소스 모델 (특히 Gemini-Ultra 및 GPT-4)은 CodeeditorBench의 오픈 소스 모델을 능가하여 문제 유형 및 신속한 감도에 따라 모델 성능의 차이를 강조합니다.CodeeditorBench는 코드 편집 기능을 평가하기위한 강력한 플랫폼을 제공하여 LLM의 발전을 촉진하는 것을 목표로합니다.커뮤니티가 데이터 세트를 확장하고 신흥 LLM을 벤치마킹 할 수 있도록 모든 프롬프트와 데이터 세트를 출시 할 것입니다.CodeeditorBench를 도입함으로써 우리는 코드 편집에서 LLM의 발전에 기여하고 연구원과 실무자에게 귀중한 자원을 제공합니다.",2024.04.04,Jiawei Guo&&Ziming Li&&Xueling Liu&&Kaijing Ma&&Tianyu Zheng&&Zhouliang Yu&&Ding Pan&&Yizhi LI&&Ruibo Liu&&Yue Wang&&Shuyue Guo&&Xingwei Qu&&Xiang Yue&&Ge Zhang&&Wenhu Chen&&Jie Fu,arxiv,https://arxiv.org/abs/2404.03543
Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences,"이 논문은 강력한 Oracle의 선호도 피드백을 사용하여 LLM (Lange Language Model)을 훈련시켜 모델이 반복적으로 개선되도록 도와줍니다.훈련 후 LLM에 대한 전형적인 접근법은 전통적으로 보상 학습과 후속 정책 최적화를 분리하는 인간 피드백 (RLHF)의 강화 학습을 포함합니다.그러나 이러한 보상 최대화 접근법은 복잡한 비정규 적 또는 주기적 선호 관계를 표현하지 못하는 ""포인트 현저한""보상 (예 : Bradley-Terry 모델)의 특성에 의해 제한됩니다.RLHF 쇼의 발전 보상 학습 및 정책 최적화는 안정성에 대한 단일 대조적 목표로 병합 될 수 있지만 여전히 보상 최대화 프레임 워크에 묶여 있습니다.최근에, 새로운 연구의 물결은 ""쌍별""또는 일반적인 선호도보다 직접 최적화하는 데 유리한 보상 최대화 추정을 회피합니다.이 백서에서는 일반적인 선호도를 최적화함으로써 이론적 인 일반성과 대조적 인 학습의 단순성과 안정성과 결혼 할 수 있고 확장 가능한 알고리즘 인 DNO (Direct Nash Optimization)를 소개합니다.DNO는 회귀 기반 목표를 사용하여 배치 된 정책 알고리즘이기 때문에 구현은 간단하고 효율적입니다.또한 DNO는 반복적으로 단조로운 개선을 즐기며 강력한 교사 (예 : GPT-4)에서도 개선하는 데 도움이됩니다.우리의 실험에서, DNO에 의해 정렬 된 결과 7b 매개 변수 ORCA-2.5 모델은 Alpacaeval 2.0에서 GPT-4 터보에 대한 최신 승리률을 달성합니다 (응답 길이를 제어 한 후에도)초기화 모델에 비해 26% (7% ~ 33%)의 이득.Mistral Large, Self-Rewarding LM (70b 매개 변수) 및 이전 버전의 GPT-4를 포함하여 훨씬 더 많은 매개 변수로 모델을 능가합니다.",2024.04.04,Corby Rosset&&Ching-An Cheng&&Arindam Mitra&&Michael Santacroce&&Ahmed Awadallah&&Tengyang Xie,arxiv,https://arxiv.org/abs/2404.03715
CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues,"지시 조정 데이터 세트의 최근 발전은 주로 수학적 또는 논리적 추론과 같은 특정 작업에 중점을두고 있습니다.대화의 주제 관련성을 유지하기 위해 언어 모델을 조정하기 위해 설계된 데이터에는 주목할만한 차이가있었습니다. 챗봇을 제작에 배치하는 데 중요한 측면입니다.우리는 언어 모델이 작업 중심 상호 작용 중에 당면한 주제에 집중할 수 있도록 CanttalkaboutThis DataSet을 소개합니다.그것은 다른 도메인의 광범위한 대화 주제에 대한 합성 대화로 구성됩니다.이 대화는 의도적으로 챗봇을 사전 정의 된 주제에서 전환시키는 산만 턴으로 산재합니다.이 데이터 세트의 미세 조정 언어 모델은 할당 된 역할을 수행하는 데 탄력적으로 만들어주고 GPT-4 터보 및 Mixtral-Intruct와 같은 일반 목적 교육 LLM에 비해 국소 일관성을 유지하는 능력을 향상시킵니다.또한, 예비 관찰은이 데이터 세트의 교육 모델도 세밀한 지시에 따라 작업에 대한 성능을 향상 시킨다고 제안합니다.",2024.04.04,Makesh Narsimhan Sreedhar&&Traian Rebedea&&Shaona Ghosh&&Christopher Parisien,arxiv,https://arxiv.org/abs/2404.03820
"No ""Zero-Shot"" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance","웹 크롤링 된 사전 조정 데이터 세트는 분류/검색 클립 및 이미지 생성에 대한 안정적인 확산과 같은 멀티 모달 모델의 인상적인 ""제로 샷""평가 성능에 기초합니다.그러나, ""제로 샷""일반화의 개념은 이러한 멀티 모달 모델에 대해 얼마나 의미가 없는지 불분명합니다. 예전의 데이터 세트가 ""제로 샷""평가 중에 타겟팅 된 다운 스트림 개념을 어느 정도까지 포함하는지 알려지지 않았기 때문입니다.이 작업에서 우리는 다음과 같이 묻습니다. 다운 스트림 개념에 대한 멀티 모달 모델의 성능은 전처리 데이터 세트에서 이러한 개념의 빈도에 영향을 받는가?300GB 이상의 데이터 아티팩트를 생성하는 34 개의 모델과 5 개의 표준 사전 계통 데이터 세트 (CC-3M, CC-12M, YFCC-15M, LAION-400M, LAION-ASSHETICS) 에서이 질문을 종합적으로 조사합니다.우리는 ""제로 샷""일반화를 나타내는 것 외에도, 멀티 모달 모델은 샘플 비효율적 인 로그 라이어 스케일링 경향에 따라 다운 스트림 ""제로 샷""성능의 선형 개선을 달성하기 위해 기하 급수적으로 더 많은 데이터가 필요하다는 것을 발견했습니다.이 추세는 사전 여과와 다운 스트림 데이터 세트 사이의 샘플 수준 유사성을 제어하고 순수 합성 데이터 분포에 대한 테스트를 제어 할 때에도 지속됩니다.또한, 분석을 바탕으로 샘플링 된 긴 꼬리 데이터의 벤치마킹 모델에 따라, 우리는 보드 전체의 멀티 모달 모델이 제대로 작동하지 않음을 보여줍니다.우리는이 긴 꼬리 테스트 세트를 ""Let it Wag!""로 기부합니다.이 방향으로의 추가 연구를위한 벤치 마크.종합하면, 우리의 연구는 대규모 훈련 패러다임 하에서 ""제로 샷""일반화 기능의 열쇠가 여전히 발견되어야한다는 것을 의미하는 교육 데이터에 대한 기하 급수적 인 필요성을 보여줍니다.",2024.04.04,Vishaal Udandarao&&Ameya Prabhu&&Adhiraj Ghosh&&Yash Sharma&&Philip H.S. Torr&&Adel Bibi&&Samuel Albanie&&Matthias Bethge,arxiv,https://arxiv.org/abs/2404.04125
Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model,"이 연구에서, 우리는 LLM을 개발할 때 중국어의 우선 순위를 정하는 데 대한 중추적 인 전환을 보여주는 2B 대형 언어 모델 (LLM) 인 CT-LLM을 소개합니다.CT-LLM은 처음부터 독창적으로 시작하여 주로 중국어 텍스트 데이터를 통합하여 기존의 방법론에서 발산되어 8 천억 개의 중국 토큰, 3 천억 개의 영어 토큰 및 1,000 억 코드 토큰을 포함하여 1,200 억 개의 토큰을 사용하여 중국어 텍스트 데이터를 주로 통합함으로써 기존의 방법론에서 분기됩니다.이 전략적 구성은 중국어를 이해하고 처리하는 데있어 모델의 탁월한 능력을 촉진하며, 정렬 기술을 통해 더욱 향상되었습니다.CT-LLM은 CHC- 벤치에서 놀라운 성능을 보여 주면서 중국어 작업에 탁월하며 SFT를 통해 영어로의 능력을 보여줍니다.이 연구는 영어 Corpora에서 LLM을 주로 훈련시키는 패러다임에 도전 한 다음 다른 언어에 적응하여 LLM 교육 방법론에 대한 지평을 넓히는 데 도전합니다.획득 한 대규모 적절한 전제 중국 코퍼스 (MAP-CC), 잘 선택된 다 분야 중국 하드 케이스 벤치 마크 (CHC- 벤치)를 포함한 세부 데이터 처리 절차를 포함하여 중국 LLM을 훈련시키는 전체 프로세스를 개방형 소싱함으로써2B 사이즈 중국 Tiny LLM (CT-LLM), 우리는 학계와 산업 모두에서 추가 탐사와 혁신을 촉진하여보다 포괄적이고 다재다능한 언어 모델을위한 길을 열어줍니다.",2024.04.05,Xinrun Du&&Zhouliang Yu&&Songyang Gao&&Ding Pan&&Yuyang Cheng&&Ziyang Ma&&Ruibin Yuan&&Xingwei Qu&&Jiaheng Liu&&Tianyu Zheng&&Xinchen Luo&&Guorui Zhou&&Binhang Yuan&&Wenhu Chen&&Jie Fu&&Ge Zhang,arxiv,https://arxiv.org/abs/2404.04167
Robust Gaussian Splatting,"이 논문에서는 핸드 헬드 전화 캡처의 재구성과 같은 실제 애플리케이션에 대한 견고성을 개선하기 위해 블러, 불완전한 카메라 포즈 및 색상 불일치를 포함하여 3D 가우시안 플래팅 (3DG)의 일반적인 오류 소스를 다룹니다.우리의 주요 기여는 카메라 포즈에 대한 가우시안 분포로 모션 블러를 모델링하는 것과 관련하여 카메라 포즈 세분화와 모션 블러 수정을 통합적인 방식으로 해결할 수 있습니다.또한, 우리는 Defocus 블러 보상 및 주변 조명, 그림자로 인한 색상의 컨텐츠 또는 다양한 흰색 밸런싱 설정과 같은 카메라 관련 요소로 인해 메커니즘을 제안합니다.우리의 제안 된 솔루션은 훈련 효율 및 렌더링 속도 측면에서 이점을 유지하면서 3DG 제제와 완벽한 방식으로 통합됩니다.우리는 Scannet ++ 및 DeBlur-Nerf를 포함한 관련 벤치 마크 데이터 세트에 대한 기여를 실험적으로 검증하여 최첨단 결과를 얻어 관련 기준선에 대한 일관된 개선을 실험적으로 검증합니다.",2024.04.05,François Darmon&&Lorenzo Porzi&&Samuel Rota-Bulò&&Peter Kontschieder,arxiv,https://arxiv.org/abs/2404.04211
Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation,"다중 모달 시맨틱 세분화는 특히 저조도 또는 과다 노출 된 환경과 같은 불리한 조건에서 AI 에이전트의 인식 및 장면 이해를 크게 향상시킵니다.기존 RGB와 함께 열 및 깊이와 같은 추가 양식 (x- 모형)을 활용하면 보완적인 정보가 제공되어보다 강력하고 신뢰할 수있는 세분화가 가능합니다.이 작업에서 우리는 선택적 구조화 된 상태 공간 모델 인 Mamba를 사용하여 멀티 모달 의미 론적 세분화를위한 시암 맘바 네트워크 인 Sigma를 소개합니다.제한된 로컬 수용 필드 또는 VITS (Vision Cleartive Fields)가 제한된 로컬 수용 필드 (VIT)를 사용하여 CNN에 의존하는 기존의 방법과 달리, 우리의 모델은 선형 복잡성으로 글로벌 수용 필드 커버리지를 달성합니다.시암 인코더를 사용하고 맘바 퓨전 메커니즘을 혁신함으로써, 우리는 다른 양식에서 필수 정보를 효과적으로 선택합니다.그런 다음 디코더가 모델의 채널 별 모델링 능력을 향상시키기 위해 개발됩니다.우리의 방법 인 Sigma는 RGB-thermal 및 RGB-Depth 세분화 작업 모두에서 엄격하게 평가되며, 그 우월성을 입증하고 다중 모드 인식 작업에서 State Space Model (SSM)의 첫 번째 성공적인 적용을 표시합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.04.05,Zifu Wan&&Yuhao Wang&&Silong Yong&&Pingping Zhang&&Simon Stepputtis&&Katia Sycara&&Yaqi Xie,arxiv,https://arxiv.org/abs/2404.04256
Social Skill Training with Large Language Models,사람들은 갈등 해결과 같은 사회적 기술에 의존하여 효과적으로 의사 소통하고 일과 개인 생활에서 번성합니다.그러나 사회 기술을위한 실습 환경은 일반적으로 대부분의 사람들에게 손이 닿지 않습니다.사회적 기술 훈련을보다 이용할 수 있고 접근 가능하며 초대 할 수있는 방법은 무엇입니까?커뮤니케이션 및 심리학의 학제 간 연구를 바탕 으로이 관점 논문은 특수 분야에 들어가는 사회적 기술 장벽을 식별합니다.그런 다음 일반적인 프레임 워크를 통해 소셜 기술 훈련을위한 큰 언어 모델을 활용하는 솔루션을 제시합니다.우리의 AI 파트너 인 AI 멘토 프레임 워크는 체험 학습을 현실적인 연습과 맞춤형 피드백과 병합합니다.이 작업은 궁극적으로 인력 개발 및 사회적 평등에 대한 광범위한 영향을 해결하기 위해 학제 간 혁신을 요구합니다.,2024.04.05,Diyi Yang&&Caleb Ziems&&William Held&&Omar Shaikh&&Michael S. Bernstein&&John Mitchell,arxiv,https://arxiv.org/abs/2404.04204
SpatialTracker: Tracking Any 2D Pixels in 3D Space,"비디오에서 조밀하고 장거리 픽셀 동작을 회복하는 것은 어려운 문제입니다.어려움의 일부는 3D-2D 프로젝션 프로세스에서 발생하여 2D 모션 도메인의 폐색 및 불연속으로 이어집니다.2D 모션은 복잡 할 수 있지만, 우리는 기본 3D 운동이 종종 단순하고 저 차원 일 수 있다고 주장합니다.이 작업에서는 이미지 투영으로 인한 문제를 완화하기 위해 3D 공간의 포인트 궤적을 추정 할 것을 제안합니다.SpatialTracker라는 우리의 방법은 단금 깊이 추정기를 사용하여 2D 픽셀을 3D로 들어 올리며 트리플란 표현을 사용하여 각 프레임의 3D 함량을 효율적으로 나타내며 변압기를 사용하여 3D 궤적을 추정하기 위해 반복 업데이트를 수행합니다.3D를 추적하면 ARAP (Rigid-As-Arsible) 제약 조건을 활용하는 동시에 픽셀을 다른 강성 부품으로 픽셀로 포함하는 강성 임베딩을 동시에 학습 할 수 있습니다.광범위한 평가에 따르면 우리의 접근 방식은 특히 평면 외 회전과 같은 도전적인 시나리오에서 질적 및 정량적으로 최첨단 추적 성능을 달성합니다.",2024.04.05,Yuxi Xiao&&Qianqian Wang&&Shangzhan Zhang&&Nan Xue&&Sida Peng&&Yujun Shen&&Xiaowei Zhou,arxiv,https://arxiv.org/abs/2404.04319
Koala: Key frame-conditioned long video-LLM,"긴 비디오 질문 답변은 단기 활동을 인식하고 세밀한 관계에 대한 추론을 포함하는 어려운 과제입니다.최첨단 비디오 대형 언어 모델 (VLLM)은 새로운 작업에 대한 출현 능력으로 인해 실행 가능한 솔루션으로 약속을 잡습니다.그러나 수백만 초 긴 비디오에 대한 교육을 받았음에도 불구하고 VLLM은 몇 분 길이의 비디오를 이해하고 이에 대한 질문에 정확하게 답변 할 수 없습니다.이 한계를 해결하기 위해, 우리는 더 긴 비디오를 일반화하기 위해 사전 각인 VLLM을 적응시키기 위해 학습 가능한 시공간의 쿼리를 소개하는 Key Frame Condited Long Video-LLM (Koala)을 소개하는 가볍고 자체 감독 된 접근법을 제안합니다.우리의 접근 방식은 짧고 긴 비디오 순간을 이해하기 위해 스파 스 비디오 키 프레임에서 계산 된 비주얼 토큰의 조건을 조정하는 두 개의 새로운 토큰 화기를 소개합니다.우리는 Howto100m에 대한 제안 된 접근 방식을 훈련시키고 장거리 비디오 이해 벤치 마크에 대한 효과를 보여줍니다. 여기서 모든 작업에서 최첨단 대형 모델을 3-6% 성능이 우수합니다.놀랍게도, 우리는 또한 우리의 접근 방식이 사전에 취한 VLLM이 긴 비디오를 이해하는 데 도움이 될뿐만 아니라 단기 행동 인식에 대한 정확성을 향상 시킨다는 것을 경험적으로 보여줍니다.",2024.04.05,Reuben Tan&&Ximeng Sun&&Ping Hu&&Jui-hsien Wang&&Hanieh Deilamsalehy&&Bryan A. Plummer&&Bryan Russell&&Kate Saenko,arxiv,https://arxiv.org/abs/2404.04346
PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations,"모델링 및 렌더링 사진 아바타는 많은 응용 분야에서 매우 중요합니다.그러나 시각적 관찰로부터 3D 아바타를 구축하는 기존의 방법은 옷을 입은 인간을 재구성하기 위해 고군분투합니다.우리는 역 렌더링과 역 물리학을 결합하여 복장 비디오 데이터와 의류 패브릭의 물리적 매개 변수와 함께 인간의 모양과 모양을 자동으로 추정하는 새로운 프레임 워크 인 Physavatar를 소개합니다.이를 위해, 본 발명자들은 공간 중심 메쉬 추적을위한 메쉬 정렬 4D 가우스 기술을 채택하여 물리적으로 기반 역 렌더러를 사용하여 고유 재료 특성을 추정합니다.Physavatar는 물리 시뮬레이터를 통합하여 구배 기반 최적화를 사용하여 원칙적으로 의류의 물리적 매개 변수를 추정합니다.이 새로운 기능을 통해 Physavatar는 훈련 데이터에서 볼 수없는 움직임 및 조명 조건에서 느슨한 옷을 입은 아바타의 고품질 소설 렌더링을 만들 수 있습니다.이는 루프에서 물리학과 물리 기반 역 렌더링을 사용하여 사진을 사용하여 사진을 찍는 디지털 인간을 모델링하는 데 큰 발전을 가져옵니다.프로젝트 웹 사이트는 다음과 같습니다.이 HTTPS URL",2024.04.05,Yang Zheng&&Qingqing Zhao&&Guandao Yang&&Wang Yifan&&Donglai Xiang&&Florian Dubost&&Dmitry Lagun&&Thabo Beeler&&Federico Tombari&&Leonidas Guibas&&Gordon Wetzstein,arxiv,https://arxiv.org/abs/2404.04421
Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models,"트랜스포머는 컴퓨터 비전 및 자연어 처리 (NLP) 분야의 발전을 촉진했습니다.그러나 상당한 계산 복잡성은 고해상도 이미지 생성과 같은 장기 텍스트 작업에서 응용 프로그램에 제한을 제기합니다.이 논문은 NLP에 사용 된 RWKV 모델에서 조정 된 일련의 아키텍처를 소개하며, 확산 RWKV라고하는 이미지 생성 작업에 적용되는 확산 모델에 맞게 조정 된 필수 수정이 있습니다.변압기와의 확산과 유사하게, 우리의 모델은 추가 조건으로 순서대로 패치 리화 된 입력을 효율적으로 처리하고 효과적으로 확장하여 대규모 매개 변수와 광범위한 데이터 세트를 모두 수용하도록 설계되었습니다.그것의 독특한 이점은 감소 된 공간 집계 복잡성에 나타나 고해상도 이미지를 처리하는 데 능숙하게 만들어 창 또는 그룹 캐시 된 작업의 필요성을 제거합니다.조건 및 무조건 이미지 생성 작업 모두에 대한 실험 결과는 Diffison-RWKV가 FID의 기존 CNN 또는 변압기 기반 확산 모델과 동등한 성능을 달성하거나 총체 계산 플롭 사용량을 크게 줄이는 동시에 성능을 달성합니다.",2024.04.06,Zhengcong Fei&&Mingyuan Fan&&Changqian Yu&&Debang Li&&Junshi Huang,arxiv,https://arxiv.org/abs/2404.04478
DATENeRF: Depth-Aware Text-based Editing of NeRFs,"확산 모델의 최근 발전은 텍스트 프롬프트를 기반으로 2D 이미지를 편집하는 데 놀라운 능력을 보여주었습니다.그러나 개별 2D 프레임을 편집하면 여러 뷰에서 불일치를 초래할 수 있으므로 이러한 기술을 신경 방사선 필드 (NERF)에서 편집하기 위해 이러한 기술을 확장하는 것은 복잡합니다.우리의 중요한 통찰력은 NERF 장면의 형상 이이 2D 편집을 통합하는 브리지 역할을 할 수 있다는 것입니다.이 형상을 사용하여 각 2D 이미지 수정의 일관성을 향상시키기 위해 깊이 조절 된 Controlnet을 사용합니다.또한, 우리는 NERF 장면의 깊이 정보를 활용하여 다른 이미지에 2D 편집을 배포하여 오류에 대한 견고성과 리샘플링 문제를 보장하는 인 페인팅 접근법을 소개합니다.우리의 결과는이 방법론이 텍스트 중심 NERF 장면 편집을위한 기존 주요 방법보다 더 일관되고 생생하고 세부적인 편집을 달성한다는 것을 보여줍니다.",2024.04.06,Sara Rojas&&Julien Philip&&Kai Zhang&&Sai Bi&&Fujun Luan&&Bernard Ghanem&&Kalyan Sunkavall,arxiv,https://arxiv.org/abs/2404.04526
Aligning Diffusion Models by Optimizing Human Utility,"우리는 예상되는 인간 유용성의 최대화로서 정렬 목표를 공식화함으로써 텍스트-이미지 확산 모델을 정렬하기위한 새로운 접근법 인 확산 -KTO를 제시한다.이 목표는 각 세대에 독립적으로 적용되므로 확산 -KTO는 비용이 많이 드는 쌍 선호도 데이터를 수집하거나 복잡한 보상 모델을 훈련시킬 필요가 없습니다.대신, 우리의 목표에는 간단한 이미지 당 이진 피드백 신호가 필요합니다 (예 :풍부하게 제공되는 좋아하거나 싫어하는 것.확산 -KTO를 사용한 미세 조정 후, 텍스트-이미지 확산 모델은 인간의 판단 및 PickScore 및 ImageRower와 같은 자동 평가 지표 모두에서 감독 된 미세 조정 및 확산 -DPO를 포함한 기존 기술에 비해 우수한 성능을 나타냅니다.전반적으로, 확산 -KTO는 쉽게 이용 가능한 이미지 별 이진 신호를 활용할 수있는 잠재력을 해제하고 텍스트-이미지 확산 모델을 인간 선호도와 정렬하는 적용 가능성을 확대합니다.",2024.04.06,Shufan Li&&Konstantinos Kallidromitis&&Akash Gokul&&Yusuke Kato&&Kazuki Kozuka,arxiv,https://arxiv.org/abs/2404.04465
BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion,"세부 사항과 컨트롤로 고해상도의 인간 중심 장면을 생성하는 것은 기존 텍스트-이미지 확산 모델에 대한 과제입니다.이 도전은 제한된 훈련 이미지 크기, 텍스트 인코더 용량 (제한된 토큰) 및 여러 인간과 관련된 복잡한 장면을 생성하는 고유의 어려움에서 비롯됩니다.현재의 방법은 훈련 크기 한계 만 해결하려고 시도했지만 종종 심각한 인공물로 인간 중심의 장면을 생성했습니다.우리는 이전 한계를 극복하는 새로운 프레임 워크 인 Beyondscene을 제안하고, 기존의 사전 여분의 확산 모델을 사용하여 탁월한 텍스트 이미지 통신 및 자연성을 가진 절묘한 고해상도 (8K 이상) 인간 중심 장면을 생성합니다.Beyondscene은 단계적이고 계층 적 접근 방식을 사용하여 처음에 여러 인간의 예를 들어 생성 및 확산 모델의 토큰 한계를 넘어서는 세부적인 설명에서 중요한 요소에 중점을 둔 상세한 기본 이미지를 생성 한 다음 기본 이미지를 더 높은 해상 출력으로 완벽하게 변환하여 초과이미지 크기를 훈련하고 세부 사항을 통합하여 우리의 새로운 인스턴스 인식 계층 적 확대 프로세스를 통한 텍스트와 인스턴스를 통합하여 제안 된 고주파 전방 확산 및 적응 형 조인트 확산으로 구성됩니다.이후 세부는 상세한 텍스트 설명 및 자연과의 대응 측면에서 기존의 방법을 능가하며, 고도의 재교육이 비싼 재교육없이 고해상도의 인간 중심 장면 생성에서 고급 응용 프로그램의 길을 열어줍니다.프로젝트 페이지 :이 HTTPS URL.",2024.04.06,Gwanghyun Kim&&Hayeon Kim&&Hoigi Seo&&Dong Un Kang&&Se Young Chun,arxiv,https://arxiv.org/abs/2404.04544
"ByteEdit: Boost, Comply and Accelerate Generative Image Editing","확산 기반 생성 이미지 편집의 최근 발전은 심오한 혁명을 일으켜 이미지가 돋보이는 작업의 풍경을 재구성하고 작업을 수행했습니다.이러한 보폭에도 불구하고, 현장은 다음을 포함하여 고유 한 도전에 맞서지 않는다. i) 열등한 품질;ii) 일관성 불량;iii) 불충분 한 도구 준수;iv) 차선의 생성 효율성.이러한 장애물을 해결하기 위해, 우리는 Byteedit, 혁신적인 피드백 학습 프레임 워크 인 Byteedit를 생성 된 이미지 편집 작업을 강화, 준수 및 가속화하도록 세 심하게 설계되었습니다.Byteedit는 미학 및 이미지 텍스트 정렬을 향상시키는 데 전념하는 이미지 보상 모델을 완벽하게 통합하는 한편 출력의 일관성을 높이기 위해 조정 된 조밀 한 픽셀 레벨 보상 모델을 도입합니다.또한, 우리는 모델의 추론 속도를 신속하게하기 위해 선구적인 적대 및 진보적 인 피드백 학습 전략을 제안합니다.광범위한 대규모 사용자 평가를 통해 Byteedit은 Adobe, Canva 및 Meitu를 포함한 주요 생성 이미지 편집 제품을 세대 품질과 일관성 모두에서 능가한다는 것을 보여줍니다.ByteeDit-outpainting은 기준선 모델과 비교할 때 각각 품질 및 일관성이 각각 388% 및 135%의 놀라운 향상을 나타냅니다.실험은 또한 우리의 가속 모델이 품질과 일관성 측면에서 우수한 성능 결과를 유지한다는 사실을 알게되었습니다.",2024.04.07,Yuxi Ren&&Jie Wu&&Yanzuo Lu&&Huafeng Kuang&&Xin Xia&&Xionghui Wang&&Qianqian Wang&&Yixing Zhu&&Pan Xie&&Shiyin Wang&&Xuefeng Xiao&&Yitong Wang&&Min Zheng&&Lean Fu,arxiv,https://arxiv.org/abs/2404.04860
MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators,"T2V (Text-to-Video Generation)의 최근 발전은 텍스트 설명에서 고품질 일반 비디오를 종합하는 데 놀라운 성공을 거두었습니다.T2V에서 크게 간과 된 문제는 기존 모델이 실제 세계에 대한 물리적 지식을 적절하게 인코딩하지 않았으므로 생성 된 비디오는 움직임이 제한되고 변동이 제한적인 경향이 있다는 것입니다.이 논문에서는 시간 경과 비디오에서 실제 물리 지식을 배우고 변성 생성을 구현하는 변성 시간 경과 비디오 생성 모델 인 \ textbf {Magictime}을 제안합니다.먼저, 공간 및 시간 훈련을 해체하고, 변성 비디오에서 더 많은 물리적 지식을 인코딩하고, 미리 훈련 된 T2V 모델을 변환하여 변성 비디오를 생성하기위한 MagicAdapter 체계를 설계합니다.둘째, 우리는 변형 범위가 더 넓고 극적인 물체 변성 프로세스를 다루는 변성 시간 경과 비디오에 적응하기 위해 동적 프레임 추출 전략을 소개하여 일반 비디오보다 더 많은 물리적 지식을 구현합니다.마지막으로, 우리는 변성 비디오 프롬프트에 대한 이해를 향상시키기 위해 마술 텍스트 인코더를 소개합니다.또한, 우리는 \ textbf {chronomagic}이라는 타임 랩스 비디오 텍스트 데이터 세트를 만듭니다.광범위한 실험은 고품질의 역동적 인 변성 비디오를 생성하기위한 Magictime의 우수성과 효과를 보여줍니다. 시간 경과 비디오 생성은 물리적 세계의 변성 시뮬레이터를 구축하는 유망한 경로임을 시사합니다.",2024.04.07,Shenghai Yuan&&Jinfa Huang&&Yujun Shi&&Yongqi Xu&&Ruijie Zhu&&Bin Lin&&Xinhua Cheng&&Li Yuan&&Jiebo Luo,arxiv,https://arxiv.org/abs/2404.05014
MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation,"이 백서에서는 MOMA를 제시합니다 : 유연한 제로 샷 기능을 자랑하는 개방형 변형, 훈련이없는 개인화 된 이미지 모델을 제시합니다.기초 텍스트-이미지 모델이 빠르게 발전함에 따라 강력한 이미지-이미지 번역에 대한 수요가 증가합니다.이러한 요구를 해결하여 MOMA는 주제 중심의 개인화 된 이미지 생성을 전문으로합니다.Open-Source, Multimodal Lange Language Model (MLLM)을 사용하여 MOMA는 기능 추출기 및 발전기로 이중 역할을 수행하도록 훈련시킵니다.이 접근법은 참조 이미지 및 텍스트 프롬프트 정보를 효과적으로 상승하여 귀중한 이미지 기능을 생성하여 이미지 확산 모델을 용이하게합니다.생성 된 기능을 더 잘 활용하기 위해 이미지 기능을 이미지 확산 모델로 효율적으로 전송하여 생성 된 이미지에서 대상 객체의 유사성을 향상시키는 새로운 자체 변환 단축키 방법을 추가로 소개합니다.놀랍게도, 튜닝이없는 플러그 앤 플레이 모듈로서, 우리의 모델은 단일 참조 이미지 만 필요하며, 세부적인 충실도, 향상된 아이덴티티 보존 및 신실함을 가진 이미지를 생성 할 때 기존 메소드를 능가합니다.우리의 작업은 오픈 소스이므로 이러한 발전에 대한 보편적 인 접근을 제공합니다.",2024.04.08,Kunpeng Song&&Yizhe Zhu&&Bingchen Liu&&Qing Yan&&Ahmed Elgammal&&Xiao Yang,arxiv,https://arxiv.org/abs/2404.05674
SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing,"개인 콘텐츠의 효과적인 편집은 개인이 창의성을 표현하고 시각적 이야기 내에서 사로화하는 이야기를 직조하고 시각적 컨텐츠의 전반적인 품질과 영향을 높이는 데 중추적 인 역할을합니다.따라서이 작업에서 우리는 컨텍스트를 변경하지 않고 참조에 의해 주어진 개인화 된 개념으로 이미지의 객체를 스왑 할 수있는 새로운 프레임 워크 인 Swapanything을 소개합니다.Swapanything은 (1) 주요 주제가 아닌 임의의 대상 및 부품의 정확한 제어, (2) 문맥 픽셀의 더 충실한 보존, (3) 개인화 된 개념의 더 나은 적응이미지에.먼저, 우리는 TARBONTED 변수 교환을 제안합니다. 우리는 충실한 맥락 보존 및 초기 시맨틱 개념 교환을 위해 잠재 기능 맵 및 마스크 된 변수를 스왑 마스크 변수에 대한 지역 제어를 적용하기 위해 대상 변수 스왑을 제안합니다.그런 다음 이미지 생성 프로세스 중에 대상 위치, 모양, 스타일 및 내용 측면에서 시맨틱 개념을 원본 이미지에 원래 이미지로 원래 이미지에 원활하게 조정하여 모양 적응을 도입합니다.인간 및 자동 평가에 대한 광범위한 결과는 개인화 된 스왑에 대한 기준선 방법에 대한 접근 방식의 상당한 개선을 보여줍니다.또한 Swapanything은 단일 객체, 다중 객체, 부분 객체 및 크로스 도메인 교환 작업에서 정확하고 충실한 교환 능력을 보여줍니다.Swapanything은 텍스트 기반 스와핑 및 객체 삽입과 같은 스와핑 이외의 작업에서 큰 성능을 달성합니다.",2024.04.08,Jing Gu&&Yilin Wang&&Nanxuan Zhao&&Wei Xiong&&Qing Liu&&Zhifei Zhang&&He Zhang&&Jianming Zhang&&HyunJoon Jung&&Xin Eric Wang,arxiv,https://arxiv.org/abs/2404.05717
Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs,"멀티 모달 대형 언어 모델 (MLLM)의 최근 발전은 주목할 만하지 않았지만, 이러한 일반 도메인 MLLM은 종종 사용자 인터페이스 (UI) 화면과 효과적으로 이해하고 상호 작용할 수있는 능력이 부족합니다.이 논문에서는 참조, 접지 및 추론 능력이 장착 된 모바일 UI 화면에 대한 이해를 높이기 위해 새로운 MLLM 인 Ferret-UI를 제시합니다.UI 스크린은 일반적으로 더 길쭉한 종횡비를 나타내고 자연 이미지보다 작은 관심 객체 (예 : 아이콘, 텍스트)를 포함한다는 점을 감안할 때, 우리는 흰 족제비 위에 ""모든 해상도""를 통합하여 세부 사항을 확대하고 향상된 시각적 기능을 활용합니다.구체적으로, 각 스크린은 원래 종횡비 (예 : 초상화 스크린의 수평 구분 및 조경 스크린의 수직 분할)를 기반으로 2 개의 하위 이미지로 나뉩니다.두 하위 이미지는 LLM으로 보내기 전에 별도로 인코딩됩니다.우리는 아이콘 인식, 텍스트 찾기 및 위젯 목록과 같은 광범위한 기본 UI 작업에서 교육 샘플을 세 심하게 수집합니다.이 샘플은 정확한 참조 및 접지를 용이하게하기 위해 영역 주석으로 명령을 따르는 것을 위해 형식화됩니다.모델의 추론 능력을 강화하기 위해 자세한 설명, 인식/상호 작용 대화 및 기능 추론을 포함하여 고급 작업을위한 데이터 세트를 추가로 컴파일합니다.선별 된 데이터 세트에 대한 교육 후 Ferret-UI는 UI 화면의 뛰어난 이해력과 개방형 지침을 실행하는 기능을 보여줍니다.모델 평가를 위해, 우리는 위에서 언급 한 모든 작업을 포괄하는 포괄적 인 벤치 마크를 설정합니다.Ferret-UI는 대부분의 오픈 소스 UI MLLM을 넘어선뿐만 아니라 모든 기본 UI 작업에서 GPT-4V를 능가합니다.",2024.04.08,Keen You&&Haotian Zhang&&Eldon Schoop&&Floris Weers&&Amanda Swearngin&&Jeffrey Nichols&&Yinfei Yang&&Zhe Gan,arxiv,https://arxiv.org/abs/2404.05719
YaART: Yet Another ART Rendering Technology,"빠르게 진행되는 생성 모델의 분야에서 효율적이고 고유 한 텍스트-이미지 확산 시스템의 개발은 중요한 프론티어를 나타냅니다.이 연구는 인간 피드백 (RLHF)의 강화 학습을 사용하여 인간 선호도에 정렬 된 새로운 생산 등급 텍스트-이미지 Cascaded 확산 모델 인 Yaart를 소개합니다.Yaart가 개발하는 동안 특히 모델 및 교육 데이터 세트 크기의 선택에 중점을 둡니다. 이전에 텍스트-이미지 계단식 확산 모델에 대해 체계적으로 조사되지 않은 측면.특히, 우리는 이러한 선택이 훈련 프로세스의 효율성과 생성 된 이미지의 품질에 어떤 영향을 미치는지 종합적으로 분석합니다.또한, 우리는 고품질 이미지의 소규모 데이터 세트에 대한 교육을받은 모델이 더 큰 데이터 세트에 대한 교육을받은 모델과 성공적으로 경쟁하여 확산 모델 교육의보다 효율적인 시나리오를 설정할 수 있음을 보여줍니다.품질 관점에서 Yaart는 기존의 많은 최첨단 모델보다 사용자가 지속적으로 선호합니다.",2024.04.08,Sergey Kastryulin&&Artem Konev&&Alexander Shishenya&&Eugene Lyapustin&&Artem Khurshudov&&Alexander Tselousov&&Nikita Vinokurov&&Denis Kuznedelev&&Alexander Markovich&&Grigoriy Livshits&&Alexey Kirillov&&Anastasiia Tabisheva&&Liubov Chubarova&&Marina Kaminskaia&&Alexander Ustyuzhanin&&Artemii Shvetsov&&Daniil Shlenskii&&Valerii Startsev&&Dmitrii Kornilov&&Mikhail Romanov&&Artem Babenko&&Sergei Ovcharenko&&Valentin Khrulkov,arxiv,https://arxiv.org/abs/2404.05666
MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding,"LLM (Large Language Model)의 성공으로 비전 모델을 LLM에 통합하여 Vision-Language Foundation 모델을 구축하는 것이 최근에 훨씬 더 많은 관심을 끌었습니다.그러나 기존의 LLM 기반의 대형 멀티 모드 모델 (예 : 비디오 롤라, 비디오 캣)은 짧은 비디오 이해를 위해 제한된 수의 프레임 만 사용할 수 있습니다.이 연구에서 우리는 주로 장기 비디오 이해를위한 효율적이고 효과적인 모델을 설계하는 데 중점을 둡니다.대부분의 기존 작업과 같이 더 많은 프레임을 동시에 처리하려고 시도하는 대신 온라인 방식으로 비디오를 처리하고 메모리 뱅크에 과거 비디오 정보를 저장할 것을 제안합니다.이를 통해 우리의 모델은 LLMS의 컨텍스트 길이 제약 조건 또는 GPU 메모리 한계를 초과하지 않고 장기 분석을 위해 과거 비디오 컨텐츠를 참조 할 수 있습니다.우리의 메모리 뱅크는 상용으로 현재의 멀티 모달 LLM에 완벽하게 통합 될 수 있습니다.우리는 장기 비디오 이해, 비디오 질문 응답 및 비디오 캡션과 같은 다양한 비디오 이해 작업에 대한 광범위한 실험을 수행하며, 모델은 여러 데이터 세트에서 최첨단 공연을 달성 할 수 있습니다.https url에서 사용 가능한 코드.",2024.04.08,Bo He&&Hengduo Li&&Young Kyun Jang&&Menglin Jia&&Xuefei Cao&&Ashish Shah&&Abhinav Shrivastava&&Ser-Nam Lim,arxiv,https://arxiv.org/abs/2404.05726
UniFL: Improve Stable Diffusion via Unified Feedback Learning,"확산 모델은 이미지 생성 분야에 혁명을 일으켜 고품질 모델의 확산과 다양한 다운 스트림 애플리케이션을 이끌어 냈습니다.그러나 이러한 상당한 발전에도 불구하고 현재 경쟁 솔루션은 여전히 시각적 품질이 열등한, 미적 매력 부족 및 포괄적 인 솔루션없이 비효율적 인 추론을 포함한 몇 가지 한계를 겪고 있습니다.이러한 과제를 해결하기 위해, 우리는 피드백 학습을 활용하여 확산 모델을 포괄적으로 향상시키는 통합 프레임 워크 인 UNIFL을 제시합니다.UNIFL은 SD1.5 및 SDXL과 같은 다양한 확산 모델에 적용 할 수있는 보편적이고 효과적이며 일반화 가능한 솔루션으로 두드러집니다.특히 UNIFL은 세 가지 주요 구성 요소를 통합합니다. 시각적 품질을 향상시키는 지각 피드백 학습;미적 호소력을 향상시키는 분리 된 피드백 학습;그리고 추론 속도를 최적화하는 적대적 피드백 학습.심층 실험과 광범위한 사용자 연구는 생성 된 모델의 품질과 가속도를 모두 향상시키는 제안 된 방법의 우수한 성능을 검증합니다.예를 들어, UNIFL은 생성 품질 측면에서 17%의 사용자 선호도를 능가하고 LCM 및 SDXL Turbo보다 4 단계 추론에서 57% 및 20%를 능가합니다.또한 Lora, Controlnet 및 Animatediff를 포함한 다운 스트림 작업에서 접근 방식의 효능을 확인했습니다.",2024.04.08,Jiacheng Zhang&&Jie Wu&&Yuxi Ren&&Xin Xia&&Huafeng Kuang&&Pan Xie&&Jiashi Li&&Xuefeng Xiao&&Weilin Huang&&Min Zheng&&Lean Fu&&Guanbin Li,arxiv,https://arxiv.org/abs/2404.05595
CodecLM: Aligning Language Models with Tailored Synthetic Data,"명령 튜닝은 LLMS (Lange Language Models)를 특정 작업 명령어와 정렬하는 열쇠로 나타 났으며, 따라서 다음 토닉 예측 목표와 사용자의 실제 목표 사이의 불일치를 완화시킵니다.인간이 데이터를 수집하거나 주석을 달기위한 노동 및 시간 비용을 줄이기 위해 연구원들은 LLM의 사용을 탐색하여 교육 정렬 합성 데이터를 생성하기 시작합니다.최근의 연구는 다양한 지침을 생성하고 LLM을 적용하여 교육 복잡성을 높이고 종종 다운 스트림 사용 사례를 무시하는 데 중점을 둡니다.다른 대상 명령 분포 및 LLM에서 더 나은 명령어를 따르는 능력을 이끌어 내기 위해 고품질 데이터를 조정하는 방법은 확실하지 않습니다.이를 위해, 우리는 다른 다운 스트림 명령 분포 및 LLM과 LLM 정렬에 대한 고품질 합성 데이터를 적응 적으로 생성하기위한 일반적인 프레임 워크 인 CodeClm을 소개합니다.Encode-Decode 원칙을 바탕으로 LLM을 코덱으로 사용하여 데이터 생성 프로세스를 안내합니다.먼저 시드 명령어를 메타 데이터로 인코딩하는데, 이는 대상 명령 분포를 캡처하기 위해 온라인으로 생성 된 간결한 키워드 인 다음 메타 데이터를 디코딩하여 맞춤형 명령어를 작성합니다.또한 데이터 효율적인 샘플을 조정하기 위해 디코딩 중에 자기 흡기와 대조 필터링을 도입합니다.벤치 마크에 따른 4 개의 오픈 도메인 교육에 대한 광범위한 실험은 현재 최첨단 예술가에 대한 CodeClm의 효과를 검증합니다.",2024.04.08,Zifeng Wang&&Chun-Liang Li&&Vincent Perot&&Long T. Le&&Jin Miao&&Zizhao Zhang&&Chen-Yu Lee&&Tomas Pfister,arxiv,https://arxiv.org/abs/2404.05875
SambaLingo: Teaching Large Language Models New Languages,"LLM의 광범위한 가용성에도 불구하고 다양한 언어에 걸쳐 능력과 가용성에 상당한 격차가 남아 있습니다.이러한 문제를 해결하기위한 한 가지 방법은 기존 미리 훈련 된 LLM을 취하고 새로운 언어로 계속 훈련하는 것입니다.이전 작품은 언어 적응을 실험했지만 모범 사례 및 방법론에 관한 많은 질문이 다루어지지 않았습니다.이 논문에서는 LLM을 새로운 언어에 적응시키는 것에 대한 포괄적 인 조사를 제시합니다.우리의 연구는 어휘 확장, 직접 선호도 최적화 및 저주적 언어의 인간 정렬에 대한 데이터 부족 문제를 포함 하여이 프로세스의 주요 구성 요소를 다룹니다.우리는이 실험을 9 개의 언어와 2 개의 매개 변수 척도 (7b 및 70b)에 걸쳐 확장합니다.우리는 우리의 모델을 LLAMA 2, AYA-101, XGLM, Bloom 및 기존 언어 전문가와 비교하여 이전에 게시 된 모든 기준선을 능가합니다.또한 모든 평가 코드 및 체크 포인트는 향후 연구를 촉진하기 위해 공개됩니다.",2024.04.08,Zoltan Csaki&&Bo Li&&Jonathan Li&&Qiantong Xu&&Pian Pawakapan&&Leon Zhang&&Yun Du&&Hengyu Zhao&&Changran Hu&&Urmish Thakker,arxiv,https://arxiv.org/abs/2404.05829
Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence,우리는 RWKV (RWKV-4) 아키텍처에서 개선 된 시퀀스 모델 인 Eagle (RWKV-5) 및 Finch (RWKV-6)를 제시합니다.우리의 건축 설계 발전에는 다중 머리 매트릭스 값 상태와 RNN의 추론 효율 특성을 유지하면서 표현성을 향상시키는 동적 재발 메커니즘이 포함됩니다.우리는 1.12 조 토큰과 강화 된 다국어를위한 탐욕스러운 매칭을 기반으로 한 빠른 토큰 화기를 가진 새로운 다국어 코퍼스를 소개합니다.우리는 0.46 ~ 75 억 파라미터의 4 개의 Eagle 모델과 1.6 및 31 억 매개 변수의 2 개의 Finch 모델을 훈련 시켰으며 다양한 벤치 마크에서 경쟁력있는 성능을 달성한다는 것을 발견했습니다.Apache 2.0 라이센스에 따라 Huggingface의 모든 모델을 출시합니다.모델 :이 https urltraining code at :이 https urlinference 코드 at :이 https urltime-parallel training code at :이 https url,2024.04.08,Bo Peng&&Daniel Goldstein&&Quentin Anthony&&Alon Albalak&&Eric Alcaide&&Stella Biderman&&Eugene Cheah&&Xingjian Du&&Teddy Ferdinan&&Haowen Hou&&Przemysław Kazienko&&Kranthi Kiran GV&&Jan Kocoń&&Bartłomiej Koptyra&&Satyapriya Krishna&&Ronald McClelland Jr.&&Niklas Muennighoff&&Fares Obeid&&Atsushi Saito&&Guangyu Song&&Haoqin Tu&&Stanisław Woźniak&&Ruichong Zhang&&Bingchen Zhao&&Qihang Zhao&&Peng Zhou&&Jian Zhu&&Rui-Jie Zhu,arxiv,https://arxiv.org/abs/2404.05892
WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents,"웹 에이전트 연구 영역에서 일반화와 정확성을 모두 달성하는 것은 여전히 어려운 문제입니다.웹 사이트 구조의 높은 차이로 인해 기존 접근법이 종종 실패합니다.또한 기존의 미세 조정 및 텍스트 내 학습 기술은 여러 웹 사이트에서 일반화되지 않습니다.우리는 Wilbur를 소개합니다. Wilbur는 차별화 가능한 순위 모델과 새로운 명령 합성 기술을 사용하여 이전 실행의 작업 데모와 함께 블랙 박스 대형 언어 모델의 프롬프트를 최적으로 채우는 접근 방식을 소개합니다.엔드 투 엔드 성공률을 극대화하기 위해 실수를 배우고 회복하는 지능형 역 추적 메커니즘도 제안합니다.마지막으로, 우리는 순위 모델이 LLM의 대표적 목표를 샘플링하고 에이전트를 실행하고 수동 주석이 없어서 자동으로 평가하는 생성 자동 교과 과정의 데이터에 대해 교육을받을 수 있음을 보여줍니다.Wilbur는 WebVoyager 벤치 마크에서 최첨단 결과를 달성하여 텍스트 전용 모델을 전체 8%, 특정 웹 사이트에서 최대 36%를 꺾었습니다.동일한 벤치 마크에서 Wilbur는 텍스트 입력 만 수신 되었음에도 불구하고 강력한 멀티 모달 모델의 5% 이내에 있으며, 추가 분석에 따르면 상당수의 실패는 웹 작동의 엔지니어링 문제로 인한 것입니다.",2024.04.08,Michael Lutz&&Arth Bohra&&Manvel Saroyan&&Artem Harutyunyan&&Giovanni Campagna,arxiv,https://arxiv.org/abs/2404.05902
Hash3D: Training-free Acceleration for 3D Generation,"3D 생성 모델링의 진화는 2D 확산 모델의 채택에 의해 현저히 추진되어왔다.이러한 진보에도 불구하고, 성가신 최적화 프로세스 자체는 효율성에 중요한 장애물을 나타냅니다.이 논문에서는 모델 교육없이 3D 세대를위한 범용 가속 인 Hash3d를 소개합니다.HASH3D의 중심은 카메라 위치에서 렌더링 된 이미지와 근접성에서 확산 시간 단계에서 피처 맵 중복성이 널리 퍼져 있다는 통찰력입니다.주변 타임 스펙 및 카메라 각도에서 이러한 기능 맵을 효과적으로 해시하고 재사용함으로써 Hash3D는 중복 계산을 실질적으로 방지하여 3D 세대 작업에서 확산 모델의 추론을 가속화합니다.우리는 적응 형 그리드 기반 해싱을 통해이를 달성합니다.놀랍게도,이 기능 공유 메커니즘은 생성 속도를 높일뿐만 아니라 합성 된 3D 객체의 부드러운 일관성을 향상시키고 일관성을 강화합니다.5 개의 텍스트-3D 및 3 개의 이미지-3D 모델을 다루는 실험은 최적화 속도를 높이고 효율성을 1.3 ~ 4 배 향상시키는 HASH3D의 다목적 성을 보여줍니다.또한 HASH3D와 3D 가우시안 플래팅과의 통합은 3D 모델 생성 속도를 높이고 텍스트-3D 처리를 약 10 분으로 줄이고 이미지-3D 변환을 약 30 초로 줄입니다.프로젝트 페이지는이 https url입니다.",2024.04.09,Xingyi Yang&&Xinchao Wang,arxiv,https://arxiv.org/abs/2404.06091
MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies,"최대 10 조의 매개 변수로 대형 언어 모델 (LLM) 개발에 대한 급격한 관심은 자원 효율성과 실질 비용에 관한 우려와 관련이 있습니다.이 시나리오는 소규모 언어 모델 (SLMS)의 잠재력을 자원 효율적인 대안으로 탐색하는 것의 중요성을 강조합니다.이러한 맥락에서, 우리는 MINICPM, 특히 1.2B 및 2.4B 비 에비 딩 매개 변수 변형을 소개하며, 각 범주에서 탁월 할뿐만 아니라 7B-13B LLMS와 동등한 기능을 보여줍니다.SLM에 중점을 두면서 우리의 접근 방식은 미래의 LLM 연구를위한 모델 및 데이터 차원 모두에서 확장 성을 나타냅니다.모델 스케일링과 관련하여, 우리는 안정적이고 최적의 스케일링을 위해 광범위한 모델 풍동 실험을 사용합니다.데이터 스케일링의 경우, 지속적인 교육 및 도메인 적응에 도움이되는 WARMUP-STABLE-DECAY (WSD) 학습 속도 스케줄러 (LRS)를 소개합니다.우리는 WSD LRS에서 발생한 흥미로운 훈련 역학에 대한 심층 분석을 제시합니다.WSD LRS를 사용하면 모델과 데이터 축에 대한 광범위한 재교육 실험없이 데이터 모델 스케일링 법을 효율적으로 연구 할 수 있습니다. 여기서 Chinchilla 최적보다 훨씬 높은 컴퓨팅 최적의 데이터 모델 비율을 도출합니다.또한, 우리는 MINICPM-DPO, MINICPM-MOE 및 MINICPM-128K를 포함한 MINICPM 패밀리를 소개합니다.MinICPM 모델은 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.09,Shengding Hu&&Yuge Tu&&Xu Han&&Chaoqun He&&Ganqu Cui&&Xiang Long&&Zhi Zheng&&Yewei Fang&&Yuxiang Huang&&Weilin Zhao&&Xinrong Zhang&&Zheng Leng Thai&&Kaihuo Zhang&&Chongyi Wang&&Yuan Yao&&Chenyang Zhao&&Jie Zhou&&Jie Cai&&Zhongwu Zhai&&Ning Ding&&Chao Jia&&Guoyang Zeng&&Dahai Li&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.06395
Reconstructing Hand-Held Objects in 3D,"손에 의해 조작 된 물체 (즉, Manipulanda)는 특히 야생 RGB 이미지 나 비디오에서 재구성하기가 어렵습니다.손은 객체의 대부분을 막을뿐만 아니라 물체는 종종 소수의 이미지 픽셀에서만 볼 수 있습니다.동시에이 설정에서 두 개의 강한 앵커가 나타납니다. (1) 3D 손이 물체의 위치와 스케일을 명확하게하는 데 도움이되며 (2) Manipulanda 세트는 가능한 모든 물체에 비해 작습니다.이러한 통찰력을 염두에두고, 우리는 큰 언어/비전 모델 및 3D 객체 데이터 세트의 최근 혁신을 바탕으로 핸드 헬드 객체 재구성을위한 확장 가능한 패러다임을 제시합니다.우리의 모델 MCC-Hand-Bobject (MCC-HO)는 단일 RGB 이미지와 3D 핸드를 입력으로 유추하여 손과 물체 구조를 공동으로 재구성합니다.그 후, 우리는 GPT-4 (v)를 사용하여 이미지의 객체와 일치하는 3D 객체 모델을 검색하고 모델을 네트워크에 인출 된 지오메트리에 엄격하게 정렬합니다.우리는이 정렬 검색 재구성 재구성 (RAR)이라고합니다.실험에 따르면 MCC-HO는 실험실 및 인터넷 데이터 세트에서 최첨단 성능을 달성하고 RAR을 사용하여 손으로 객체 상호 작용의 야만적 인 이미지에 대한 3D 레이블을 자동으로 얻는 방법을 보여줍니다.",2024.04.09,Jane Wu&&Georgios Pavlakos&&Georgia Gkioxari&&Jitendra Malik,arxiv,https://arxiv.org/abs/2404.06507
MuPT: A Generative Symbolic Music Pretrained Transformer,"이 논문에서는 음악의 사전 훈련에 대형 언어 모델 (LLM)의 적용을 탐구합니다.음악 모델링에서 MIDI의 일반적인 사용은 잘 확립되어 있지만, 우리의 연구 결과는 LLM이 본질적으로 ABC 표기법과 더 호환되며, 이는 디자인 및 강점과 더 밀접하게 일치하여 음악 구성에서 모델의 성능을 향상시킵니다.세대 동안 다른 트랙의 잘못 정렬 된 측정과 관련된 과제를 해결하기 위해 여러 음악적 트랙에서 일관성을 보존하는 것을 목표로하는 동기화 된 멀티 트랙 ABC 표기법 (SMT-ABC 표기법)의 개발을 제안합니다.우리의 기여에는 최대 8192 개의 토큰을 처리 할 수있는 일련의 모델이 포함되어 있으며 교육 세트에서 상징적 인 음악 데이터의 90%를 차지합니다.또한, 우리는 모델 성능에 대한 상징적 음악 스케일링 법 (SMS Law)의 의미를 탐구합니다.결과는 음악 생성에 대한 미래의 연구를위한 유망한 방향을 나타냅니다. 공개 소스 기여를 통해 커뮤니티 주도 연구를위한 광범위한 자원을 제공합니다.",2024.04.09,Xingwei Qu&&Yuelin Bai&&Yinghao Ma&&Ziya Zhou&&Ka Man Lo&&Jiaheng Liu&&Ruibin Yuan&&Lejun Min&&Xueling Liu&&Tianyu Zhang&&Xinrun Du&&Shuyue Guo&&Yiming Liang&&Yizhi Li&&Shangda Wu&&Junting Zhou&&Tianyu Zheng&&Ziyang Ma&&Fengze Han&&Wei Xue&&Gus Xia&&Emmanouil Benetos&&Xiang Yue&&Chenghua Lin&&Xu Tan&&Stephen W. Huang&&Wenhu Chen&&Jie Fu&&Ge Zhang,arxiv,https://arxiv.org/abs/2404.06393
InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD,"LVLM (Large Vision-Language Model) 분야는 상당한 발전을 보였지만 제한된 해상도로 인해 세밀한 시각적 컨텐츠를 이해하는 데 어려움을 겪었습니다.최근의 노력은 LVLM의 고해상도 이해 기능을 향상시키기위한 노력을 기울 였지만 약 1500 x 1500 픽셀에 캡핑되어 상대적으로 좁은 해상도 범위로 제한됩니다.이 논문은 최대 4K HD (3840 x 1600) 이상의 LVLM 해상도 기능을 높이기위한 획기적인 탐사 인 Internlm-Xcomposer2-4KHD를 나타냅니다.동시에 모든 시나리오에서 초고 해상도가 필요하지 않을 수 있다는 점을 고려할 때 336 픽셀에서 4K 표준까지 다양한 해상도를 지원하여 적용 범위를 크게 확장시킵니다.구체적으로,이 연구는 자동 패치 구성을 통한 새로운 확장 : 동적 해상도를 도입하여 패치 디비전 패러다임을 발전시킵니다.훈련 이미지 종횡비를 유지하는 반면, 패치 카운트가 자동으로 변경되고 미리 훈련 된 비전 변압기 (VIT) (336 x 336)를 기반으로 레이아웃을 구성하여 336 픽셀에서 4K 표준으로 동적 훈련 해상도를 초래합니다.우리의 연구는 최대 4K HD까지 훈련 해상도를 스케일링하면 잠재적 인 개선의 천장에 도달하지 않고 일관된 성능 향상으로 이어집니다.Internlm-Xcomposer2-4KHD는 16 개의 벤치 마크 중 10 개에서 GPT-4V 및 Gemini Pro와 일치하거나 능가하는 훌륭한 기능을 보여줍니다.7B 매개 변수가있는 Internlm-Xcomposer2-4KHD 모델 시리즈는 HTTPS URL에서 공개적으로 사용할 수 있습니다.",2024.04.09,Xiaoyi Dong&&Pan Zhang&&Yuhang Zang&&Yuhang Cao&&Bin Wang&&Linke Ouyang&&Songyang Zhang&&Haodong Duan&&Wenwei Zhang&&Yining Li&&Hang Yan&&Yang Gao&&Zhe Chen&&Xinyue Zhang&&Wei Li&&Jingwen Li&&Wenhai Wang&&Kai Chen&&Conghui He&&Xingcheng Zhang&&Jifeng Dai&&Yu Qiao&&Dahua Lin&&Jiaqi Wang,arxiv,https://arxiv.org/abs/2404.06512
LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders,"LLM (Large Decoder 전용 언어 모델)은 오늘날의 NLP 작업 및 벤치 마크의 대부분의 최신 모델입니다.그러나 커뮤니티는 텍스트 임베딩 작업을 위해 이러한 모델을 천천히 채택하고 있으며, 이는 풍부한 상황에 맞는 표현이 필요합니다.이 작업에서는 디코더 전용 LLM을 강력한 텍스트 인코더로 변환 할 수있는 단순한 감독 접근법 인 LLM2VEC를 소개합니다.LLM2VEC는 세 가지 간단한 단계로 구성됩니다. 1) 양방향주의 가능성, 2) 다음 토큰 예측, 3) 감독되지 않은 대조 학습.우리는 1.3b ~ 7b 매개 변수 범위의 3 가지 인기있는 LLM에 적용하여 LLM2VEC의 효과를 보여주고 영어 단어 및 시퀀스 수준 작업에서 변환 된 모델을 평가합니다.우리는 단어 수준 작업에 큰 마진으로 인코더 전용 모델을 능가하고 대규모 텍스트 임베드 벤치 마크 (MTEB)에서 감독되지 않은 최신 성능에 도달합니다.또한, LLM2VEC와 감독 된 대조 학습을 결합 할 때, 우리는 공개적으로 이용 가능한 데이터 만 훈련하는 모델 중에서 MTEB에 대한 최첨단 성과를 달성합니다.우리의 강력한 경험적 결과와 광범위한 분석은 값 비싼 적응 또는 합성 GPT-4 생성 데이터의 필요없이 LLM이 매개 변수 효율적인 방식으로 범용 텍스트 인코더로 효과적으로 변환 될 수 있음을 보여줍니다.",2024.04.09,Parishad BehnamGhader&&Vaibhav Adlakha&&Marius Mosbach&&Dzmitry Bahdanau&&Nicolas Chapados&&Siva Reddy,arxiv,https://arxiv.org/abs/2404.05961
OmniFusion Technical Report,"작년에 멀티 모달 아키텍처는 AI 기반 접근 방식 및 솔루션에서 혁명을 일으켜 LLM (Lange Language Models)의 기능을 확장했습니다.시각적 양식을위한 사전 간 LLM과 어댑터를 기반으로 \ textit {omnifusion} 모델을 제안합니다.우리는 더 나은 텍스트 및 시각적 데이터 커플 링 (MLP 및 변압기 어댑터), 다양한 클립 VIT 기반 인코더 (SIGLIP, InternVit 등) 및 퓨즈 접근 방식, 이미지 인코딩 방법 (전체 이미지 또는 타일 인코딩) 및 2 개의 7B LLM (독점 및 오픈 소스 미스트랄).8 개의 시각적 언어 벤치 마크에 대한 실험은 Open-Source Llava와 같은 솔루션과 비교하여 다양한 VQA 작업과 관련하여 최고의 전능 설정 설정의 최고 점수를 보여줍니다 : Vizwiz, Pope, MM-Vet, Scienceqa, Mmbench, TextVQA, VQAV2, MMMU.또한 Omnifusion은 가정용, 관광, 문화, 의약품, 필기 및 스캔 방정식 인식 등 다양한 영역에서 고도로 분해 된 답변을 제공하는 다양한 상황을 제안합니다. Mistral 기반의 전능 행사 모델은 가중치, 교육을 가진 오픈 소스 솔루션입니다.이 HTTPS URL에서 사용 가능한 추론 스크립트.",2024.04.09,Elizaveta Goncharova&&Anton Razzhigaev&&Matvey Mikhalchuk&&Maxim Kurkin&&Irina Abdullaeva&&Matvey Skripkin&&Ivan Oseledets&&Denis Dimitrov&&Andrey Kuznetsov,arxiv,https://arxiv.org/abs/2404.06212
Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion,"2D 확산 모델의 빠른 발전으로 인해 3D 컨텐츠 제작은 최근 상당한 진전을 이루었습니다.유망한 솔루션 중 하나는 미리 훈련 된 2D 확산 모델의 미세 조정을 포함하여 멀티 뷰 이미지를 생성하기위한 용량을 활용하며, 이는 Fast-Nerfs 또는 대규모 재구성 모델과 같은 방법을 통해 정확한 3D 모델로 들어 올립니다.그러나 불일치가 여전히 존재하고 생성 된 해상도가 제한되어 있기 때문에 이러한 방법의 생성 결과는 여전히 복잡한 질감과 복잡한 형상이 부족합니다.이 문제를 해결하기 위해 간단한 SDS 최적화 (\ sim15min)를 통해 거친 생성 결과를 크게 개선하는 멀티 뷰 조절 확산 모델 인 Magic-Boost를 제안합니다.이전 텍스트 또는 단일 이미지 기반 확산 모델과 비교하여 Magic-Boost는 의사 합성 다중 뷰 이미지로부터 높은 일관성을 가진 이미지를 생성 할 수있는 강력한 기능을 보여줍니다.입력 이미지의 ID와 잘 맞는 정확한 SDS 지침을 제공하여 초기 생성 결과의 형상 및 질감 모두에서 로컬 세부 사항을 풍부하게합니다.광범위한 실험에 따르면 Magic-Boost는 거친 입력을 크게 향상시키고 풍부한 기하학적 및 조직적 세부 사항을 가진 고품질 3D 자산을 생성합니다.(프로젝트 페이지 :이 https url)",2024.04.09,Fan Yang&&Jianfeng Zhang&&Yichun Shi&&Bowen Chen&&Chenxu Zhang&&Huichao Zhang&&Xiaofeng Yang&&Jiashi Feng&&Guosheng Lin,arxiv,https://arxiv.org/abs/2404.06429
Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models,"많은 사람들이 다양한 작업 세트에 LLM (Lange Language Model)을 적용 할 수있는 방법을 보여 주었지만 데이터 오염 및 암기의 중요한 문제는 종종 광택이 발생합니다.이 작업에서 우리는 표식 데이터에 대한이 문제를 해결합니다.구체적으로, 우리는 언어 모델이 훈련 중에 표 데이터 세트를 보았는지 여부를 평가하기 위해 다양한 다양한 기술을 소개합니다.이 조사에 따르면 LLM은 많은 대중적인 표준 데이터 세트가 구두로 암기했음을 보여줍니다.그런 다음 훈련 중에 보이는 데이터 세트에서 LLM의 소수의 학습 성능을 교육 후 출시 된 데이터 세트의 성능에 비교합니다.우리는 훈련 중에 보이는 데이터 세트에서 LLM이 더 잘 수행되며, 이는 암기가 과결을 일으킨다는 것을 나타냅니다.동시에 LLM은 새로운 데이터 세트에서 사소한 성능을 보여 주며 놀랍게도 데이터 변환에 강력합니다.그런 다음 LLM의 텍스트 내 통계 학습 능력을 조사합니다.미세 조정 없이는 제한적이라고 생각합니다.이것은 새로운 데이터 세트에서 소수의 성능이 LLM의 세계 지식 때문이라는 것을 시사합니다.전반적으로, 우리의 결과는 LLM이 사전 훈련 중에 평가 데이터 세트를 보았는지 여부를 테스트하는 것의 중요성을 강조합니다.우리는 우리가 개발 한 노출 테스트를 https url에서 tabmemcheck python 패키지로 사용할 수 있도록합니다.",2024.04.09,Sebastian Bordt&&Harsha Nori&&Vanessa Rodrigues&&Besmira Nushi&&Rich Caruana,arxiv,https://arxiv.org/abs/2404.06209
Revising Densification in Gaussian Splatting,"이 논문에서, 우리는 3D 가우시안 스플릿 (3DG)에서 적응 밀도 제어 (ADC)의 한계를 다룬다.ADC는 자동 3D 포인트 원시 관리, 밀도 화 및 가지 치열 제어를 위해 도입되었지만 밀도 로직의 특정 제한 사항이 있습니다.우리의 주요 기여는 3DG의 밀도 제어를위한보다 원칙적인 픽셀-오류 구동 공식화이며, 픽셀 당 오차 기능을 밀도의 기준으로 활용합니다.또한 장면 당 생성 된 총 프리미티브 수를 제어하는 메커니즘을 도입하고 클로닝 작업 중에 ADC의 현재 불투명도 처리 전략에서 편향을 수정합니다.우리의 접근 방식은 방법의 효율성을 희생하지 않고 다양한 벤치 마크 장면에서 일관된 품질 향상으로 이어집니다.",2024.04.09,Samuel Rota Bulò&&Lorenzo Porzi&&Peter Kontschieder,arxiv,https://arxiv.org/abs/2404.06109
RULER: What's the Real Context Size of Your Long-Context Language Models?,"긴 산만 텍스트 ( ""Haystack"")에서 정보 ( ""바늘"")를 검색하는 능력을 조사하는 Beless-in-A-Haystack (NIAH) 테스트는 장거리 텍스트 언어를 평가하기 위해 널리 채택되었습니다.모델 (LMS).그러나이 간단한 검색 기반 테스트는 피상적 인 형태의 장기 텍스트 이해만을 나타냅니다.장기 텍스트 LMS에 대한보다 포괄적 인 평가를 제공하기 위해 맞춤형 시퀀스 길이 및 작업 복잡성을위한 유연한 구성을 가진 새로운 합성 벤치 마크 규칙을 만듭니다.통치자는 바닐라 Niah 테스트를 확장하여 다양한 유형과 양의 바늘을 가진 변형을 포함합니다.또한 Ruler는 컨텍스트에서 검색을 넘어서 행동을 테스트하기 위해 새로운 작업 카테고리 멀티 홉 추적 및 집계를 소개합니다.우리는 통치자에 13 개의 대표적인 작업이있는 10 개의 장거리 LM을 평가합니다.바닐라 NIAH 테스트에서 거의 완벽한 정확도를 달성하더라도 모든 모델은 컨텍스트 길이가 증가함에 따라 큰 성능 감소를 나타냅니다.이 모델들은 모두 32k 토큰 이상의 컨텍스트 크기를 주장하지만 4 개의 모델 (GPT-4, Command-R, Yi-34B 및 Mixtral) 만 32k 길이의 만족스러운 성능을 유지할 수 있습니다.컨텍스트 길이 200k를 지원하는 Yi-34B에 대한 우리의 분석은 입력 길이와 작업 복잡성을 증가시킬 때 개선의 넓은 공간을 보여줍니다.우리는 오픈 소스 통치자가 장기 텍스트 LMS의 포괄적 인 평가를 박차 를가합니다.",2024.04.09,Cheng-Ping Hsieh&&Simeng Sun&&Samuel Kriman&&Shantanu Acharya&&Dima Rekesh&&Fei Jia&&Yang Zhang&&Boris Ginsburg,arxiv,https://arxiv.org/abs/2404.06654
Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior,"Text-to-3D Generation은 대규모 텍스트-이미지 확산 모델을 통해 놀라운 성공을 거두었습니다.그럼에도 불구하고, 방법론을 도시 규모로 확장하는 패러다임은 없습니다.수많은 요소, 복잡한 배열 관계 및 광대 한 규모로 특징 지어진 도시 장면은 효과적인 모델 최적화를위한 모호한 텍스트 설명의 해석 가능성에 대한 강력한 장벽을 제시합니다.이 작업에서, 우리는 추가 사전으로 작용하여 작곡 3D 레이아웃 표현을 텍스트-3D 패러다임에 도입하여 한계를 극복합니다.그것은 단순한 기하학적 구조와 명백한 배열 관계를 갖는 의미 론적 프리미티브 세트로 구성되어 텍스트 설명을 보완하고 조향 가능한 생성을 가능하게합니다.이에 따라, 우리는 두 가지 수정을 제안합니다. (1) 모델 최적화 부적합을 해결하기 위해 레이아웃 유도 변형 점수 증류를 도입합니다.3D 레이아웃의 기하학적 및 시맨틱 제약 조건으로 점수 증류 샘플링 프로세스를 조정합니다.(2) 도시 장면의 무한한 특성을 처리하기 위해, 우리는 확장 가능한 해시 그리드 구조로 3D 장면을 나타내며, 도시 장면의 규모가 점점 점진적으로 적응됩니다.광범위한 실험은 우리의 프레임 워크가 처음으로 1000m 이상의 운전 거리를 차지하는 대규모 도시 장면으로 텍스트-3D 세대를 확장하는 프레임 워크의 기능을 입증합니다.우리는 또한 다양한 장면 편집 데모를 제시하여 조향 가능한 도시 장면 생성의 힘을 보여줍니다.웹 사이트 :이 https url.",2024.04.10,Fan Lu&&Kwan-Yee Lin&&Yan Xu&&Hongsheng Li&&Guang Chen&&Changjun Jiang,arxiv,https://arxiv.org/abs/2404.06780
Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention,"이 작업은 트랜스포머 기반 대형 언어 모델 (LLM)을 제한된 메모리 및 계산으로 무한대 입력으로 확장하는 효율적인 방법을 도입합니다.제안 된 접근 방식의 핵심 요소는 인피니트 (Infini-Attention)라는 새로운주의 기술입니다.Infini-Intention은 압축 메모리를 바닐라주의 메커니즘에 통합하고 단일 변압기 블록에서 마스크 된 로컬주의 및 장기 선형주의 메커니즘을 모두 구축합니다.우리는 장거리 텍스트 언어 모델링 벤치 마크, 1M 시퀀스 길이 패스 키 컨텍스트 블록 검색 및 1B 및 8B LLM을 갖춘 500K 길이의 책 요약 작업에 대한 접근 방식의 효과를 보여줍니다.우리의 접근 방식은 최소한의 경계 메모리 매개 변수를 소개하고 LLM에 대한 빠른 스트리밍 추론을 가능하게합니다.",2024.04.10,Tsendsuren Munkhdalai&&Manaal Faruqui&&Siddharth Gopal,arxiv,https://arxiv.org/abs/2404.07143
RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion,"우리는 텍스트 설명에서 일반적인 전진 3D 장면을 생성하는 기술인 Realmdreamer를 소개합니다.우리의 기술은 복잡한 텍스트 프롬프트와 일치하도록 3D 가우시안 플래팅 표현을 최적화합니다.최첨단 텍스트-이미지 생성기를 사용하여 샘플을 3D로 들어 올리고 폐색 볼륨을 계산하여 이러한 Splats를 초기화합니다.그런 다음 이미지 조건 확산 모델을 사용한 3D 인 페인팅 작업으로 여러 뷰 에서이 표현을 최적화합니다.올바른 기하학적 구조를 배우기 위해, 우리는 인화 모델의 샘플에 컨디셔닝하여 깊이 확산 모델을 통합하여 풍부한 기하학적 구조를 제공합니다.마지막으로, 이미지 생성기의 날카로운 샘플을 사용하여 모델을 정합합니다.특히, 우리의 기술은 비디오 또는 멀티 뷰 데이터가 필요하지 않으며 여러 객체로 구성된 다양한 스타일의 다양한 고품질 3D 장면을 종합 할 수 있습니다.일반성은 추가로 단일 이미지에서 3D 합성을 허용합니다.",2024.04.10,Jaidev Shriram&&Alex Trevithick&&Lingjie Liu&&Ravi Ramamoorthi,arxiv,https://arxiv.org/abs/2404.07199
BRAVE: Broadening the visual encoding of vision-language models,"VLM (Vision-Language Models)은 일반적으로 비전 인코더로 구성됩니다 (예 :클립 및 인코딩 된 기능을 해석하여 다운 스트림 작업을 해결하는 언어 모델 (LM).놀라운 진보에도 불구하고 VLM은 비전 인코더의 제한된 기능으로 인해 몇 가지 단점이 있습니다 (예 :특정 이미지 기능, 시각적 환각 등에 대한 ""실명"". 이러한 문제를 해결하기 위해 VLM의 시각적 인코딩 기능을 넓히는 것을 연구합니다.우리는 먼저 VLM 작업을 해결하기 위해 다른 유도 편향을 가진 여러 비전 인코더를 포괄적으로 벤치마킹합니다.우리는 다른 작업에서 일관되게 최고의 성능을 달성하는 단일 인코딩 구성이 없으며, 다른 바이어스를 가진 인코더는 놀랍게도 유사하게 수행 할 수 있음을 관찰합니다.이에 의해 동기를 부여하면서, 우리는 Brave라는 이름의 방법을 소개하여 여러 냉동 인코더의 기능을 냉동 LM에 입력으로 직접 공급할 수있는보다 다재다능한 표현으로 통합됩니다.Brave는 광범위한 캡션 및 VQA 벤치 마크에서 최첨단 성능을 달성하고 위에서 언급 한 VLM의 문제를 크게 줄이며 기존 방법보다 더 적은 수의 훈련 가능한 매개 변수를 요구하고보다 압축 된 표현을 갖습니다.우리의 결과는 VLM에 대한보다 광범위하고 상황에 맞는 시각적 이해를 위해 다른 시각적 편향을 통합 할 수있는 잠재력을 강조합니다.",2024.04.10,Oğuzhan Fatih Kar&&Alessio Tonioni&&Petra Poklukar&&Achin Kulshrestha&&Amir Zamir&&Federico Tombari,arxiv,https://arxiv.org/abs/2404.07204
Adapting LLaMA Decoder to Vision Transformer,"이 연구는 원래 LLM (Lange Language Models) 용으로 설계된 LLAMA와 같은 디코더 전용 변압기가 컴퓨터 비전 분야에 적응할 수 있는지 여부를 조사합니다.우리는 먼저 Llama의 건축과 일치하는 표준 VIT 단계별 단계별 ""Llamafy""를 ""llamafy""하고, 자체 소지에 캐주얼 마스크를 직접 적용하면주의 붕괴 문제가 발생하여 네트워크 교육에 실패합니다.우리는이 도전을 극복하기 위해 시퀀스 후 클래스 토큰 기술로 이미지 토큰 뒤에있는 클래스 토큰을 재배치하여 인과 적자 변환이 전체 이미지의 정보를 효율적으로 캡처 할 수 있도록하는 것이 좋습니다.또한, 우리는 최적화 동작을 촉진하기 위해 훈련을 시작할 때 자체 변환에 대한 캐주얼 마스크를 점차적으로 도입하는 소프트 마스크 전략을 개발합니다.Image Llama (Illama)로 불리는 맞춤형 모델은 건축의 라마와 유사하며 직접적인 감독 학습을 가능하게합니다.인과 적자 변환은 계산 효율성을 높이고주의지도 순위를 높여 복잡한 표현을 배웁니다.Illama는 인코더 전용 대응 자로 성능을 발휘하여 5.7m 매개 변수로 75.1% Imagenet Top-1 정확도를 달성합니다.모델을 ~ 310m로 확장하고 ImageNet-21K에서 사전 훈련하면 정확도가 86.0%로 향상됩니다.광범위한 실험은 캘리브레이션, 모양-텍스처 바이어스, 양자화 호환성, ADE20K 세분화 및 CIFAR 전송 학습과 같은 Illama의 신뢰할 수있는 특성을 보여줍니다.우리는 우리의 연구가 LLM의 물결에서 시각적 모델 디자인에 대한 새로운 견해를 만들 수 있기를 바랍니다.미리 훈련 된 모델과 코드는 여기에서 제공됩니다.",2024.04.10,Jiahao Wang&&Wenqi Shao&&Mengzhao Chen&&Chengyue Wu&&Yong Liu&&Kaipeng Zhang&&Songyang Zhang&&Kai Chen&&Ping Luo,arxiv,https://arxiv.org/abs/2404.06773
DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting,"가상 현실 애플리케이션에 대한 수요가 증가함에 따라 몰입 형 3D 자산을 제작하는 것의 중요성을 강조했습니다.우리는 몇 분 안에 야만적 인 환경을위한 포괄적 인 360^{\ circ} 장면의 생성을 용이하게하는 텍스트-3d 360^{\ circ} 장면 생성 파이프 라인을 제시합니다.우리의 접근 방식은 2D 확산 모델의 생성력을 활용하고 자체 반영을 자극하여 고품질의 전 세계적으로 일관된 파노라마 이미지를 만듭니다.이 이미지는 예비 ""플랫""(2d) 장면 표현 역할을합니다.그 후, 그것은 실시간 탐색을 가능하게하기 위해 3D 가우시안으로 들어 올려 진 3D 가우시안으로 들어 올려집니다.일관된 3D 지오메트리를 생성하기 위해, 파이프 라인은 2D 단안 깊이를 전 세계적으로 최적화 된 포인트 클라우드에 정렬하여 공간적으로 일관된 구조를 구성합니다.이 지점 클라우드는 3D 가우스의 중심의 초기 상태 역할을합니다.단일 뷰 입력에 내재 된 보이지 않는 문제를 해결하기 위해 정규화로 합성 및 입력 카메라보기에 시맨틱 및 기하학적 제약을 부과합니다.이들은 가우시안의 최적화를 안내하며 보이지 않는 지역의 재건을 돕습니다.요약하면, 우리의 방법은 360^{\ circ} 관점 내에서 전 세계적으로 일관된 3D 장면을 제공하여 기존 기술에 비해 강화 된 몰입 형 경험을 제공합니다.프로젝트 웹 사이트 :이 HTTP URL",2024.04.10,Shijie Zhou&&Zhiwen Fan&&Dejia Xu&&Haoran Chang&&Pradyumna Chari&&Tejas Bharadwaj&&Suya You&&Zhangyang Wang&&Achuta Kadambi,arxiv,https://arxiv.org/abs/2404.06903
ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback,"텍스트-이미지 확산 모델의 제어 가능성을 향상시키기 위해 Controlnet과 같은 기존의 노력은 이미지 기반 조건부 제어를 통합합니다.이 논문에서는 기존 방법이 이미지 조건부 컨트롤과 일치하는 이미지를 생성하는 데 여전히 중요한 도전에 직면한다는 것을 보여줍니다.이를 위해 생성 된 이미지와 조건부 컨트롤 사이의 픽셀 레벨 사이클 일관성을 명시 적으로 최적화하여 제어 가능한 생성을 향상시키는 새로운 접근법 인 Controlnet ++를 제안합니다.구체적으로, 입력 조건부 제어의 경우, 미리 훈련 된 판별 보상 모델을 사용하여 생성 된 이미지의 해당 조건을 추출한 다음 입력 조건부 제어 및 추출 된 조건 사이의 일관성 손실을 최적화합니다.간단한 구현은 임의의 소음에서 이미지를 생성 한 다음 일관성 손실을 계산하는 것이지만, 이러한 접근 방식은 여러 샘플링 타임 스텝에 대한 그라디언트를 저장해야하므로 상당한 시간과 메모리 비용이 발생합니다.이를 해결하기 위해 노이즈를 추가하여 입력 이미지를 의도적으로 방해하는 효율적인 보상 전략을 소개 한 다음 보상 미세 조정을 위해 단일 단계 거부 이미지를 사용합니다.이는 이미지 샘플링과 관련된 광범위한 비용을 피하여보다 효율적인 보상 미세 조정을 허용합니다.광범위한 실험에 따르면 Controlnet ++는 다양한 조건부 제어 하에서 제어 성을 크게 향상시킨다.예를 들어 세분화 마스크, 라인 아트 모서리 및 깊이 조건에 대해 각각 7.9% MIOU, 13.4% SSIM 및 7.6% RMSE의 ControlNet보다 개선을 달성합니다.",2024.04.11,Ming Li&&Taojiannan Yang&&Huafeng Kuang&&Jie Wu&&Zhaoning Wang&&Xuefeng Xiao&&Chen Chen,arxiv,https://arxiv.org/abs/2404.07987
JetMoE: Reaching Llama2 Performance with 0.1M Dollars,"LLM (Lange Language Models)은 놀라운 결과를 얻었지만, 그들의 자원 수요가 증가하는 것은 강력하고 접근 가능한 초인간 지능의 개발에 중요한 장애물이되었습니다.이 보고서는 신중하게 혼합 된 오픈 소스 코퍼라와 30,000 H100 GPU 시간의 1.25T 토큰을 사용하여 0.1 백만 달러 미만의 새로운 LLM 인 Jetmoe-8B를 소개합니다.저렴한 비용에도 불구하고 Jetmoe-8B는 LLAMA2-7B 모델과 Jetmoe-8B-Chat가 LLAMA2-13B-CHAT 모델을 능가하는 인상적인 성능을 보여줍니다.이러한 결과는 LLM 교육이 일반적으로 생각하는 것보다 훨씬 비용 효율적 일 수 있음을 시사합니다.Jetmoe-8B는 주의력과 피드 포워드 전문가로 구성된 효율적인 드물게 게이팅 된 SMOE (Smoe) 아키텍처를 기반으로합니다.두 층 모두 드물게 활성화되어 Jetmoe-8b는 8b 매개 변수를 갖는 반면 각 입력 토큰에 대해 2B 만 활성화하여 LLAMA2-7B에 비해 추론 계산을 약 70% 감소시킵니다.또한 Jetmoe-8B는 공개 데이터 세트 및 교육 코드 만 사용하여 매우 개방적이고 학문 친화적입니다.모든 교육 매개 변수 및 데이터 혼합물은이 보고서에서 열린 기초 모델의 개발에 미래의 노력을 촉진하기 위해 자세히 설명되어 있습니다.이 투명성은 접근 가능하고 효율적인 LLM 분야의 협업과 추가 발전을 장려하는 것을 목표로합니다.모델 가중치는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Yikang Shen&&Zhen Guo&&Tianle Cai&&Zengyi Qin,arxiv,https://arxiv.org/abs/2404.07413
LLoCO: Learning Long Contexts Offline,"자체 변환 메커니즘의 2 차 계산 및 메모리 오버 헤드와 생성 중 실질적인 KV 캐시 크기로 인해 LLM (Lang Contex)을 처리하는 것은 여전히 큰 언어 모델 (LLMS)의 과제로 남아 있습니다.우리는 컨텍스트 압축 및 도메인 매개 변수 효율적인 결합을 통해 오프라인 컨텍스트를 학습 함으로써이 문제를 해결하기위한 새로운 접근법을 제안합니다.우리의 방법을 통해 LLM은 원래 컨텍스트를 간결하게 표현하고 관련 정보를 효율적으로 검색하여 질문에 정확하게 답변 할 수 있습니다.LORA를 사용하여 컨텍스트 압축, 검색 및 매개 변수 효율적인 양조를 결합한 기술 인 Lloco를 소개합니다.우리의 접근 방식은 최대 128k 토큰을 처리하기 위해 4K 토큰 LLAMA2-7B 모델의 효과적인 컨텍스트 창을 확장합니다.우리는 여러 장기 텍스트 질문 응답 데이터 세트에 대한 접근 방식을 평가하여 Lloco가 추론 중에 30 \ Timesfewer 토큰을 사용하면서 텍스트 내 학습보다 훨씬 성능이 우수 함을 보여줍니다.Lloco는 최대 7.62 \ Timesspeed-Up을 달성하고 긴 문서 질문에 대한 비용을 크게 줄여서 효율적인 긴 상황 처리를위한 유망한 솔루션입니다.우리의 코드는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Sijun Tan&&Xiuyu Li&&Shishir Patil&&Ziyang Wu&&Tianjun Zhang&&Kurt Keutzer&&Joseph E. Gonzalez&&Raluca Ada Popa,arxiv,https://arxiv.org/abs/2404.07979
HGRN2: Gated Linear RNNs with State Expansion,"계층 적으로 게이트 된 선형 RNN (HGRN, Qin et al. 2023)은 효율적인 추론을 제공하면서 언어 모델링에서 경쟁력있는 교육 속도와 성능을 보여주었습니다.그러나 HGRN의 반복 상태 크기는 비교적 작으며,이 문제는 선형주의에서 영감을 얻은이 문제를 제한하여 간단한 외부 제품 기반 상태 확장 메커니즘을 도입하여 재발 상태 크기를 소개하지 않고도 크게 확대 될 수 있습니다.추가 매개 변수.선형주의 형태는 하드웨어 효율적인 교육을 허용합니다. 우리의 광범위한 실험은 언어 모델링, 이미지 분류 및 장거리 분야에서 HGRN1보다 HGRN2의 이점을 확인합니다.제어 된 실험 설정;또한 전체 교육 토큰을 사용하면서 다운 스트림 평가에서 많은 오픈 소스 3B 모델과 경쟁적으로 수행합니다.",2024.04.11,Zhen Qin&&Songlin Yang&&Weixuan Sun&&Xuyang Shen&&Dong Li&&Weigao Sun&&Yiran Zhong,arxiv,https://arxiv.org/abs/2404.07904
Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models,"안내는 이미지 생성 확산 모델에서 최고의 성능을 추출하는 데 중요한 기술입니다.전통적으로, 이미지의 샘플링 체인 전체에 일정한 지침 가중치가 적용되었습니다.우리는 지침이 체인의 시작 (높은 노이즈 레벨)에 대해 분명히 유해하고, 끝까지 (저음 수준)에 크게 불필요하며 중간에서만 유리하다는 것을 보여줍니다.따라서 우리는이를 특정 범위의 노이즈 레벨로 제한하여 추론 속도와 결과 품질을 모두 향상시킵니다.이 제한된 지침 간격은 Imagenet-512의 레코드 FID를 1.81에서 1.40으로 크게 향상시킵니다.우리는 그것이 안정적인 확산 XL의 대규모 설정을 포함하여 서로 다른 샘플러 매개 변수, 네트워크 아키텍처 및 데이터 세트에서 정량적이고 질적으로 유리하다는 것을 보여줍니다.따라서 우리는지도를 사용하는 모든 확산 모델에서 지침 간격을 과복 매개 변수로 노출하는 것이 좋습니다.",2024.04.11,Tuomas Kynkäänniemi&&Miika Aittala&&Tero Karras&&Samuli Laine&&Timo Aila&&Jaakko Lehtinen,arxiv,https://arxiv.org/abs/2404.07724
OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments,"최소한의 인간 개입으로 복잡한 컴퓨터 작업을 달성하는 자율적 인 에이전트는 인간 컴퓨터 상호 작용을 변화시켜 접근성과 생산성을 크게 향상시킬 수 있습니다.그러나 기존 벤치 마크는 대화식 환경이 부족하거나 특정 응용 프로그램 또는 도메인에 특정한 환경으로 제한되어 실제 컴퓨터 사용의 다양하고 복잡한 특성을 반영하지 않으므로 작업 범위 및 에이전트 확장 성을 제한합니다.이 문제를 해결하기 위해, 우리는 Ubuntu, Windows 및 MacOS와 같은 다양한 운영 체제에서 지원하는 작업 설정, 실행 기반 평가 및 대화식 학습을위한 최초의 확장 가능한 실제 컴퓨터 환경 인 Osworld를 소개합니다..Osworld는 임의의 응용 프로그램과 관련된 개방형 컴퓨터 작업을 평가하기위한 통합 된 통합 컴퓨터 환경 역할을 할 수 있습니다.Osworld를 바탕으로 Open Domains, OS 파일 I/O 및 여러 응용 프로그램에 걸친 워크 플로에서 실제 웹 및 데스크탑 앱과 관련된 369 개의 컴퓨터 작업의 벤치 마크를 만듭니다.각 작업 예제는 실제 컴퓨터 사용 사례에서 파생되며 신뢰할 수 있고 재현 가능한 평가를위한 자세한 초기 상태 설정 구성 및 사용자 정의 실행 기반 평가 스크립트가 포함되어 있습니다.Osworld에서 최첨단 LLM/VLM 기반 에이전트에 대한 광범위한 평가는 컴퓨터 보조자 역할을 수행하는 능력이 상당한 결함을 보여줍니다.인간은 작업의 72.36% 이상을 달성 할 수 있지만, 최고의 모델은 12.24%의 성공 만 달성하며, 주로 GUI 근거 및 운영 지식으로 어려움을 겪고 있습니다.Osworld를 사용한 포괄적 인 분석은 이전 벤치 마크에서는 불가능한 멀티 모달 일반 요원을 개발하기위한 귀중한 통찰력을 제공합니다.우리의 코드, 환경, 기준선 모델 및 데이터는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Tianbao Xie&&Danyang Zhang&&Jixuan Chen&&Xiaochuan Li&&Siheng Zhao&&Ruisheng Cao&&Toh Jing Hua&&Zhoujun Cheng&&Dongchan Shin&&Fangyu Lei&&Yitao Liu&&Yiheng Xu&&Shuyan Zhou&&Silvio Savarese&&Caiming Xiong&&Victor Zhong&&Tao Yu,arxiv,https://arxiv.org/abs/2404.07972
Transferable and Principled Efficiency for Open-Vocabulary Segmentation,"사전 훈련 된 기초 시력-언어 모델의 최근 성공은 OVS (Open-Vocabulary Segmentation)를 가능하게합니다.유망한 성능에도 불구하고,이 접근법은 두 가지 과제에 대한 무거운 계산 간접비를 도입합니다. 1) 백본의 큰 모델 크기;2) 미세 조정 중에 비싼 비용.이러한 과제는이 OVS 전략이 실제 시나리오에서 널리 적용되고 저렴 해지는 것을 방해합니다.모델 압축 및 효율적인 미세 조정과 같은 전통적인 방법은 이러한 과제를 해결할 수 있지만 종종 휴리스틱에 의존합니다.이는 해당 솔루션을 쉽게 전송할 수 없으며 다른 모델에서 재 훈련이 필요하다는 것을 의미합니다.효율적인 OV의 맥락에서, 우리는 교육 비용이 낮은 소규모 모델을 활용하여 대규모 비전 언어 기초 모델을 기반으로 이전 OVS 작업과 비교할 수있는 성능을 달성하는 것을 목표로합니다.핵심 전략은 우리의 효율성을 하나의 OVS 프레임 워크에서 다른 사용자 정의없이 다른 OVS 프레임 워크에서 다른 사람으로 원활하게 전송할 수 있도록하는 것입니다.다양한 OVS 벤치 마크에 대한 포괄적 인 실험은 이전 작품에 대한 세분화 정확도와 계산 비용 사이의 우수한 상충 관계를 보여줍니다.우리의 코드는이 https url에서 사용할 수 있습니다",2024.04.11,Jingxuan Xu&&Wuyang Chen&&Yao Zhao&&Yunchao Wei,arxiv,https://arxiv.org/abs/2404.07448
Best Practices and Lessons Learned on Synthetic Data for Language Models,"AI 모델의 성공은 데이터 부족, 개인 정보 보호 문제 및 높은 비용으로 인해 얻기가 어려울 수있는 크고 다양하며 고품질 데이터 세트의 가용성에 의존합니다.합성 데이터는 실제 패턴을 모방하는 인공 데이터를 생성함으로써 유망한 솔루션으로 등장했습니다.이 백서는 합성 데이터 연구에 대한 개요를 제공하고 응용 프로그램, 과제 및 향후 방향을 논의합니다.우리는 우선 예술의 경험적 증거를 제시하여 그 효과를 보여주고 사실 성, 충실도 및 편견을 보장하는 것의 중요성을 강조합니다.우리는보다 강력하고 포괄적이며 신뢰할 수있는 언어 모델을 구축하기 위해 합성 데이터의 책임감을 강조합니다.",2024.04.11,Ruibo Liu&&Jerry Wei&&Fangyu Liu&&Chenglei Si&&Yanzhe Zhang&&Jinmeng Rao&&Steven Zheng&&Daiyi Peng&&Diyi Yang&&Denny Zhou&&Andrew M. Dai,arxiv,https://arxiv.org/abs/2404.07503
Rho-1: Not All Tokens Are What You Need,"이전 언어 모델 사전 훈련 방법은 모든 훈련 토큰에 다음 번의 예측 손실을 균일하게 적용했습니다.이 규범에 도전하면서, 우리는 ""코퍼스의 모든 토큰이 언어 모델 훈련에 똑같이 중요하지는 않습니다""라고 주장합니다.우리의 초기 분석은 언어 모델의 토큰 수준의 훈련 역학을 탐구하여 다른 토큰에 대한 뚜렷한 손실 패턴을 드러냅니다.이러한 통찰력을 활용하여 Rho-1이라는 새로운 언어 모델을 소개합니다.Corpus의 다음 토큰을 예측하는 법을 배우는 전통적인 LM과 달리 RHO-1은 선택적 언어 모델링 (SLM)을 사용하는데, 이는 원하는 분포와 정렬 된 유용한 토큰을 선택적으로 훈련시킵니다.이 접근법은 참조 모델을 사용하여 사전 트레인 토큰의 점수를 매긴 다음 더 높은 손실로 토큰에 집중된 손실로 언어 모델을 훈련시키는 것이 포함됩니다.15B OpenWebMath Corpus에서 지속적으로 사전 여면을 할 때 RHO-1은 9 개의 수학 작업에서 최대 30%의 몇 번의 정확도가 절대적으로 개선됩니다.미세 조정 후, RHO-1-1B 및 7B는 수학 데이터 세트에서 각각 40.6% 및 51.8%의 최첨단 결과를 달성했습니다.또한, 80B 일반 토큰의 사전 여지가있을 때 RHO-1은 15 가지 다양한 작업에서 6.8% 평균 향상을 달성하여 언어 모델 사전 훈련의 효율성과 성능을 모두 증가시킵니다.",2024.04.11,Zhenghao Lin&&Zhibin Gou&&Yeyun Gong&&Xiao Liu&&Yelong Shen&&Ruochen Xu&&Chen Lin&&Yujiu Yang&&Jian Jiao&&Nan Duan&&Weizhu Chen,arxiv,https://arxiv.org/abs/2404.07965
Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models,"흰 족제비는 지역 이해를 대형 언어 모델 (LLM)에 원활하게 통합하여 참조 및 접지 기능을 용이하게하지만, 미리 훈련 된 고정 시각 인코더에 의해 제한되고 더 넓은 작업에서 잘 수행되지 않았다.이 작품에서 우리는 흰 족제비로 업그레이드 한 Ferret-V2, 세 가지 주요 디자인을 공개합니다.(1) 모든 해상도 접지 및 참조 : 더 높은 이미지 해상도를 쉽게 처리하는 유연한 접근 방식으로 이미지를 처리하고 이해하는 모델의 능력을 향상시킵니다.(2) 다중 부문 시각 인코딩 : 추가 DINOV2 인코더를 통합 함으로써이 모델은 글로벌 및 세분화 된 시각 정보에 대한 더 좋고 다양한 기본 컨텍스트를 학습합니다.(3) 3 단계 훈련 패러다임 : 이미지 캡션 정렬 외에도 최종 명령 튜닝 전에 고해상도 조밀 한 정렬에 대한 추가 단계가 제안됩니다.실험에 따르면 Ferret-V2는 고해상도 스케일링 및 세밀한 시각적 처리 덕분에 흰 족제비 및 기타 최첨단 방법에 비해 상당한 개선을 제공합니다.",2024.04.11,Haotian Zhang&&Haoxuan You&&Philipp Dufter&&Bowen Zhang&&Chen Chen&&Hong-You Chen&&Tsu-Jui Fu&&William Yang Wang&&Shih-Fu Chang&&Zhe Gan&&Yinfei Yang,arxiv,https://arxiv.org/abs/2404.07973
From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples,"우리는 사전 훈련 된 대형 언어 모델 (예 : LLAMA2, GPT-4, Claude 3 등)이 추가 교육 또는 그라디언트 업데이트없이 텍스트 내 예제를 제공 할 때 선형 및 비선형 회귀를 수행 할 수있는 방법을 분석합니다.우리의 연구 결과에 따르면 몇 가지 대형 언어 모델 (예 : GPT-4, Claude 3)은 임의의 산림, 포장 또는 그라디언트 부스팅과 같은 전통적인 감독 방법의 성능 경쟁 (또는 성능 성능)로 회귀 작업을 수행 할 수 있습니다.예를 들어, 까다로운 Friedman #2 회귀 데이터 세트에서 Claude 3은 Adaboost, SVM, Random Forest, KNN 또는 Gradient Boosting과 같은 많은 감독 된 방법을 능가합니다.그런 다음 대형 언어 모델의 성능이 텍스트 내 모범의 수를 얼마나 잘 확장하는지 조사합니다.우리는 온라인 학습에서 후회의 개념에서 빌리며 LLM이 하위 선회 후회를 얻을 수 있음을 경험적으로 보여줍니다.",2024.04.11,Robert Vacareanu&&Vlad-Andrei Negru&&Vasile Suciu&&Mihai Surdeanu,arxiv,https://arxiv.org/abs/2404.07544
RecurrentGemma: Moving Past Transformers for Efficient Open Language Models,우리는 Google의 소설 그리핀 아키텍처를 사용하는 오픈 언어 모델 인 RecurrentGemma를 소개합니다.그리핀은 선형 재발과 지역주의를 결합하여 언어에 대한 탁월한 성능을 달성합니다.고정 된 크기의 상태가있어 메모리 사용을 줄이고 긴 시퀀스에서 효율적인 추론을 가능하게합니다.우리는 2B 비 embedding 매개 변수와 명령 조정 된 변형을 가진 미리 훈련 된 모델을 제공합니다.두 모델 모두 더 적은 수의 토큰에 대해 훈련을 받았음에도 불구하고 Gemma-2B와 비슷한 성능을 달성합니다.,2024.04.11,Aleksandar Botev&&Soham De&&Samuel L Smith&&Anushan Fernando&&George-Cristian Muraru&&Ruba Haroun&&Leonard Berrada&&Razvan Pascanu&&Pier Giuseppe Sessa&&Robert Dadashi&&Léonard Hussenot&&Johan Ferret&&Sertan Girgin&&Olivier Bachem&&Alek Andreev&&Kathleen Kenealy&&Thomas Mesnard&&Cassidy Hardin&&Surya Bhupatiraju&&Shreya Pathak&&Laurent Sifre&&Morgane Rivière&&Mihir Sanjay Kale&&Juliette Love&&Pouya Tafti&&Armand Joulin&&Noah Fiedel&&Evan Senter&&Yutian Chen&&Srivatsan Srinivasan&&Guillaume Desjardins&&David Budden&&Arnaud Doucet&&Sharad Vikram&&Adam Paszke&&Trevor Gale&&Sebastian Borgeaud&&Charlie Chen&&Andy Brock&&Antonia Paterson&&Jenny Brennan&&Meg Risdal&&Raj Gundluru&&Nesh Devanathan&&Paul Mooney&&Nilay Chauhan&&Phil Culliton&&Luiz GUStavo Martins&&Elisa Bandy&&David Huntsperger&&Glenn Cameron&&Arthur Zucker&&Tris Warkentin&&Ludovic Peran&&Minh Giang&&Zoubin Ghahramani&&Clément Farabet&&Koray Kavukcuoglu&&Demis Hassabis&&Raia Hadsell&&Yee Whye Teh&&Nando de Frietas,arxiv,https://arxiv.org/abs/2404.07839
Audio Dialogues: Dialogues dataset for audio and music understanding,"오디오 이해를위한 기존 데이터 세트는 주로 자연 언어로 오디오를 설명하기위한 단일 회전 상호 작용 (예 : 오디오 캡션, 오디오 질문 응답)에 중점을 두어 대화식 대화를 통해 오디오 이해를 제한합니다.이 차이를 해결하기 위해, 우리는 일반 오디오 사운드 및 음악을위한 163.8k 샘플을 포함하는 다중 회전 대화 데이터 세트를 소개합니다.대화 외에도 오디오 대화에는 여러 입력 오디오를 이해하고 비교할 수있는 질문 응답 쌍이 있습니다.오디오 대화 상자는 기존 데이터 세트의 프롬프트 기반 접근 방식 및 캡션 주석을 활용하여 LLM (Lange Language Model)을 사용하여 다중 턴 대화를 생성합니다.오디오 대화의 복잡성과 적용 가능성을 보여주기 위해 제안 된 데이터 세트에서 기존 오디오 구축 된 대형 언어 모델을 평가합니다.데이터 세트를 생성하기위한 코드는 공개적으로 제공됩니다.자세한 프롬프트 및 생성 된 대화는 데모 웹 사이트 HTTPS URL에서 찾을 수 있습니다.",2024.04.11,Arushi Goel&&Zhifeng Kong&&Rafael Valle&&Bryan Catanzaro,arxiv,https://arxiv.org/abs/2404.07616
Sparse Laneformer,"차선 탐지는 자율 주행의 근본적인 작업이며 딥 러닝이 등장함에 따라 큰 진전을 이루었습니다.이전의 앵커 기반 방법은 종종 조밀 한 앵커를 설계하며, 이는 훈련 데이터 세트에 크게 의존하고 추론 중에 고정 된 상태로 유지됩니다.우리는 레인 검출에 밀집된 앵커가 필요하지 않다는 것을 분석하고 희소 한 앵커 메커니즘을 기반으로 변압기 기반 차선 검출 프레임 워크를 제안합니다.이를 위해, 우리는 전통적인 명시 적 앵커 대신 위치 인식 레인 쿼리와 각도 쿼리를 가진 스파 스 앵커를 생성합니다.우리는 수평 지각주의 (HPA)를 채택하여 수평 방향을 따라 레인 특징을 집계하고 레인 앵글 크로스주의 (LACA)를 채택하여 레인 쿼리와 각도 쿼리 사이의 상호 작용을 수행합니다.또한 차선 예측을 추가로 개선하기 위해 변형 가능한 교차주의에 기초하여 레인 지각주의 (LPA)를 제안합니다.Sparse Laneformer라는 우리의 방법은 구현하기 쉬우 며 엔드 투 엔드 훈련 가능입니다.광범위한 실험에 따르면 스파 스 란 형성체는 최첨단 방법, 예를 들어 LANEFORMER를 3.0% F1 점수로, O2SFormer를 0.7% F1 점수만큼 동일한 RESNET-34 백본으로 CULANE에서 MAC의 MAC를 능가합니다.",2024.04.11,Ji Liu&&Zifeng Zhang&&Mingjie Lu&&Hongyang Wei&&Dong Li&&Yile Xie&&Jinzhang Peng&&Lu Tian&&Ashish Sirasao&&Emad Barsoum,arxiv,https://arxiv.org/abs/2404.07821
On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation,"자연어를 추가 지침으로 통합하여 단안 깊이 추정의 최근 발전이 이루어졌습니다.인상적인 결과를 낳지 만, 언어의 영향, 특히 일반화와 견고성 측면에서 언어의 영향은 여전히 탐구되지 않습니다.이 백서에서는이 이전의 영향을 정량화 하여이 격차를 해결하고 다양한 설정에서 그 효과를 벤치마킹하기위한 방법을 소개합니다.우리는 객체 중심의 3 차원 공간 관계를 전달하는 ""저수준""문장을 생성하고, 추가 언어 사전으로 통합하고 깊이 추정에 대한 하류 영향을 평가합니다.우리의 주요 발견은 현재 언어 유도 깊이 추정기가 장면 수준 설명에서만 최적으로 성능을 발휘하고 낮은 수준의 설명으로 반 직관적으로 악화된다는 것입니다.추가 데이터를 활용하더라도 이러한 방법은 지시 된 적대적 공격에 대한 강력하지 않으며 분포 이동이 증가함에 따라 성능 감소.마지막으로, 미래의 연구를위한 토대를 제공하기 위해, 우리는 실패 지점을 식별하고 이러한 단점을 더 잘 이해할 수있는 통찰력을 제공합니다.깊이 추정을 위해 언어를 사용하여 점점 더 많은 방법으로, 우리의 연구 결과는 실제 환경에서 효과적인 배포를 위해 신중한 고려가 필요한 기회와 함정을 강조합니다.",2024.04.12,Agneet Chatterjee&&Tejas Gokhale&&Chitta Baral&&Yezhou Yang,arxiv,https://arxiv.org/abs/2404.08540
COCONut: Modernizing COCO Segmentation,"최근 수십 년 동안 비전 커뮤니티는 데이터 세트 벤치 마크의 발전으로 인해 시각적 인식의 놀라운 진전을 목격했습니다.특히, 확립 된 Coco 벤치 마크는 현대 탐지 및 세분화 시스템의 개발을 추진했습니다.그러나 Coco Segmentation 벤치 마크는 지난 10 년 동안 비교적 느리게 개선되었습니다.사물 인스턴스에 대한 거친 다각형 주석이 원래 장착 된이 제품은 물건 영역에 대해 거친 슈퍼 픽셀 주석을 점차적으로 통합하여 파노틱 세분화 주석을 생성하기 위해 휴리스틱으로 합병되었습니다.다른 평가자 그룹에 의해 실행 된 이러한 주석은 거친 분할 마스크뿐만 아니라 세분화 유형 사이의 불일치로도 발생했습니다.이 연구에서 우리는 Coco 세분화 주석에 대한 포괄적 인 재평가를 수행합니다.주석 품질을 향상시키고 데이터 세트를 확장하여 5.18m 이상의 Panoptic 마스크가있는 383k 이미지를 포함하여 코코넛 인 Coco Next Universal Segmentation 데이터 세트를 소개합니다.코코넛은 세분화 된 고품질 마스크를 사용하여 시맨틱, 인스턴스 및 팬틱 세분화에 걸쳐 세분화 주석을 조화시키고 모든 세분화 작업에 대한 강력한 벤치 마크를 설정합니다.우리가 아는 한, 코코넛은 인간 평가자에 의해 검증 된 대규모 대규모 보편적 인 세분화 데이터 세트로 서 있습니다.우리는 코코넛의 출시가 새로운 신경망의 진행 상황을 평가하는 지역 사회의 능력에 크게 기여할 것으로 기대합니다.",2024.04.12,Xueqing Deng&&Qihang Yu&&Peng Wang&&Xiaohui Shen&&Liang-Chieh Chen,arxiv,https://arxiv.org/abs/2404.08639
Dataset Reset Policy Optimization for RLHF,"인간 선호도 기반 피드백의 강화 학습 (RL)은 GPT-4 및 Claude3 Opus와 같은 인상적인 모델을 생성 한 미세 조정 생성 모델에 대한 인기있는 패러다임입니다.이 프레임 워크는 종종 오프라인 환경 설정 데이터 세트에서 보상 모델을 배우고 온라인 RL을 실행하여 학습 된 보상 모델을 최적화합니다.이 작업에서는 재설정 아이디어를 활용하여 입증 가능한 보증이있는 새로운 RLHF 알고리즘을 제안합니다.오프라인 환경 설정 데이터 세트가 유익한 상태 (즉, 레이더가 선호하는 데이터), 새로운 알고리즘 인 DR-PO (Dataset Reset Policy Optimization)를 제공한다는 사실에 의해 기존의 오프라인 선호도 데이터 세트를 온라인 정책 교육 절차에 통합한다는 사실에 의해 동기가 부여됩니다.데이터 세트 재설정 : 항상 초기 상태 배포에서 시작하는 대신 오프라인 데이터 세트의 상태에 정책 옵티마이저를 직접 재설정합니다.이론적으로, 우리는 DR-PO가 유한 한 샘플 복잡성으로 일반 함수 근사치에 따라 오프라인 데이터 세트가 다루는 모든 정책만큼 적어도 우수한 성능을 배우는 것을 보여줍니다.실험에서, 우리는 TL; DR 요약과 인류 유용한 유해 (HH) 데이터 세트 모두에서 DR-PO의 생성이 근위 정책 최적화 (PPO)와 DPO (Direction Preverence Optimization)의 생성보다 낫다는 것을 보여줍니다.GPT4 Win-Rate의 메트릭.이 작업에 대한 코드는 HTTPS URL에서 찾을 수 있습니다.",2024.04.12,Jonathan D. Chang&&Wenhao Zhan&&Owen Oertell&&Kianté Brantley&&Dipendra Misra&&Jason D. Lee&&Wen Sun,arxiv,https://arxiv.org/abs/2404.08495
Probing the 3D Awareness of Visual Foundation Models,"대규모 사전 해독의 최근 발전은 강력한 기능을 갖춘 시각적 기초 모델을 산출했습니다.최근 모델은 훈련 작업을 위해 임의의 이미지로 일반화 할 수있을뿐만 아니라, 중간 표현은 탐지 및 세분화와 같은 다른 시각적 작업에 유용합니다.이러한 모델이 2D로 객체를 분류, 묘사 및 로컬화할 수 있다는 점을 감안할 때, 우리는 그들이 3D 구조를 나타내는 지 여부를 묻습니다.이 작업에서는 시각적 기초 모델의 3D 인식을 분석합니다.우리는 3D 인식이 (1) 장면의 3D 구조를 인코딩하고 (2) 표면을 지속적으로 표현한다는 것을 암시한다.우리는 냉동 기능에 대한 작업 별 프로브와 제로 샷 추론 절차를 사용하여 일련의 실험을 수행합니다.우리의 실험은 현재 모델의 몇 가지 한계를 보여줍니다.우리의 코드 및 분석은 https url에서 찾을 수 있습니다.",2024.04.12,Mohamed El Banani&&Amit Raj&&Kevis-Kokitsi Maninis&&Abhishek Kar&&Yuanzhen Li&&Michael Rubinstein&&Deqing Sun&&Leonidas Guibas&&Justin Johnson&&Varun Jampani,arxiv,https://arxiv.org/abs/2404.08636
"Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies","이 논문은 제한된 계산 예산으로 확장 될 때 대조적 인 언어 이미지 사전 훈련 (클립)의 성능을 조사합니다.데이터, 아키텍처 및 교육 전략의 세 가지 차원을 따라 클립을 탐색합니다.데이터와 관련하여 고품질 교육 데이터의 중요성을 보여주고 고품질 데이터의 더 작은 데이터 세트가 품질이 낮은 더 큰 데이터 세트보다 우수 할 수 있음을 보여줍니다.또한 모델 성능이 데이터 세트 크기에 따라 어떻게 변하는 지 살펴 봅니다. 이는 소규모 VIT 모델이 소규모 데이터 세트에 더 적합한 반면, 더 큰 모델은 고정 된 컴퓨팅을 통해 더 큰 데이터 세트에서 더 잘 작동 함을 시사합니다.또한 CNN 기반 아키텍처 또는 클립 교육을위한 VIT 기반 아키텍처를 선택할시기에 대한 지침을 제공합니다.우리는 미끄러짐, 플립, 클립 및 클립+데이터 증강의 네 가지 클립 훈련 전략을 비교하고 교육 전략의 선택이 사용 가능한 컴퓨팅 리소스에 달려 있음을 보여줍니다.우리의 분석에 따르면 Clip+Data 증강은 교육 데이터의 절반 만 사용하여 Clip과 비슷한 성능을 달성 할 수 있습니다.이 작업은 클립 모델을 효과적으로 훈련하고 배포하는 방법에 대한 실질적인 통찰력을 제공하여 다양한 응용 프로그램에서 실질적으로 사용하기 쉽고 저렴한 가격으로 제공합니다.",2024.04.12,Zichao Li&&Cihang Xie&&Ekin Dogus Cubuk,arxiv,https://arxiv.org/abs/2404.08197
MonoPatchNeRF: Improving Neural Radiance Fields with Patch-based Monocular Guidance,"최신 정규화 된 신경 방사 분야 (NERF) 접근법은 열악한 지오메트리를 생성하고 MVS (Multiview Stereo) 벤치 마크에 대한 외삽을 봅니다.이 논문에서는 정확한 형상 및 뷰 합성을 제공하는 3D 모델을 만들어 NERF와 전통적인 MVS 방법 사이의 대규모 기하학적 성능 간격을 부분적으로 닫는 것을 목표로합니다.우리는 단안 표면 정상 및 상대 깊이 예측을 효과적으로 활용하는 패치 기반 접근법을 제안합니다.패치 기반 광선 샘플링은 또한 무작위로 샘플링 된 가상 및 훈련 뷰 사이의 정규화 된 교차 상관 (NCC) 및 구조적 유사성 (SSIM)의 외관 정규화를 가능하게합니다.우리는 소설 구조에 기초한 ""밀도 제한""이 소설 뷰 합성 메트릭의 약간 감소함으로써 기하학적 정확도를 크게 향상시키는 데 도움이 될 수 있음을 보여줍니다.우리의 실험에 따르면 ETH3D MVS 벤치 마크의 평균 F1@2cm의 Freenerf의 성능은 4 배, NERF 기반 모델의 기하학적 정확도를 향상시키기위한 유익한 연구 방향을 시사하고 NERF를 활성화하기위한 잠재적 인 미래의 접근 방식을 밝힙니다.-결국 기존 MV를 능가하기위한 기반 최적화.",2024.04.12,Yuqun Wu&&Jae Yong Lee&&Chuhang Zou&&Shenlong Wang&&Derek Hoiem,arxiv,https://arxiv.org/abs/2404.08252
Pre-training Small Base LMs with Fewer Tokens,"우리는 기존의 큰 기본 LM에서 시작하여 작은 기본 언어 모델 (LM)을 개발하기위한 간단한 접근 방식의 효과를 연구합니다. 먼저 큰 LM에서 몇 개의 변압기 블록을 상속 한 다음이 작은 모델을 매우 작은 서브 세트 (0.1에서 훈련시킵니다.더 큰 모델의 원시 프리 트레인 데이터의 \%).우리는 간단한 레시피 상인을 호출하고 먼저 1B 토큰 (및 더 큰 LM 3B 매개 변수의 시작 몇 층의 시작)을 사용하여 1.5B 매개 변수가있는 작은베이스 LM을 구축하기 위해 먼저 시연합니다.우리는 반나절 미만 동안 단일 A6000 GPU를 사용하여이를 수행합니다.MMLU 벤치 마크뿐만 아니라 9 가지 다양한 평가 데이터 세트에서 결과 모델은 1B-2B 크기의 공개적으로 사용 가능한 기본 모델과 유리하게 비교되며, 그 중 일부는 50-1000 배 더 많은 토큰을 사용하여 교육을 받았으며 약간 다른 설정에서의 상속을 조사합니다.큰 LMS와 전체 사전 훈련 데이터 세트를 사용하여 소형 LMS를 훈련시킵니다.여기서 우리는 GPT2- 메드 (355m) 및 GPT-2-LARGE (770m)의 일부 층 중 일부를 사용하여 더 작은 LMS 훈련을 받았음을 보여줍니다.9B 토큰이있는 OpenWebText 데이터 세트.우리는 광범위한 실험으로 레시피를 분석하고 다양한 설정에서 효능을 보여줍니다.우리의 코드는 https url에서 사용할 수 있습니다.",2024.04.12,Sunny Sanyal&&Sujay Sanghavi&&Alexandros G. Dimakis,arxiv,https://arxiv.org/abs/2404.08634
Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length,"변압기의 2 차 복잡성 및 약한 길이 외삽은 긴 시퀀스로 확장하는 능력을 제한하며, 선형주의 및 상태 공간 모델과 같은 하위 분량 솔루션이 존재하지만, 사전 변형 효율과 다운 스트림 작업 정확도에서 변압기가 경험적으로 저조합니다.우리는 무제한 컨텍스트 길이를 가진 효율적인 서열 모델링을위한 신경 구조 인 Megalodon을 소개합니다.Megalodon은 Mega의 아키텍처 (게이트 된주의를 기울여 지수 이동 평균)의 아키텍처를 상속하고, 복잡한 지수 이동 평균 (CEMA), 타임 스텝 정규화 층, 정규화 된주의 메커니즘 및 두 가지를 포함하여 기능 및 안정성을 향상시키기 위해 여러 기술 구성 요소를 도입합니다.잔류 구성.LLAMA2와의 제어 된 헤드 투 헤드 비교에서 Megalodon은 70 억 파라미터 규모와 2 조 훈련 토큰의 변압기보다 더 나은 효율을 달성합니다.Megalodon은 LLAMA2-7B (1.75)와 13B (1.67) 사이의 중간 쯤에 1.70의 훈련 손실에 도달합니다.코드 :이 https url",2024.04.12,Xuezhe Ma&&Xiaomeng Yang&&Wenhan Xiong&&Beidi Chen&&Lili Yu&&Hao Zhang&&Jonathan May&&Luke Zettlemoyer&&Omer Levy&&Chunting Zhou,arxiv,https://arxiv.org/abs/2404.08801
On Speculative Decoding for Multimodal Large Language Models,"멀티 모달 대형 언어 모델 (MLLM)과의 추론은 메모리 대역폭 병목으로 고통 받고 토큰을 자동으로 생성하는 대형 모델 백본으로 인해 느리게 진행됩니다.이 논문에서는 MLLM의 추론 효율, 특히 LLAVA 7B 모델의 추론 효율을 향상시키기위한 투기 디코딩의 적용을 탐구합니다.우리는 언어 전용 모델이 LLAVA 7B로 투기 디코딩을위한 좋은 초안 모델 역할을 할 수 있으며, 초안 모델의 이미지 토큰 및 관련 처리 구성 요소를 우회합니다.세 가지 다른 작업에 대한 실험에 따르면 투기 디코딩은 처음부터 훈련 한 115m 매개 변수 언어 모델을 최대 2.37의 메모리 바운드 속도를 달성 할 수 있음을 보여줍니다.또한 이미지 어댑터를 통합 한 컴팩트 한 LLAVA 드래프트 모델을 소개하는데, 이는 이미지 캡션의 한계 성능 이득을 보여 주면서 다른 작업에서 비슷한 결과를 유지합니다.",2024.04.13,Mukul Gagrani&&Raghavv Goel&&Wonseok Jeon&&Junyoung Park&&Mingu Lee&&Christopher Lott,arxiv,https://arxiv.org/abs/2404.08856
TransformerFAM: Feedback attention is working memory,"트랜스포머는 딥 러닝에 혁명을 일으켰지 만, 2 차주의 복잡성은 무한한 입력을 처리하는 능력을 방해합니다.우리는 피드백 루프를 활용하여 네트워크가 자체 잠재적 표현에 참석할 수 있도록 피드백 루프를 활용하는 새로운 변압기 아키텍처 인 피드백주의 메모리 (FAM)를 제안합니다.이 디자인은 변압기 내 작업 메모리의 출현을 촉진하여 무기한 긴 시퀀스를 처리 할 수 있습니다.TransformerFam은 추가 가중치가 필요하지 않으므로 미리 훈련 된 모델과 완벽하게 통합 할 수 있습니다.우리의 실험에 따르면 TransformerFam은 다양한 모델 크기 (1B, 8B 및 24B)에서 장기 텍스트 작업에서 변압기 성능을 크게 향상시킵니다.이 결과는 LLM (Lange Language Model)에 힘을 실어 줄 수있는 잠재력을 보여줍니다.",2024.04.14,Dongseong Hwang&&Weiran Wang&&Zhuoyuan Huo&&Khe Chai Sim&&Pedro Moreno Mengibar,arxiv,https://arxiv.org/abs/2404.09173
TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models,"멀티 모달 대형 언어 모델 (MLLM)은 다양한 멀티 모달 작업에 대한 인상적인 결과를 보여주었습니다.그러나 대부분의 기존 MLLM은 문서 지향 작업에 적합하지 않으며, 세밀한 이미지 인식 및 정보 압축이 필요합니다.이 논문에서는 MLLM의 일반적인 기능을 유지하면서 문서 지향 작업을 위해 특별히 설계된 MLLM 인 Texthawk를 제시합니다.Texthawk는 4 개의 전용 구성 요소를 설계하여 효율적인 세밀한 인식을 탐색하는 것을 목표로합니다.첫째, 문서 텍스트의 중복성을 줄이고 MLLM의 계산 비용을 낮추기 위해 리샘플링 및 재 배열 (RESA) 모듈이 제안됩니다.다양한 이미지 크기의 확장 성을 보존 할 수있는 확장 가능한 위치 임베딩 (SPE)을 제시하여 각 로컬 기능의 위치를 인코딩하는 것을 탐색합니다.그런 다음 쿼리 제안 네트워크 (QPN)가 채택되어 다른 하위 이미지간에 쿼리를 동적으로 초기화합니다.MLLM의 세밀한 시각적 지각 능력을 더욱 향상시키기 위해, 우리는 문서 이미지의 계층 적 구조와 의미 론적 관계를 포착하는 다단계 크로스-해소 (MLCA) 메커니즘을 설계합니다.또한 Gemini Pro를 사용하여 멀티 모달 문서 데이터를 풍부하게하여 문서 지향 작업을위한 새로운 명령 조정 데이터 세트를 만듭니다.우리는 일반 및 문서 지향 MLLM 벤치 마크에 대한 광범위한 실험을 수행하고 Texthawk가 최첨단 방법보다 우수하여 세밀한 문서 인식과 일반적인 능력의 효과와 우월성을 보여줍니다.",2024.04.14,Ya-Qi Yu&&Minghui Liao&&Jihao Wu&&Yongxin Liao&&Xiaoyu Zheng&&Wei Zeng,arxiv,https://arxiv.org/abs/2404.09204
Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model,"Controlnets는 깊이 맵, 캐니 가장자리 및 인간 포즈와 같은 다양한 조건으로 이미지 생성에서 공간 제어를 추가하는 데 널리 사용됩니다.그러나 제어 된 비디오 생성을 위해 사전 상환 이미지 컨트롤을 활용할 때 몇 가지 과제가 있습니다.먼저, 사전에 사전 처리 된 Controlnet은 기능 공간의 불일치로 인해 새로운 백본 모델에 직접 연결할 수 없으며 새로운 백본에 대한 컨트롤을 훈련하는 비용은 큰 부담입니다.둘째, 다른 프레임의 Controlnet 기능은 시간적 일관성을 효과적으로 처리하지 못할 수 있습니다.이러한 과제를 해결하기 위해, 우리는 사전 제어 컨트롤을 조정하고 (비디오에 대한 시간적 정렬을 개선함으로써 모든 이미지/비디오 확산 모델에 다양한 컨트롤을 추가하는 효율적이고 다양한 프레임 워크 인 CTRL-ADAPTER를 소개합니다.Ctrl-Adapter는 이미지 제어, 비디오 제어, 희소 프레임이있는 비디오 제어, 다중 조건 제어, 다른 백본과의 호환성, 보이지 않는 제어 조건에 대한 적응 및 비디오 편집 등 다양한 기능을 제공합니다.Ctrl-Adapter에서, 우리는 전례가 된 컨트롤 넷 기능을 다른 이미지/비디오 확산 모델에 융합시키고 컨트롤 넷의 매개 변수와 확산 모델을 동결시키는 어댑터 레이어를 훈련시킵니다.Ctrl-Adapter는 시간 및 공간 모듈로 구성되어 비디오의 시간적 일관성을 효과적으로 처리 할 수 있습니다.또한 강력한 적응 및 드문 제어를 위해 잠재적 인 건너 뛰기 및 역 타임 스텝 샘플링을 제안합니다.또한 Ctrl-Adapter는 단순히 (가중치) 평균의 ControlNet 출력을 취하여 여러 조건의 제어를 가능하게합니다.다양한 이미지/비디오 확산 백본 (SDXL, Hotshot-XL, I2VGEN-XL 및 SVD)을 사용하면 CTRL-Adapter는 이미지 제어를위한 Controlnet과 일치하고 비디오 제어를위한 모든 기준 (Davis 2017 데이터 세트의 SOTA 정확도 달성)을 능가합니다.계산 비용 절감 (10GPU 시간 미만).",2024.04.15,Han Lin&&Jaemin Cho&&Abhay Zala&&Mohit Bansal,arxiv,https://arxiv.org/abs/2404.09967
Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization,아티스트와 미디어 직원이 아이디어를 빠르게 생생하게하여 사전 제작 모형을 만들 수있게되므로 컨텐츠 제작 분야의 대부분에서 생성 된 멀티 모드 컨텐츠가 점점 더 널리 퍼져 있습니다.텍스트 프롬프트의 오디오 생성은 음악 및 영화 산업에서 이러한 프로세스의 중요한 측면입니다.최근의 확산 기반 텍스트-아우 디오 모델 중 다수는 프롬프트 아우 디오 쌍의 대규모 데이터 세트에서 점점 더 정교한 확산 모델을 훈련시키는 데 중점을 둡니다.이 모델은 입력 프롬프트와 관련하여 개념이나 이벤트의 존재 및 출력 오디오에서의 시간 순서에 명시 적으로 초점을 맞추지 않습니다.우리의 가설은 오디오 생성의 이러한 측면이 제한된 데이터가있을 때 오디오 생성 성능을 향상시킬 수있는 방법에 초점을 맞추고 있습니다.따라서이 작업에서 기존 텍스트-오디오 모델 Tango를 사용하여 각 프롬프트에는 승자 오디오 출력 및 확산 모델에 대한 일부 패자 오디오 출력이있는 선호도 데이터 세트를 합성 적으로 만듭니다.이론적으로 패자 생산량은 프롬프트 누락 또는 잘못된 순서로 일부 개념이 있습니다.우리는 선호도 데이터 세트에서 확산 -DPO (직접 환경 설정 최적화) 손실을 사용하여 공개적으로 사용 가능한 탱고 텍스트-아우 디오 모델을 미세 조정하고 자동 및 매뉴얼 측면에서 탱고 및 아우디로드 (Audioldm2)보다 오디오 출력이 향상됨을 보여줍니다.-평가 지표.,2024.04.15,Navonil Majumder&&Chia-Yu Hung&&Deepanway Ghosal&&Wei-Ning Hsu&&Rada Mihalcea&&Soujanya Poria,arxiv,https://arxiv.org/abs/2404.09956
CompGS: Efficient 3D Scene Representation via Compressed Gaussian Splatting,"뛰어난 렌더링 품질과 효율성으로 유명한 가우스 스플릿은 3D 장면 표현에서 두드러진 기술로 부상했습니다.그러나 가우스 분할의 상당한 데이터 양은 실제 응용 프로그램에서 실질적인 유용성을 방해합니다.여기, 우리는 압축 가우시안 스플릿 (Comppressed Gaussian Splatting)이라는 효율적인 3D 장면 표현을 제안하며, 이는 데이터 크기가 현저하게 감소한 충실한 3D 장면 모델링을위한 소형 가우시안 프리미티브를 활용합니다.가우시안 프리미티브의 작품을 보장하기 위해, 우리는 서로의 예측 관계를 포착하는 하이브리드 원시 구조를 고안합니다.그런 다음 예측을위한 작은 앵커 프리미티브 세트를 이용하여 대부분의 프리미티브를 고도로 컴팩트 한 잔류 형태로 캡슐화 할 수 있습니다.또한, 우리는 이러한 하이브리드 프리미티브 내에서 중복성을 제거하기 위해 속도 제약 최적화 체계를 개발하여 Bitrate 소비와 표현 효능 사이의 최적의 트레이드 오프로 CompG를 조정합니다.실험 결과에 따르면 제안 된 COMPG는 기존 방법을 훨씬 능가하여 모델 정확도와 렌더링 품질을 손상시키지 않으면 서 3D 장면 표현에서 우수한 소형성을 달성 함을 보여줍니다.우리의 코드는 추가 연구를 위해 Github에서 발표 될 것입니다.",2024.04.15,Xiangrui Liu&&Xinju Wu&&Pingping Zhang&&Shiqi Wang&&Zhu Li&&Sam Kwong,arxiv,https://arxiv.org/abs/2404.09458
"Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video",게임 및 시뮬레이터와 같은 고품질 및 대화식 가상 환경을 만드는 경우 종종 복잡하고 비용이 많이 드는 수동 모델링 프로세스가 포함됩니다.이 논문에서는 실제 장면의 비디오를 사실적이고 대화식 게임 환경으로 자동 변환하는 새로운 접근 방식 인 Video2Game을 제시합니다.우리 시스템의 핵심에는 세 가지 핵심 구성 요소가 있습니다. (i) 장면의 형상 및 시각적 모양을 효과적으로 캡처하는 신경 방사선 (NERF) 모듈;(ii) 더 빠른 렌더링을 위해 NERF에서 지식을 증류하는 메쉬 모듈;및 (iii) 물체 간의 상호 작용과 물리적 역학을 모델링하는 물리 모듈.신중하게 설계된 파이프 라인을 따르면 실제 세계의 상호 작용 가능하고 실행 가능한 디지털 복제본을 구성 할 수 있습니다.우리는 실내 및 대규모 야외 장면 모두에서 시스템을 벤치마킹합니다.우리는 실시간으로 매우 현실적인 렌더링을 생성 할 수있을뿐만 아니라 대화 형 게임을 구축 할 수 있음을 보여줍니다.,2024.04.15,Hongchi Xia&&Zhi-Hao Lin&&Wei-Chiu Ma&&Shenlong Wang,arxiv,https://arxiv.org/abs/2404.09833
HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing,"이 연구는 약 200,000 개의 편집 된 고품질 교육 기반 이미지 편집 데이터 세트 인 HQ-EDIT를 소개합니다.구축 데이터 세트에 대한 속성 안내 또는 인간 피드백에 의존하는 이전 접근 방식과 달리, 우리는 고급 파운데이션 모델을 활용하는 확장 가능한 데이터 수집 파이프 라인, 즉 GPT-4V 및 Dall-E 3을 고안합니다.그런 다음 상세한 텍스트 프롬프트가있는 입력 및 출력 이미지를 특징으로하는 고품질 디티치를 만들었고, 후 처리를 통해 정확한 정렬을 보장합니다.또한 GPT-4V를 사용하여 이미지 편집 쌍의 품질을 정량적으로 평가하기 위해 정렬 및 일관성의 두 가지 평가 메트릭을 제안합니다.HQ EDITS 고해상도 이미지는 세부 사항이 풍부하고 포괄적 인 편집 프롬프트와 함께 기존 이미지 편집 모델의 기능을 크게 향상시킵니다.예를 들어, HQ-EDIT FINETUNED ORTRUCTPIX2PIX는 최첨단 이미지 편집 성능을 얻을 수 있으며, 인간이 주석화 된 데이터로 미세 조정 된 모델을 능가 할 수도 있습니다.프로젝트 페이지는 https url입니다.",2024.04.15,Mude Hui&&Siwei Yang&&Bingchen Zhao&&Yichun Shi&&Heng Wang&&Peng Wang&&Yuyin Zhou&&Cihang Xie,arxiv,https://arxiv.org/abs/2404.09990
Learn Your Reference Model for Real Good Alignment,"정렬 문제의 복잡성은 기존 방법이 불안정하다는 사실에서 비롯됩니다.연구원들은이 단점을 다루기 위해 다양한 트릭을 지속적으로 발명했습니다.예를 들어, 언어 모델 정렬의 인간 피드백 (RLHF) 기술로부터의 기본 강화 학습에서 보상 최대화 외에도 훈련 가능한 정책과 SFT 정책 사이의 Kullback-Leibler 발산이 최소화됩니다.이 추가로 모델이 RM (Reward Model)에 과도하게 장착되고 RM의 도메인이 아닌 텍스트를 생성하는 것을 방지합니다.DPO (Direct Preference Optimization) 메소드는 RLHF의 최적화 작업을 재구성하고 보상 모델을 제거하면서 정책이 SFT 정책에 가까워 지도록 요건을 암묵적으로 유지합니다.우리 논문에서, 우리는 DPO 메소드 에서이 암시 적 제한이 하위 최적의 결과로 이어진다 고 주장한다.우리는 교육 중 참조 정책을 업데이트하는 Trust Region DPO (TR-DPO)라는 새로운 방법을 제안합니다.이러한 간단한 업데이트를 통해 우리는 Anthropic HH 및 TLDR 데이터 세트에서 DPO에 대한 TR-DPO의 효과를 보여줍니다.우리는 TR-DPO가 GPT-4로 자동 평가에 의해 측정 된 DPO보다 최대 19%를 능가한다는 것을 보여줍니다.우리가 제안한 새로운 정렬 접근법을 통해 일관성, 정확성, 세부 수준, 도움 및 무해함과 같은 여러 매개 변수에서 모델의 품질을 한 번에 개선 할 수 있습니다.",2024.04.15,Alexey Gorbatovski&&Boris Shaposhnikov&&Alexey Malakhov&&Nikita Surnachev&&Yaroslav Aksenov&&Ian Maksimov&&Nikita Balagansky&&Daniil Gavrilov,arxiv,https://arxiv.org/abs/2404.09656
Compression Represents Intelligence Linearly,"잘 압축하는 법을 배우면 지능으로 이어질 것이라는 믿음이 있습니다.최근 언어 모델링은 압축과 동등한 것으로 나타 났으며, 이는 LLMS (Lange Language Models)의 성공을위한 강력한 이론적 근거를 제공합니다.보다 고급 언어 모델의 개발은 본질적으로 압축을 향상시켜 인텔리전스를 용이하게합니다.이러한 매력적인 토론에도 불구하고 압축과 지능 사이의 상호 작용에 대한 경험적 증거는 거의 없습니다.이 작업에서 우리는 LLM의 맥락에서 LLM을 데이터 압축기로 취급하는 관계를 조사합니다.""지능""이라는 추상적 인 개념을 고려할 때, 우리는 평균 다운 스트림 벤치 마크 점수를 대리로, 특히 지식 및 상식, 코딩 및 수학적 추론과 관련된 지능을 대상으로 채택합니다.12 개의 벤치 마크에서, 우리의 연구는 다양한 조직에서 유래 한 30 개의 공개 LLM을 모았습니다.놀랍게도, 우리는 평균 벤치 마크 점수로 반영된 LLMS의 지능이 외부 텍스트 Corpora를 압축하는 능력과 거의 선형 적으로 상관 관계가 있음을 발견했습니다.이 결과는 우수한 압축이 더 큰 지능을 나타내는 신념을 뒷받침하는 구체적인 증거를 제공합니다.또한, 우리의 연구 결과는 원시 텍스트 Corpora에서 파생 된 감독되지 않은 메트릭으로서 압축 효율이 모델 기능과 선형으로 연관된 신뢰할 수있는 평가 측정으로 작용한다는 것을 시사합니다.우리는 압축 데이터 세트와 데이터 수집 파이프 라인을 개방하여 향후 연구원이 압축을 올바르게 평가할 수 있도록합니다.",2024.04.15,Yuzhen Huang&&Jinghan Zhang&&Zifei Shan&&Junxian He,arxiv,https://arxiv.org/abs/2404.09937
Taming Latent Diffusion Model for Neural Radiance Field Inpainting,"NERF (Neural Radiance Field)는 멀티 뷰 이미지로부터의 3D 재구성을위한 표현이다.최근에 확산으로 재구성 된 NERF 편집에서 예비 성공을 보여주는 최근의 일부 작업에도 불구하고, 그들은 완전히 발견되지 않은 지역에서 합리적인 지오메트리를 합성하기 위해 고군분투하고 있습니다.주요 이유 중 하나는 확산 모델의 다양한 합성 함량이 높은 다양한 합성 함량으로, 이는 빛나는 필드가 선명하고 결정적인 기하학으로 수렴하는 것을 방해합니다.또한, 실제 데이터에 잠재 확산 모델을 적용하면 종종 자동 인코딩 오류로 인해 이미지 조건과 일관되지 않는 텍스처 이동이 생성됩니다.이 두 가지 문제는 픽셀 차량 손실을 사용하여 더욱 강화됩니다.이러한 문제를 해결하기 위해, 우리는 장면 별 사용자 정의로 확산 모델의 확률을 강화하고 마스크 된 적대 훈련으로 조직적 변화를 완화 할 것을 제안합니다.분석 과정에서, 우리는 또한 일반적으로 사용되는 픽셀과 지각 손실이 NERF 수입 작업에서 유해하다는 것을 발견했습니다.우리의 프레임 워크는 엄격한 실험을 통해 다양한 실제 장면에서 최첨단 NERF 결과를 제공합니다.프로젝트 페이지 :이 HTTPS URL",2024.04.15,Chieh Hubert Lin&&Changil Kim&&Jia-Bin Huang&&Qinbo Li&&Chih-Yao Ma&&Johannes Kopf&&Ming-Hsuan Yang&&Hung-Yu Tseng,arxiv,https://arxiv.org/abs/2404.09995
