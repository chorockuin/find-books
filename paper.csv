title,abstract,release,authors,publishers,url
Eagle and Finch : 매트릭스 값 상태와 동적 재발이있는 RWKV,우리는 RWKV (RWKV-4) 아키텍처에서 개선 된 시퀀스 모델 인 Eagle (RWKV-5) 및 Finch (RWKV-6)를 제시합니다.우리의 건축 설계 발전에는 다중 머리 매트릭스 값 상태와 RNN의 추론 효율 특성을 유지하면서 표현성을 향상시키는 동적 재발 메커니즘이 포함됩니다.우리는 1.12 조 토큰과 강화 된 다국어를위한 탐욕스러운 매칭을 기반으로 한 빠른 토큰 화기를 가진 새로운 다국어 코퍼스를 소개합니다.우리는 0.46 ~ 75 억 파라미터의 4 개의 Eagle 모델과 1.6 및 31 억 매개 변수의 2 개의 Finch 모델을 훈련 시켰으며 다양한 벤치 마크에서 경쟁력있는 성능을 달성한다는 것을 발견했습니다.Apache 2.0 라이센스에 따라 Huggingface의 모든 모델을 출시합니다.모델 :이 https urltraining code at :이 https urlinference 코드 at :이 https urltime-parallel training code at :이 https url,2024.04.08,Bo Peng&&Daniel Goldstein&&Quentin Anthony&&Alon Albalak&&Eric Alcaide&&Stella Biderman&&Eugene Cheah&&Teddy Ferdinan&&Haowen Hou&&Przemysław Kazienko&&Kranthi Kiran GV&&Jan Kocoń&&Bartłomiej Koptyra&&Satyapriya Krishna&&Ronald McClelland Jr.&&Niklas Muennighoff&&Fares Obeid&&Atsushi Saito&&Guangyu Song&&Haoqin Tu&&Stanisław Woźniak&&Ruichong Zhang&&Bingchen Zhao&&Qihang Zhao&&Peng Zhou&&Jian Zhu&&Rui-Jie Zhu,arxiv,https://arxiv.org/abs/2404.05892
CodeClm : 언어 모델을 맞춤형 합성 데이터와 정렬합니다,"명령 튜닝은 LLMS (Lange Language Models)를 특정 작업 명령어와 정렬하는 열쇠로 나타 났으며, 따라서 다음 토닉 예측 목표와 사용자의 실제 목표 사이의 불일치를 완화시킵니다.인간이 데이터를 수집하거나 주석을 달기위한 노동 및 시간 비용을 줄이기 위해 연구원들은 LLM의 사용을 탐색하여 교육 정렬 합성 데이터를 생성하기 시작합니다.최근의 연구는 다양한 지침을 생성하고 LLM을 적용하여 교육 복잡성을 높이고 종종 다운 스트림 사용 사례를 무시하는 데 중점을 둡니다.다른 대상 명령 분포 및 LLM에서 더 나은 명령어를 따르는 능력을 이끌어 내기 위해 고품질 데이터를 조정하는 방법은 확실하지 않습니다.이를 위해, 우리는 다른 다운 스트림 명령 분포 및 LLM과 LLM 정렬에 대한 고품질 합성 데이터를 적응 적으로 생성하기위한 일반적인 프레임 워크 인 CodeClm을 소개합니다.Encode-Decode 원칙을 바탕으로 LLM을 코덱으로 사용하여 데이터 생성 프로세스를 안내합니다.먼저 시드 명령어를 메타 데이터로 인코딩하는데, 이는 대상 명령 분포를 캡처하기 위해 온라인으로 생성 된 간결한 키워드 인 다음 메타 데이터를 디코딩하여 맞춤형 명령어를 작성합니다.또한 데이터 효율적인 샘플을 조정하기 위해 디코딩 중에 자기 흡기와 대조 필터링을 도입합니다.벤치 마크에 따른 4 개의 오픈 도메인 교육에 대한 광범위한 실험은 현재 최첨단 예술가에 대한 CodeClm의 효과를 검증합니다.",2024.04.08,Zifeng Wang&&Chun-Liang Li&&Vincent Perot&&Long T. Le&&Jin Miao&&Zizhao Zhang&&Chen-Yu Lee&&Tomas Pfister,arxiv,https://arxiv.org/abs/2404.05875
삼발 링고 : 큰 언어 모델을 가르치는 새로운 언어,"LLM의 광범위한 가용성에도 불구하고 다양한 언어에 걸쳐 능력과 가용성에 상당한 격차가 남아 있습니다.이러한 문제를 해결하기위한 한 가지 방법은 기존 미리 훈련 된 LLM을 취하고 새로운 언어로 계속 훈련하는 것입니다.이전 작품은 언어 적응을 실험했지만 모범 사례 및 방법론에 관한 많은 질문이 다루어지지 않았습니다.이 논문에서는 LLM을 새로운 언어에 적응시키는 것에 대한 포괄적 인 조사를 제시합니다.우리의 연구는 어휘 확장, 직접 선호도 최적화 및 저주적 언어의 인간 정렬에 대한 데이터 부족 문제를 포함 하여이 프로세스의 주요 구성 요소를 다룹니다.우리는이 실험을 9 개의 언어와 2 개의 매개 변수 척도 (7b 및 70b)에 걸쳐 확장합니다.우리는 우리의 모델을 LLAMA 2, AYA-101, XGLM, Bloom 및 기존 언어 전문가와 비교하여 이전에 게시 된 모든 기준선을 능가합니다.또한 모든 평가 코드 및 체크 포인트는 향후 연구를 촉진하기 위해 공개됩니다.",2024.04.08,Zoltan Csaki&&Bo Li&&Jonathan Li&&Qiantong Xu&&Pian Pawakapan&&Leon Zhang&&Yun Du&&Hengyu Zhao&&Changran Hu&&Urmish Thakker,arxiv,https://arxiv.org/abs/2404.05829
모방 기술 보고서,"작년에 멀티 모달 아키텍처는 AI 기반 접근 방식 및 솔루션에서 혁명을 일으켜 LLM (Lange Language Models)의 기능을 확장했습니다.시각적 양식을위한 사전 간 LLM과 어댑터를 기반으로 \ textit {omnifusion} 모델을 제안합니다.우리는 더 나은 텍스트 및 시각적 데이터 커플 링 (MLP 및 변압기 어댑터), 다양한 클립 VIT 기반 인코더 (SIGLIP, InternVit 등) 및 퓨즈 접근 방식, 이미지 인코딩 방법 (전체 이미지 또는 타일 인코딩) 및 2 개의 7B LLM (독점 및 오픈 소스 미스트랄).8 개의 시각적 언어 벤치 마크에 대한 실험은 Open-Source Llava와 같은 솔루션과 비교하여 다양한 VQA 작업과 관련하여 최고의 전능 설정 설정의 최고 점수를 보여줍니다 : Vizwiz, Pope, MM-Vet, Scienceqa, Mmbench, TextVQA, VQAV2, MMMU.또한 Omnifusion은 가정용, 관광, 문화, 의약품, 필기 및 스캔 방정식 인식 등 다양한 영역에서 고도로 분해 된 답변을 제공하는 다양한 상황을 제안합니다. Mistral 기반의 전능 행사 모델은 가중치, 교육을 가진 오픈 소스 솔루션입니다.이 HTTPS URL에서 사용 가능한 추론 스크립트.",2024.04.09,Elizaveta Goncharova&&Anton Razzhigaev&&Matvey Mikhalchuk&&Maxim Kurkin&&Irina Abdullaeva&&Matvey Skripkin&&Ivan Oseledets&&Denis Dimitrov&&Andrey Kuznetsov,arxiv,https://arxiv.org/abs/2404.06212
Magic-Boost : 멀티 뷰 조절 확산으로 3D 세대를 부스트합니다,"2D 확산 모델의 빠른 발전으로 인해 3D 컨텐츠 제작은 최근 상당한 진전을 이루었습니다.유망한 솔루션 중 하나는 미리 훈련 된 2D 확산 모델의 미세 조정을 포함하여 멀티 뷰 이미지를 생성하기위한 용량을 활용하며, 이는 Fast-Nerfs 또는 대규모 재구성 모델과 같은 방법을 통해 정확한 3D 모델로 들어 올립니다.그러나 불일치가 여전히 존재하고 생성 된 해상도가 제한되어 있기 때문에 이러한 방법의 생성 결과는 여전히 복잡한 질감과 복잡한 형상이 부족합니다.이 문제를 해결하기 위해 간단한 SDS 최적화 ($ \ SIM15 $ min)를 통해 거친 생성 결과를 크게 개선하는 다중 뷰 조절 확산 모델 인 Magic-Boost를 제안합니다.이전 텍스트 또는 단일 이미지 기반 확산 모델과 비교하여 Magic-Boost는 의사 합성 다중 뷰 이미지로부터 높은 일관성을 가진 이미지를 생성 할 수있는 강력한 기능을 보여줍니다.입력 이미지의 ID와 잘 맞는 정확한 SDS 지침을 제공하여 초기 생성 결과의 형상 및 질감 모두에서 로컬 세부 사항을 풍부하게합니다.광범위한 실험에 따르면 Magic-Boost는 거친 입력을 크게 향상시키고 풍부한 기하학적 및 조직적 세부 사항을 가진 고품질 3D 자산을 생성합니다.(프로젝트 페이지 :이 https url)",2024.04.09,Fan Yang&&Jianfeng Zhang&&Yichun Shi&&Bowen Chen&&Chenxu Zhang&&Huichao Zhang&&Xiaofeng Yang&&Jiashi Feng&&Guosheng Lin,arxiv,https://arxiv.org/abs/2404.06429
코끼리는 절대 잊지 못함 : 대형 언어 모델에서 테이블 데이터의 암기와 학습,"많은 사람들이 다양한 작업 세트에 LLM (Lange Language Model)을 적용 할 수있는 방법을 보여 주었지만 데이터 오염 및 암기의 중요한 문제는 종종 광택이 발생합니다.이 작업에서 우리는 표식 데이터에 대한이 문제를 해결합니다.구체적으로, 우리는 언어 모델이 훈련 중에 표 데이터 세트를 보았는지 여부를 평가하기 위해 다양한 다양한 기술을 소개합니다.이 조사에 따르면 LLM은 많은 대중적인 표준 데이터 세트가 구두로 암기했음을 보여줍니다.그런 다음 훈련 중에 보이는 데이터 세트에서 LLM의 소수의 학습 성능을 교육 후 출시 된 데이터 세트의 성능에 비교합니다.우리는 훈련 중에 보이는 데이터 세트에서 LLM이 더 잘 수행되며, 이는 암기가 과결을 일으킨다는 것을 나타냅니다.동시에 LLM은 새로운 데이터 세트에서 사소한 성능을 보여 주며 놀랍게도 데이터 변환에 강력합니다.그런 다음 LLM의 텍스트 내 통계 학습 능력을 조사합니다.미세 조정 없이는 제한적이라고 생각합니다.이것은 새로운 데이터 세트에서 소수의 성능이 LLM의 세계 지식 때문이라는 것을 시사합니다.전반적으로, 우리의 결과는 LLM이 사전 훈련 중에 평가 데이터 세트를 보았는지 여부를 테스트하는 것의 중요성을 강조합니다.우리는 우리가 개발 한 노출 테스트를 https url에서 tabmemcheck python 패키지로 사용할 수 있도록합니다.",2024.04.09,Sebastian Bordt&&Harsha Nori&&Vanessa Rodrigues&&Besmira Nushi&&Rich Caruana,arxiv,https://arxiv.org/abs/2404.06209
가우스 플래팅의 밀도 수정,"이 논문에서, 우리는 3D 가우시안 스플릿 (3DG)에서 적응 밀도 제어 (ADC)의 한계를 다룬다.ADC는 자동 3D 포인트 원시 관리, 밀도 화 및 가지 치열 제어를 위해 도입되었지만 밀도 로직의 특정 제한 사항이 있습니다.우리의 주요 기여는 3DG의 밀도 제어를위한보다 원칙적인 픽셀-오류 구동 공식화이며, 픽셀 당 오차 기능을 밀도의 기준으로 활용합니다.또한 장면 당 생성 된 총 프리미티브 수를 제어하는 메커니즘을 도입하고 클로닝 작업 중에 ADC의 현재 불투명도 처리 전략에서 편향을 수정합니다.우리의 접근 방식은 방법의 효율성을 희생하지 않고 다양한 벤치 마크 장면에서 일관된 품질 향상으로 이어집니다.",2024.04.09,Samuel Rota Bulò&&Lorenzo Porzi&&Peter Kontschieder,arxiv,https://arxiv.org/abs/2404.06109
MUPT : 생성 된 상징적 인 음악이 사전 변압기,"이 논문에서는 음악의 사전 훈련에 대형 언어 모델 (LLM)의 적용을 탐구합니다.음악 모델링에서 MIDI의 일반적인 사용은 잘 확립되어 있지만, 우리의 연구 결과는 LLM이 본질적으로 ABC 표기법과 더 호환되며, 이는 디자인 및 강점과 더 밀접하게 일치하여 음악 구성에서 모델의 성능을 향상시킵니다.세대 동안 다른 트랙의 잘못 정렬 된 측정과 관련된 과제를 해결하기 위해, 우리는 \ 밑줄 {s} ynchronized \ 밑줄 {m} ulti-\ 밑줄 {t} rack abc 표기법의 개발을 제안합니다 (\ textbf {smt-abc ervic relation}), 여러 뮤지컬 트랙에서 일관성을 보존하는 것을 목표로합니다.우리의 기여에는 교육 세트에서 상징적 인 음악 데이터의 90%를 다루는 최대 8192 개의 토큰을 처리 할 수있는 일련의 모델이 포함됩니다.또한, 우리는 모델 성능에 대한 \ underline {s} ymbolic \ 밑줄 {m} usic \ 밑줄 {s} caling law (\ textbf {sms law})의 의미를 탐구합니다.결과는 음악 생성에 대한 미래의 연구를위한 유망한 방향을 나타냅니다. 공개 소스 기여를 통해 커뮤니티 주도 연구를위한 광범위한 자원을 제공합니다.",2024.04.09,Xingwei Qu&&Yuelin Bai&&Yinghao Ma&&Ziya Zhou&&Ka Man Lo&&Jiaheng Liu&&Ruibin Yuan&&Lejun Min&&Xueling Liu&&Tianyu Zhang&&Xinrun Du&&Shuyue Guo&&Yiming Liang&&Yizhi Li&&Shangda Wu&&Junting Zhou&&Tianyu Zheng&&Ziyang Ma&&Fengze Han&&Wei Xue&&Gus Xia&&Emmanouil Benetos&&Xiang Yue&&Chenghua Lin&&Xu Tan&&Stephen W. Huang&&Wenhu Chen&&Jie Fu&&Ge Zhang,arxiv,https://arxiv.org/abs/2404.06393
HASH3D : 3D 세대를위한 훈련없는 가속도,"3D 생성 모델링의 진화는 2D 확산 모델의 채택에 의해 현저히 추진되어왔다.이러한 진보에도 불구하고, 성가신 최적화 프로세스 자체는 효율성에 중요한 장애물을 나타냅니다.이 논문에서는 모델 교육없이 3D 세대를위한 범용 가속 인 Hash3d를 소개합니다.HASH3D의 중심은 카메라 위치에서 렌더링 된 이미지와 근접성에서 확산 시간 단계에서 피처 맵 중복성이 널리 퍼져 있다는 통찰력입니다.주변 타임 스펙 및 카메라 각도에서 이러한 기능 맵을 효과적으로 해시하고 재사용함으로써 Hash3D는 중복 계산을 실질적으로 방지하여 3D 세대 작업에서 확산 모델의 추론을 가속화합니다.우리는 적응 형 그리드 기반 해싱을 통해이를 달성합니다.놀랍게도,이 기능 공유 메커니즘은 생성 속도를 높일뿐만 아니라 합성 된 3D 객체의 부드러운 일관성을 향상시키고 일관성을 강화합니다.5 개의 텍스트-3D 및 3 개의 이미지-3D 모델을 다루는 실험은 최적화 속도를 높이고 효율성을 1.3 ~ 4 배 향상시키는 HASH3D의 다목적 성을 보여줍니다.또한 HASH3D와 3D 가우시안 플래팅과의 통합은 3D 모델 생성 속도를 높이고 텍스트-3D 처리를 약 10 분으로 줄이고 이미지-3D 변환을 약 30 초로 줄입니다.프로젝트 페이지는이 https url입니다.",2024.04.09,Xingyi Yang&&Xinchao Wang,arxiv,https://arxiv.org/abs/2404.06091
LLM2VEC : 대형 언어 모델은 비밀리에 강력한 텍스트 인코더입니다.,"LLM (Large Decoder 전용 언어 모델)은 오늘날의 NLP 작업 및 벤치 마크의 대부분의 최신 모델입니다.그러나 커뮤니티는 텍스트 임베딩 작업을 위해 이러한 모델을 천천히 채택하고 있으며, 이는 풍부한 상황에 맞는 표현이 필요합니다.이 작업에서는 디코더 전용 LLM을 강력한 텍스트 인코더로 변환 할 수있는 단순한 감독 접근법 인 LLM2VEC를 소개합니다.LLM2VEC는 세 가지 간단한 단계로 구성됩니다. 1) 양방향주의 가능성, 2) 다음 토큰 예측, 3) 감독되지 않은 대조 학습.우리는 1.3b ~ 7b 매개 변수 범위의 3 가지 인기있는 LLM에 적용하여 LLM2VEC의 효과를 보여주고 영어 단어 및 시퀀스 수준 작업에서 변환 된 모델을 평가합니다.우리는 단어 수준 작업에 큰 마진으로 인코더 전용 모델을 능가하고 대규모 텍스트 임베드 벤치 마크 (MTEB)에서 감독되지 않은 최신 성능에 도달합니다.또한, LLM2VEC와 감독 된 대조 학습을 결합 할 때, 우리는 공개적으로 이용 가능한 데이터 만 훈련하는 모델 중에서 MTEB에 대한 최첨단 성과를 달성합니다.우리의 강력한 경험적 결과와 광범위한 분석은 값 비싼 적응 또는 합성 GPT-4 생성 데이터의 필요없이 LLM이 매개 변수 효율적인 방식으로 범용 텍스트 인코더로 효과적으로 변환 될 수 있음을 보여줍니다.",2024.04.09,Parishad BehnamGhader&&Vaibhav Adlakha&&Marius Mosbach&&Dzmitry Bahdanau&&Nicolas Chapados&&Siva Reddy,arxiv,https://arxiv.org/abs/2404.05961
MINICPM : 확장 가능한 교육 전략으로 소규모 언어 모델의 잠재력을 공개,"최대 10 조의 매개 변수로 대형 언어 모델 (LLM) 개발에 대한 급격한 관심은 자원 효율성과 실질 비용에 관한 우려와 관련이 있습니다.이 시나리오는 소규모 언어 모델 (SLMS)의 잠재력을 자원 효율적인 대안으로 탐색하는 것의 중요성을 강조합니다.이러한 맥락에서, 우리는 MINICPM, 특히 1.2B 및 2.4B 비 에비 딩 매개 변수 변형을 소개하며, 각 범주에서 탁월 할뿐만 아니라 7B-13B LLMS와 동등한 기능을 보여줍니다.SLM에 중점을 두면서 우리의 접근 방식은 미래의 LLM 연구를위한 모델 및 데이터 차원 모두에서 확장 성을 나타냅니다.모델 스케일링과 관련하여, 우리는 안정적이고 최적의 스케일링을 위해 광범위한 모델 풍동 실험을 사용합니다.데이터 스케일링의 경우, 지속적인 교육 및 도메인 적응에 도움이되는 WARMUP-STABLE-DECAY (WSD) 학습 속도 스케줄러 (LRS)를 소개합니다.우리는 WSD LRS에서 발생한 흥미로운 훈련 역학에 대한 심층 분석을 제시합니다.WSD LRS를 사용하면 모델과 데이터 축에 대한 광범위한 재교육 실험없이 데이터 모델 스케일링 법을 효율적으로 연구 할 수 있습니다. 여기서 Chinchilla 최적보다 훨씬 높은 컴퓨팅 최적의 데이터 모델 비율을 도출합니다.또한, 우리는 MINICPM-DPO, MINICPM-MOE 및 MINICPM-128K를 포함한 MINICPM 패밀리를 소개합니다.MinICPM 모델은 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.09,Shengding Hu&&Yuge Tu&&Xu Han&&Chaoqun He&&Ganqu Cui&&Xiang Long&&Zhi Zheng&&Yewei Fang&&Yuxiang Huang&&Weilin Zhao&&Xinrong Zhang&&Zheng Leng Thai&&Kaihuo Zhang&&Chongyi Wang&&Yuan Yao&&Chenyang Zhao&&Jie Zhou&&Jie Cai&&Zhongwu Zhai&&Ning Ding&&Chao Jia&&Guoyang Zeng&&Dahai Li&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.06395
Internlm-xcomposer2-4KHD : 336 픽셀에서 4K HD에서 개척하는 대형 시력 모델 처리 해상도,"LVLM (Large Vision-Language Model) 분야는 상당한 발전을 보였지만 제한된 해상도로 인해 세밀한 시각적 컨텐츠를 이해하는 데 어려움을 겪었습니다.최근의 노력은 LVLM의 고해상도 이해 기능을 향상시키기위한 노력을 기울 였지만 약 1500 x 1500 픽셀에 캡핑되어 상대적으로 좁은 해상도 범위로 제한됩니다.이 논문은 최대 4K HD (3840 x 1600) 이상의 LVLM 해상도 기능을 높이기위한 획기적인 탐사 인 Internlm-Xcomposer2-4KHD를 나타냅니다.동시에 모든 시나리오에서 초고 해상도가 필요하지 않을 수 있다는 점을 고려할 때 336 픽셀에서 4K 표준까지 다양한 해상도를 지원하여 적용 범위를 크게 확장시킵니다.구체적으로,이 연구는 자동 패치 구성을 통한 새로운 확장 : 동적 해상도를 도입하여 패치 디비전 패러다임을 발전시킵니다.훈련 이미지 종횡비를 유지하는 반면, 패치 카운트가 자동으로 변경되고 미리 훈련 된 비전 변압기 (VIT) (336 x 336)를 기반으로 레이아웃을 구성하여 336 픽셀에서 4K 표준으로 동적 훈련 해상도를 초래합니다.우리의 연구는 최대 4K HD까지 훈련 해상도를 스케일링하면 잠재적 인 개선의 천장에 도달하지 않고 일관된 성능 향상으로 이어집니다.Internlm-Xcomposer2-4KHD는 16 개의 벤치 마크 중 10 개에서 GPT-4V 및 Gemini Pro와 일치하거나 능가하는 훌륭한 기능을 보여줍니다.7B 매개 변수가있는 Internlm-Xcomposer2-4KHD 모델 시리즈는 HTTPS URL에서 공개적으로 사용할 수 있습니다.",2024.04.09,Xiaoyi Dong&&Pan Zhang&&Yuhang Zang&&Yuhang Cao&&Bin Wang&&Linke Ouyang&&Songyang Zhang&&Haodong Duan&&Wenwei Zhang&&Yining Li&&Hang Yan&&Yang Gao&&Zhe Chen&&Xinyue Zhang&&Wei Li&&Jingwen Li&&Wenhai Wang&&Kai Chen&&Conghui He&&Xingcheng Zhang&&Jifeng Dai&&Yu Qiao&&Dahua Lin&&Jiaqi Wang,arxiv,https://arxiv.org/abs/2404.06512
3D로 핸드 헬드 객체를 재구성합니다,"손에 의해 조작 된 물체 (즉, Manipulanda)는 특히 야생 RGB 이미지 나 비디오에서 재구성하기가 어렵습니다.손은 객체의 대부분을 막을뿐만 아니라 물체는 종종 소수의 이미지 픽셀에서만 볼 수 있습니다.동시에이 설정에서 두 개의 강한 앵커가 나타납니다. (1) 3D 손이 물체의 위치와 스케일을 명확하게하는 데 도움이되며 (2) Manipulanda 세트는 가능한 모든 물체에 비해 작습니다.이러한 통찰력을 염두에두고, 우리는 큰 언어/비전 모델 및 3D 객체 데이터 세트의 최근 혁신을 바탕으로 핸드 헬드 객체 재구성을위한 확장 가능한 패러다임을 제시합니다.우리의 모델 MCC-Hand-Bobject (MCC-HO)는 단일 RGB 이미지와 3D 핸드를 입력으로 유추하여 손과 물체 구조를 공동으로 재구성합니다.그 후, 우리는 GPT-4 (v)를 사용하여 이미지의 객체와 일치하는 3D 객체 모델을 검색하고 모델을 네트워크에 인출 된 지오메트리에 엄격하게 정렬합니다.우리는이 정렬 검색 재구성 재구성 (RAR)이라고합니다.실험에 따르면 MCC-HO는 실험실 및 인터넷 데이터 세트에서 최첨단 성능을 달성하고 RAR을 사용하여 손으로 객체 상호 작용의 야만적 인 이미지에 대한 3D 레이블을 자동으로 얻는 방법을 보여줍니다.",2024.04.09,Jane Wu&&Georgios Pavlakos&&Georgia Gkioxari&&Jitendra Malik,arxiv,https://arxiv.org/abs/2404.06507
