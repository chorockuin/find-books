title,abstract,release,authors,publishers,url
DressCode: Autoregressively Sewing and Generating Garments from Text Guidance,"인간의 외모에서 의류의 중요한 역할은 디지털 인간 창조를위한 의류 디지털화의 중요성을 강조합니다.3D 컨텐츠 생성의 최근 발전은 디지털 인간 생성에 중추적입니다.그럼에도 불구하고 텍스트 안내로 인한 의복 생성은 여전히 초기입니다.우리는 텍스트 중심의 3D 의류 생성 프레임 워크 인 드레스 코드를 소개합니다.이 드레스 코드는 초보자를위한 디자인을 민주화하고 패션 디자인, 가상 시도 및 디지털 인간 생성에서 엄청난 잠재력을 제공합니다.우리는 먼저 텍스트 조건부 임베딩과 교차 변호를 통합하는 GPT 기반 아키텍처 인 SewingGpt를 소개하여 텍스트 안내로 재봉 패턴을 생성합니다.그런 다음 사전 훈련 된 안정적인 확산을 조정하여 의복에 대한 타일 기반 물리적 기반 렌더링 (PBR) 텍스처를 생성합니다.큰 언어 모델을 활용하여 당사의 프레임 워크는 자연어 상호 작용을 통해 CG 친화적 인 의류를 생성합니다.또한 패턴 완료 및 텍스처 편집을 용이하게하여 사용자 친화적 인 상호 작용을 통해 설계 프로세스를 간소화합니다.이 프레임 워크는 제작자가 디자인을 자유롭게 실험하고 고유 한 요소를 작업에 통합 할 수 있도록함으로써 혁신을 장려합니다.포괄적 인 평가와 다른 최첨단 방법과의 비교를 통해 우리의 방법은 우수한 품질과 입력 프롬프트와의 정렬을 보여줍니다.사용자 연구는 우리의 고품질 렌더링 결과를 추가로 검증하여 생산 환경에서 실질적인 유틸리티와 잠재력을 강조합니다.우리의 프로젝트 페이지는 https url입니다.",2024.01.29,Kai He&&Kaixin Yao&&Qixuan Zhang&&Lingjie Liu&&Jingyi Yu&&Lan Xu,arxiv,https://arxiv.org/abs/2401.16465
HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections,"사진가들이 캡처 한 사진이 포함 된 인터넷 이미지 컬렉션은 대규모 관광 랜드 마크의 디지털 탐사를 가능하게하는 약속을 보여줍니다.그러나 이전 작업은 주로 기하학적 재구성 및 시각화에 중점을 두어 항법 및 세밀한 이해를위한 시맨틱 인터페이스를 제공하는 데있어 언어의 주요 역할을 무시합니다.제한된 3D 도메인에서, 최근의 방법은 2D 시각적 의미의 강력한 이전의 비전 및 언어 모델을 활용했습니다.이 모델은 광범위한 시각적 의미론에 대한 훌륭한 이해를 보여 주지만, 건축 영역에 대한 전문 지식이 부족하기 때문에 이러한 관광 랜드 마크를 묘사하는 구속되지 않은 사진 컬렉션으로 어려움을 겪고 있습니다.이 작업에서, 우리는 대규모 랜드 마크를 묘사 한 장면의 신경 표현을 랜드 마크 장면 시맨틱을 이해하기위한 적응을 위해 SOTA 비전 및 언어 모델의 힘을 활용함으로써 장면의 시맨틱 영역을 설명하는 텍스트를 연결하는 현지화 시스템을 제시합니다.세분화 된 지식으로 이러한 모델을 강화하기 위해 우리는 약한 관련 텍스트 정보와 함께 유사한 랜드 마크의 이미지가 포함 된 대규모 인터넷 데이터를 활용합니다.우리의 접근 방식은 우주에 물리적으로 접지 된 이미지가 새로운 개념을 현지화하기위한 강력한 감독 신호를 제공 할 수 있다는 전제에 기반을두고 있습니다.우리는 장면보기 사이의 서신을 사용하여 이러한 의미론에 대한 공간적 이해를 부트 스트랩하여 3D 호환 세분화에 대한 지침을 제공하여 궁극적으로 볼륨 장면 표현으로 들어 올립니다.우리의 결과 Halo-Nerf는 건축 랜드 마크와 관련된 다양한 시맨틱 개념을 정확하게 현지화 할 수 있으며, 다른 3D 모델의 결과와 강력한 2D 세분화 기준선의 결과를 능가합니다.우리의 프로젝트 페이지는 https url입니다.",2024.02.14,Chen Dudai&&Morris Alper&&Hana Bezalel&&Rana Hanocka&&Itai Lang&&Hadar Averbuch-Elor,arxiv,https://arxiv.org/abs/2404.16845
Automatic Creative Selection with Cross-Modal Matching,"애플리케이션 개발자는 앱 이미지가있는 제품 페이지를 만들고 검색어에 입찰하여 앱을 광고합니다.그런 다음 앱 이미지가 검색어와 매우 관련이있는 것이 중요합니다.이 문제에 대한 솔루션에는 선택한 이미지와 검색어 사이의 일치 품질을 예측하기 위해 이미지 텍스트 매칭 모델이 필요합니다.이 작업에서는 사전 훈련 된 LXMERT 모델을 미세 조정하는 데 기반한 앱 이미지를 검색 용어와 일치시키는 새로운 접근 방식을 제시합니다.우리는 클립 모델과 검색어에 대한 변압기 모델과 이미지의 RESNET 모델을 사용한 기준선과 비교하여 일치하는 정확도를 크게 향상시킵니다.주어진 응용 프로그램에 대한 광고주 연관 (이미지, 검색 용어) 쌍의 두 가지 레이블 세트를 사용하여 접근 방식을 평가합니다.우리의 접근 방식은 광고주 관련 지상 진실의 0.96 AUC 점수를 달성하여 변압기+RESNET 기준선과 미세 조정 된 클립 모델을 8% 및 14% 성능이 우수합니다.인간의 라벨링 된 Ground Truth의 경우, 우리의 접근 방식은 0.95 AUC 점수를 달성하여 변압기+RESNET 기준선과 미세 조정 된 클립 모델을 16% 및 17%보다 우수합니다.",2024.02.28,Alex Kim&&Jia Huang&&Rob Monarch&&Jerry Kwac&&Anikesh Kamath&&Parmeshwar Khurd&&Kailash Thiyagarajan&&Goodman Gu,arxiv,https://arxiv.org/abs/2405.00029
Scaling Instructable Agents Across Many Simulated Worlds,"모든 3D 환경에서 임의의 언어 지침을 따를 수있는 구체화 된 AI 시스템을 구축하는 것은 일반 AI를 만드는 데 중요한 과제입니다.이 목표를 달성하려면 복잡한 작업을 달성하기 위해 인식과 구체화 된 행동으로 언어를 배우는 것이 필요합니다.확장 가능하고 지시 가능한 Multiworld Agent (SIMA) 프로젝트는 훈련 에이전트가 선별 된 연구 환경뿐만 아니라 개방형 상업용 비디오 게임을 포함하여 다양한 가상 3D 환경에서 자유 형식 지침을 따르도록 교육 에이전트에 의해이를 해결합니다.우리의 목표는 인간이 시뮬레이션 된 3D 환경에서 할 수있는 일을 성취 할 수있는 지시 가능한 에이전트를 개발하는 것입니다.우리의 접근 방식은 언어 중심의 일반성에 중점을 두면서 최소한의 가정을 부과합니다.당사의 에이전트는 일반적인 인간과 같은 인터페이스를 사용하여 실시간으로 환경과 상호 작용합니다. 입력은 이미지 관찰 및 언어 지침이며 출력은 키보드 및 마우스 작업입니다.이 일반적인 접근 방식은 어렵지만, 에이전트는 시각적으로 복잡하고 의미 적으로 풍부한 많은 환경에서 언어를 접지 할 수있게하며 새로운 환경에서 에이전트를 쉽게 운영 할 수 있습니다.이 논문에서 우리는 우리의 동기와 목표, 우리가 만든 초기 진보, 여러 가지 다양한 연구 환경과 다양한 상업용 비디오 게임에서 유망한 예비 결과를 설명합니다.",2024.03.13,SIMA Team&&Maria Abi Raad&&Arun Ahuja&&Catarina Barros&&Frederic Besse&&Andrew Bolt&&Adrian Bolton&&Bethanie Brownfield&&Gavin Buttimore&&Max Cant&&Sarah Chakera&&Stephanie C. Y. Chan&&Jeff Clune&&Adrian Collister&&Vikki Copeman&&Alex Cullum&&Ishita Dasgupta&&Dario de Cesare&&Julia Di Trapani&&Yani Donchev&&Emma Dunleavy&&Martin Engelcke&&Ryan Faulkner&&Frankie Garcia&&Charles Gbadamosi&&Zhitao Gong&&Lucy Gonzales&&Kshitij Gupta&&Karol Gregor&&Arne Olav Hallingstad&&Tim Harley&&Sam Haves&&Felix Hill&&Ed Hirst&&Drew A. Hudson&&Jony Hudson&&Steph Hughes-Fitt&&Danilo J. Rezende&&Mimi Jasarevic&&Laura Kampis&&Rosemary Ke&&Thomas Keck&&Junkyung Kim&&Oscar Knagg&&Kavya Kopparapu&&Andrew Lampinen&&Shane Legg&&Alexander Lerchner&&Marjorie Limont&&Yulan Liu&&Maria Loks-Thompson&&Joseph Marino&&Kathryn Martin Cussons&&Loic Matthey&&Siobhan Mcloughlin&&Piermaria Mendolicchio&&Hamza Merzic&&Anna Mitenkova&&Alexandre Moufarek&&Valeria Oliveira&&Yanko Oliveira&&Hannah Openshaw&&Renke Pan&&Aneesh Pappu&&Alex Platonov&&Ollie Purkiss&&David Reichert&&John Reid&&Pierre Harvey Richemond&&Tyson Roberts&&Giles Ruscoe&&Jaume Sanchez Elias&&Tasha Sandars&&Daniel P. Sawyer&&Tim Scholtes&&Guy Simmons&&Daniel Slater&&Hubert Soyer&&Heiko Strathmann&&Peter Stys&&Allison C. Tam&&Denis Teplyashin&&Tayfun Terzi&&Davide Vercelli&&Bojan Vujatovic&&Marcus Wainwright&&Jane X. Wang&&Zhengdong Wang&&Daan Wierstra&&Duncan Williams&&Nathaniel Wong&&Sarah York&&Nick Young,arxiv,https://arxiv.org/abs/2404.10179
FlowMind: Automatic Workflow Generation with LLMs,"RPA (Robotic Process Automation)의 빠르게 진화하는 분야는 반복 프로세스를 자동화하는 데 상당한 진전을 이루었지만 사용자가 요구하는 자발적 또는 예측할 수없는 작업이 필요한 시나리오에서 효과가 감소합니다.이 논문은 Flowmind, Flowmind, GPT (Generative Pretrained Transformer)와 같은 LLM (Lange Language Models)의 기능을 활용 하여이 제한을 해결하고 자동 워크 플로 생성 시스템을 생성합니다.FlowMind에서는 안정적인 응용 프로그램 프로그래밍 인터페이스 (API)로 LLM 추론을 지적하는 데 도움이되는 강의를위한 일반적인 프롬프트 레시피를 제안합니다.이를 통해 Flowmind는 LLM에서 환각의 일반적인 문제를 완화 할뿐만 아니라 LLMS와 독점 데이터 또는 코드 간의 직접적인 상호 작용을 제거하여 정보의 무결성과 기밀성 (금융 서비스의 초석)을 보장합니다.Flowmind는 자동 생성 워크 플로에 대한 높은 수준의 설명을 제시하여 사용자 상호 작용을 더욱 단순화하여 사용자가 효과적으로 검사하고 피드백을 제공 할 수 있도록합니다.또한 NCEN-QA는 자금에 대한 N-CEN 보고서의 질문 분석 작업을 벤치마킹하기위한 새로운 데이터 세트 인 NCEN-QA를 소개합니다.우리는 NCEN-QA를 사용하여 유량의 기준선 및 절제 변형에 대한 흐름에 의해 생성 된 워크 플로의 성능을 평가했습니다.우리는 Flowmind의 성공, 제안 된 강의 레시피에서 각 구성 요소의 중요성, Flowmind에서 사용자 상호 작용 및 피드백의 효과를 보여줍니다.",2024.03.17,Zhen Zeng&&William Watson&&Nicole Cho&&Saba Rahimi&&Shayleen Reynolds&&Tucker Balch&&Manuela Veloso,arxiv,https://arxiv.org/abs/2404.13050
RL for Consistency Models: Faster Reward Guided Text-to-Image Generation,"강화 학습 (RL)은 이미지 품질, 미학 및 지시 기능을 포착하는 보상을 직접 최적화함으로써 확산 모델로 가이드 이미지 생성을 개선했습니다.그러나 생성 된 생성 정책은 생성이 느리게 발생하는 확산 모델의 동일한 반복 샘플링 프로세스를 상속합니다.이러한 제한을 극복하기 위해 일관성 모델은 노이즈를 데이터에 직접 매핑하는 새로운 클래스의 생성 모델을 학습 할 것을 제안하여 하나의 샘플링 반복만큼 이미지를 생성 할 수있는 모델을 만들었습니다.이 작업에서 작업 별 보상을위한 텍스트-이미지 생성 모델을 최적화하고 빠른 교육 및 추론을 가능하게하기 위해 RL을 통해 미세 조정 일관성 모델을위한 프레임 워크를 제안합니다.RLCM (Renpercement Learning)이라고하는 우리의 프레임 워크는 일관성 모델의 반복 추론 프로세스를 RL 절차로 프레임합니다.RLCM은 텍스트-이미지 생성 기능에 대한 RL 미세 조정 확산 모델을 개선하고 샘플 품질에 대한 추론 시간 동안 계산을 거래합니다.실험적으로, 우리는 RLCM이 텍스트-이미지 일관성 모델을 이미지 압축성과 같은 프롬프트로 표현하기가 어렵고 미학적 품질과 같은 인간의 피드백에서 파생 된 목표에 적응할 수 있음을 보여줍니다.RLCM 트레인은 RL 미세 확산 모델과 비교하여 상당히 빠르게 열차를 만들고 보상 목표에서 측정 된 생성의 품질을 향상 시키며, 두 가지 추론 단계만으로 고품질 이미지를 생성하여 추론 절차를 가속화시킵니다.우리의 코드는 https url에서 사용할 수 있습니다",2024.03.25,Owen Oertell&&Jonathan D. Chang&&Yiyi Zhang&&Kianté Brantley&&Wen Sun,arxiv,https://arxiv.org/abs/2404.03673
Localizing Paragraph Memorization in Language Models,"우리는 언어 모델이 사용하는 무게와 메커니즘을 교육 데이터의 전체 단락을 암기하고 암송 할 수 있습니까?이 논문에서, 우리는 암기가 여러 계층과 모델 구성 요소에 걸쳐 퍼지는 동안 암기 된 단락의 그라디언트는 구별 가능한 공간 패턴을 가지며, 비-원형 예제의 그라디언트보다 낮은 모델 층에서 더 크다는 것을 보여준다.더욱이, 암기 된 예제는 고 그라디언트 가중치 만 미세 조정함으로써 배우지 못할 수있다.우리는 특히 단락 암기에 관여하는 것으로 보이는 저층 주의적 헤드를 현지화합니다.이 헤드는 주로 코퍼스 수준의 유니그램 분포에서 가장 빈번한 독특하고 희귀 한 토큰에 관심을 집중하고 있습니다.다음으로, 우리는 토큰을 교란시키고 디코딩의 원인 변화를 측정함으로써 접두사의 토큰을 가로 질러 국소화 된 암기가 어떻게 진행되는지 연구합니다.접두사 초기에 몇 가지 독특한 토큰은 종종 전체 연속을 손상시킬 수 있습니다.전반적으로, 암기 된 연속은 배우기가 더 어려울뿐만 아니라 무모하지 않은 것보다 손상되기에도 불구하고.",2024.03.28,Niklas Stoehr&&Mitchell Gordon&&Chiyuan Zhang&&Owen Lewis,arxiv,https://arxiv.org/abs/2403.19851
Jamba: A Hybrid Transformer-Mamba Language Model,"우리는 새로운 하이브리드 트랜스포머 -Mamba Mix-of-Experts (MOE) 아키텍처를 기반으로 새로운 기본 대형 언어 모델 인 Jamba를 제시합니다.구체적으로, Jamba는 변압기 및 Mamba 층의 블록을 인터리브하여 두 모델 패밀리의 이점을 누립니다.MOE는 이러한 레이어 중 일부에 추가되어 활성 매개 변수 사용을 유지하면서 모델 용량을 증가시킵니다.이 유연한 아키텍처는 리소스 및 객관적 특정 구성을 허용합니다.우리가 구현 한 특정 구성에서는 단일 80GB GPU에 적합한 강력한 모델로 끝납니다.Jamba는 대규모로 구축 된 바닐라 변압기에 비해 높은 처리량과 작은 메모리 풋 프린트를 제공하며 동시에 표준 언어 모델 벤치 마크 및 장기 텍스트 평가에서 최첨단 성능을 제공합니다.놀랍게도이 모델은 최대 256k 토큰 컨텍스트 길이에 대한 강력한 결과를 제공합니다.우리는 변압기와 Mamba 계층을 결합하는 방법과 전문가를 혼합하는 방법과 같은 다양한 건축 결정을 연구하고 일부는 대규모 모델링에서 중요하다는 것을 보여줍니다.우리는 또한 Jamba의 훈련과 평가가 공개 한이 아키텍처의 몇 가지 흥미로운 속성을 설명하고,이 새로운 건축에 대한 추가 탐색을 장려하기 위해 다양한 절제 실행에서 검문소를 공개 할 계획입니다.우리는 jamba 구현의 가중치를 허용 라이센스로 공개적으로 제공합니다.",2024.03.28,Opher Lieber&&Barak Lenz&&Hofit Bata&&Gal Cohen&&Jhonathan Osin&&Itay Dalmedigos&&Erez Safahi&&Shaked Meirom&&Yonatan Belinkov&&Shai Shalev-Shwartz&&Omri Abend&&Raz Alon&&Tomer Asida&&Amir Bergman&&Roman Glozman&&Michael Gokhman&&Avashalom Manevich&&Nir Ratner&&Noam Rozen&&Erez Shwartz&&Mor Zusman&&Yoav Shoham,arxiv,https://arxiv.org/abs/2403.19887
ReALM: Reference Resolution As Language Modeling,"참조 해상도는 중요한 문제로, 다른 종류의 맥락을 이해하고 성공적으로 처리하는 데 필수적인 문제입니다.이러한 컨텍스트에는 사용자 화면의 엔터티 또는 백그라운드에서 실행되는 것과 같은 비 변환 엔티티와 관련된 이전 회전 및 컨텍스트가 모두 포함됩니다.LLM은 다양한 작업에 대해 매우 강력한 것으로 나타 났지만, 참조 해상도, 특히 비 변환 엔티티의 경우 사용은 여전히 활용되지 않았습니다.이 논문은 전통적으로 도움이되지 않는 화면의 엔터티 형태를 포함하더라도 LLMS가 다양한 유형의 참조를 해결하기 위해 매우 효과적인 시스템을 만들기 위해 다양한 유형의 참조를 해결하는 데 사용되는 방법을 보여줍니다.텍스트 전용 양식으로 줄어 듭니다.우리는 다양한 유형의 참조에 걸쳐 유사한 기능을 갖춘 기존 시스템에 비해 크게 개선되었으며, 가장 작은 모델은 화면 참조에 대해 5% 이상의 절대 이득을 얻습니다.우리는 또한 GPT-3.5 및 GPT-4에 대한 벤치 마크를 벤치마킹하며, 가장 작은 모델은 GPT-4의 성능과 비교할 수있는 성능을 달성하고 더 큰 모델이 실질적으로 성능이 우수합니다.",2024.03.29,Joel Ruben Antony Moniz&&Soundarya Krishnan&&Melis Ozyildirim&&Prathamesh Saraf&&Halim Cagri Ates&&Yuan Zhang&&Hong Yu&&Nidhi Rajshree,arxiv,https://arxiv.org/abs/2403.20329
"Snap-it, Tap-it, Splat-it: Tactile-Informed 3D Gaussian Splatting for Reconstructing Challenging Surfaces","터치와 비전은 손을 잡고 세상을 이해하는 능력을 상호 향상시킵니다.연구 관점에서, 터치와 비전을 믹싱하는 문제는 미숙 한 것이며 흥미로운 도전을 제시합니다.이를 위해, 우리는 표면 재구성 및 새로운 뷰 합성을 달성하기 위해 다중 뷰 비전 데이터와 함께 터치 데이터 (로컬 깊이 맵)를 포함하는 새로운 접근법 인 촉각 정보 3DG를 제안합니다.우리의 방법은 3D 가우시안 프리미티브를 최적화하여 접촉 지점에서 물체의 형상을 정확하게 모델링합니다.터치 위치에서의 전송을 감소시키는 프레임 워크를 만들어 정제 된 표면 재구성을 달성하여 균일하게 부드러운 깊이 맵을 보장합니다.현대의 방법은 충실도 스펙 하이라이트로 재구성하는 경향이 있기 때문에 터치는 비 램버트 물체 (예 : 반짝 반응 또는 반사 표면)를 고려할 때 특히 유용합니다.시력과 촉각 감지를 결합하여 이전 방법보다 이미지가 적은 정확한 지오메트리 재구성을 달성합니다.우리는 광택과 반사 표면이있는 물체에 대한 평가를 수행하고 접근 방식의 효과를 보여 주며 재구성 품질이 크게 향상됩니다.",2024.03.29,Mauro Comi&&Alessio Tonioni&&Max Yang&&Jonathan Tremblay&&Valts Blukis&&Yijiong Lin&&Nathan F. Lepora&&Laurence Aitchison,arxiv,https://arxiv.org/abs/2403.20275
Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models,"이 논문은 해결할 수없는 문제 탐지 (UPD)라고 불리는 VLMS (Vision Language Models)에 대한 참신하고 중요한 도전을 소개합니다.UPD는 VQA (Visual Turysing Answering) 작업의 맥락에서 해결할 수없는 문제에 직면 할 때 VLM의 답변을 보류하는 능력을 조사합니다.Upd는 세 가지 별개의 설정을 포함합니다 : AAD (Assent Answer Detection), 호환되지 않는 답변 세트 감지 (IASD) 및 호환되지 않는 시각적 질문 감지 (IVQD)가 포함됩니다.Upd 문제를 깊이 조사하기 위해 광범위한 실험에 따르면 GPT-4V 및 LLAVA-NEXT-34B를 포함한 대부분의 VLM은 벤치 마크와 다양한 범위로 고생하여 개선을위한 중요한 공간을 강조합니다.UPD를 해결하기 위해 우리는 교육이없는 교육 기반 솔루션을 모두 탐색하여 효과와 한계에 대한 새로운 통찰력을 제공합니다.제안 된 UPD 설정 내에서 미래의 노력과 함께 우리의 통찰력이보다 실용적이고 신뢰할 수있는 VLM의 광범위한 이해와 개발을 향상시키기를 바랍니다.",2024.03.29,Atsuyuki Miyai&&Jingkang Yang&&Jingyang Zhang&&Yifei Ming&&Qing Yu&&Go Irie&&Yixuan Li&&Hai Li&&Ziwei Liu&&Kiyoharu Aizawa,arxiv,https://arxiv.org/abs/2403.20331
MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection,"딥 러닝의 최근 발전은 주로 데이터 의존성과 규모로 학습 능력으로 인해 변압기에 의존했습니다.그러나 이러한 아키텍처의주의 모듈은 입력 크기의 2 차 시간과 공간을 보여 주어 긴 시퀀스 모델링에 대한 확장 성을 제한합니다.이미지 및 다변량 시계열과 같은 다차원 데이터에 대한 효율적이고 효과적인 아키텍처 백본을 설계하려는 최근의 시도에도 불구하고 기존 모델은 데이터 독립적이거나 차원 내 및 차원 내 통신을 허용하지 못합니다.최근에, SSMS (State Space Models),보다 구체적으로 선택적인 상태 공간 모델은 효율적인 하드웨어 인식 구현을 통해 긴 시퀀스 모델링에 대한 유망한 잠재력을 보여 주었다.SSMS의 성공에 의해 동기 부여 된 우리는 선택적 토큰 및 채널 믹서라고하는 토큰 및 채널에서 이중 선택 메커니즘을 사용하는 데이터 의존성 가중치를 가진 새로운 아키텍처 인 Mambamixer를 제시합니다.Mambamixer는 가중 평균화 메커니즘을 사용하여 선택적 믹서를 연결하여 층이 초기 기능에 직접 액세스 할 수 있도록합니다.개념 증명으로서, 우리는 Mambamixer 블록을 기반으로 한 Vision Mambamixer (VIM2) 및 시계열 Mambamixer (TSM2) 아키텍처를 설계하고 다양한 비전 및 시계열 예측 작업에서 성능을 탐색합니다.우리의 결과는 토큰과 채널에서 선택적 혼합의 중요성을 강조합니다.ImageNet 분류, 객체 감지 및 시맨틱 세분화 작업에서 VIM2는 잘 확립 된 비전 모델과 SSM 기반 비전 모델보다 경쟁력있는 성능을 달성합니다.시계열 예측에서 TSM2는 최첨단 방법에 비해 뛰어난 성능을 달성하면서 계산 비용이 크게 향상되었습니다.이러한 결과는 변압기, 교차 채널주의 및 MLP가 시계열 예측에서 우수한 성능에 충분하지만 필요하지 않다는 것을 보여줍니다.",2024.03.29,Ali Behrouz&&Michele Santacatterina&&Ramin Zabih,arxiv,https://arxiv.org/abs/2403.19888
InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds,"NVS (Novel View Synthesis)는 3D 컴퓨터 비전에서 상당한 진전을 보였지만, 일반적으로 조밀 한 관점에서 카메라 내재 및 외계의 초기 추정이 필요합니다.이 사전 처리는 일반적으로 SFM (structure-from-motion) 파이프 라인을 통해 수행됩니다. 특히 정확한 재구성을 위해 일치하는 기능이 불충분 한 드문 뷰 시나리오에서 느리고 신뢰할 수없는 절차입니다.이 작업에서는 포인트 기반 표현의 강점 (예 : 3D 가우시안 스플릿, 3D-GS)을 엔드 투 엔드 빽빽한 스테레오 모델 (Dust3R)과 통합하여 구속되지 않은 설정에서 NVS에서 복잡하지만 해결되지 않은 문제를 해결합니다.포즈가없고 드문 뷰 도전을 포함합니다.우리의 프레임 워크 인 instantsplat는 3D-GS로 밀집된 스테레오 프라이어를 통합하여 Sparseview와 Pose-Free 이미지에서 대규모 장면의 3D 가우시안을 1 분 이내에 구축합니다.구체적으로, InstantSPlat은 사전 훈련 된 조밀 한 스테레오 파이프 라인에서 파생 된 전 세계적으로 정렬 된 3D 포인트 맵을 활용하여 모든 훈련보기에서 예비 장면 구조와 카메라 매개 변수를 신속하게 설정하는 CGI (Cuarse Geometric Anitiblization) 모듈로 구성됩니다.그 다음에는 3D 가우시안 속성과 초기화 된 포즈를 포즈 정규화로 최적화하는 빠른 3D-Gaussian 최적화 (F-3DGO) 모듈이 이어집니다.대규모 실외 탱크 및 사원 데이터 세트에서 수행 된 실험은 InstantSPlat이 SSIM (32%)을 크게 향상시키는 동시에 절대 궤적 오류 (ATE)를 80%감소 시킨다는 것을 보여줍니다.이들은 인스턴트 플랫을 포즈프리 및 드문 뷰 조건과 관련된 시나리오에 대한 실행 가능한 솔루션으로 설정합니다.프로젝트 페이지 :이 HTTP URL.",2024.03.29,Zhiwen Fan&&Wenyan Cong&&Kairun Wen&&Kevin Wang&&Jian Zhang&&Xinghao Ding&&Danfei Xu&&Boris Ivanovic&&Marco Pavone&&Georgios Pavlakos&&Zhangyang Wang&&Yue Wang,arxiv,https://arxiv.org/abs/2403.20309
DiJiang: Efficient Large Language Models through Compact Kernelization,"변압기의 계산 부하를 줄이기 위해 선형주의에 대한 연구는 상당한 추진력을 얻었습니다.그러나주의 메커니즘에 대한 개선 전략은 일반적으로 광범위한 재교육을 필요로하며, 이는 광범위한 매개 변수를 가진 대형 언어 모델에 비현실적입니다.이 논문에서, 우리는 미리 훈련 된 바닐라 변압기를 훈련 비용이 거의없는 선형 복잡성 모델로 변환 할 수있는 새로운 주파수 도메인 커널 화 접근법 인 Dijiang을 제시한다.샘플링을위한 가중 준 몬테 카를로 방법을 사용함으로써, 제안 된 접근법은 이론적으로 우수한 근사 효율을 제공합니다.훈련 계산 복잡성을 추가로 줄이기 위해, 우리의 커널은 DCT (Decrete Cosine Transform) 작업을 기반으로합니다.광범위한 실험은 제안 된 방법이 원래 변압기와 비슷한 성능을 달성하지만 훈련 비용이 크게 줄어들고 추론 속도가 훨씬 빨라짐을 보여줍니다.우리의 Dijiang-7b는 다양한 벤치 마크에서 LLAMA2-7B와 비슷한 성능을 달성하는 반면 약 1/50 교육 비용 만 필요합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.03.29,Hanting Chen&&Zhicheng Liu&&Xutao Wang&&Yuchuan Tian&&Yunhe Wang,arxiv,https://arxiv.org/abs/2403.19928
Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs,"LLM (Lange Language Model)은 지능적인 비서, 텍스트 요약, 번역 및 휴대 전화의 다중 유체와 같은 작업에 널리 사용됩니다.그러나 현재 기기 LLM 배포에 대한 현재 방법은 느린 추론 속도를 유지하여 사용자 경험이 좋지 않습니다.장치 GPU에 대한 고효율 LLM 배치를 촉진하기 위해, 우리는 4 가지 최적화 기술을 제안합니다. (a) 동적 모양 모델 추론을 지원하기위한 상징적 표현 기반 접근;(b) 추론 속도를 높이고 전화 지연을 줄이기위한 운영자 최적화 및 실행 우선 순위 설정;(c) Dequantization 오버 헤드를 감소시키기 위해 M0E4라고 불리는 FP4 양자화 방법;(d) LLM 추론 후 KV 캐시를 복사 할 필요가 없도록 하위 기관 기반 기술.또한 Qualcomm 및 MTK 프로세서와 호환되는 모바일 추론 엔진 인 Transformer-Lite에서 이러한 방법을 구현합니다.우리는 2B에서 14B 범위의 다양한 아키텍처 및 매개 변수를 갖춘 LLM을 사용하여 Transformer-Lite의 성능을 평가했습니다.구체적으로, 우리는 ChatGLM2 6B의 경우 121 토큰 및 14 토큰/s의 프리 필드 및 디코딩 속도, 작은 젬마 2B의 경우 각각 330 개의 토큰/s 및 30 토큰/s를 달성했습니다.CPU 기반 Fastllm 및 GPU 기반 MLC-LLM과 비교하여 엔진은 프리 필 속도를 위해 10 배 이상의 속도를 높이고 디코딩 속도의 2 ~ 3 배 속도를 달성합니다.",2024.03.29,Luchang Li&&Sheng Qian&&Jie Lu&&Lunxi Yuan&&Rui Wang&&Qin Xie,arxiv,https://arxiv.org/abs/2403.20041
Gecko: Versatile Text Embeddings Distilled from Large Language Models,"우리는 Gecko, 작고 다재다능한 텍스트 임베딩 모델을 제시합니다.Gecko는 대형 언어 모델 (LLM)의 지식을 리트리버로 증류시켜 핵심 아이디어를 활용하여 강력한 검색 성능을 달성합니다.우리의 2 단계 증류 프로세스는 LLM을 사용하여 다양한 합성 쌍 데이터를 생성하는 것으로 시작합니다.다음으로, 우리는 각 쿼리에 대한 후보 구절 세트를 검색하고 동일한 LLM을 사용하여 긍정적이고 단단한 음수 구절을 재사용하여 데이터 품질을 더욱 개선합니다.우리의 접근 방식의 효과는 Gecko의 작품에 의해 입증됩니다.MTEB (Massive Text Embedding Benchmark)에서 256 개의 임베딩 치수를 가진 Gecko는 768 개의 임베딩 크기로 기존의 모든 항목을 능가합니다.768 개의 임베딩 치수를 가진 Gecko는 평균 점수 66.31을 달성하여 7 배 큰 모델과 5 배 높은 차원 임베딩과 경쟁합니다.",2024.03.29,Jinhyuk Lee&&Zhuyun Dai&&Xiaoqi Ren&&Blair Chen&&Daniel Cer&&Jeremy R. Cole&&Kai Hui&&Michael Boratko&&Rajvi Kapadia&&Wen Ding&&Yi Luan&&Sai Meher Karthik Duddu&&Gustavo Hernandez Abrego&&Weiqiang Shi&&Nithi Gupta&&Aditya Kusupati&&Prateek Jain&&Siddhartha Reddy Jonnalagadda&&Ming-Wei Chang&&Iftekhar Naim,arxiv,https://arxiv.org/abs/2403.20327
LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model,"우리는 최근 출시 된 Gemma Family of Langer Language Models (LLM)와 함께 인기있는 LLAVA 프레임 워크를 사용하여 MMFM (Multimodal Foundation Models)을 훈련시킵니다.특히 관심있는 2B 매개 변수 Gemma 모델은 유능한 소규모 MMFM을 구성 할 수있는 기회를 제공합니다.이 공간의 다른 논문의 결과에 따라, 우리는 세 가지 디자인 기능을 절제하는 효과를 테스트하고, 커넥터 전망,보다 강력한 이미지 백본을 활용하며 언어 백본의 크기를 높입니다.Llava-Gemma라고 부르는 결과 모델은 다양한 평가에서 중간 정도의 성능을 보여 주지만 현재 비교적 크기의 SOTA 모델을 지나서 개선하지 못합니다.성능에 대한 면밀한 분석은 혼합 효과를 보여줍니다.프리 트레인을 건너 뛰는 것은 성능을 줄이는 경향이 있으며, 더 큰 비전 모델은 때때로 성능을 향상 시키며 언어 모델 크기를 증가시키는 것은 일관성이없는 영향을 미칩니다.우리는 Llava-Gemma 모델의 모델에 대한 교육 레시피, 코드 및 가중치를 공개적으로 출시합니다.",2024.03.29,Musashi Hinck&&Matthew L. Olson&&David Cobbley&&Shao-Yen Tseng&&Vasudev Lal,arxiv,https://arxiv.org/abs/2404.01331
Multi-Conditional Ranking with Large Language Models,"LLM (Large Language Model)을 사용하여 일련의 항목 세트를 순위에 올리는 것은 추천 및 검색 시스템에서 일반적인 접근 방식이되었습니다.일반적으로 이러한 시스템은 주어진 쿼리를 기반으로 단조로운 순서로 상당수의 문서를 주문하는 데 중점을 둡니다.그러나 실제 시나리오는 종종 다른 도전을 제시합니다. 비교적 작은 항목 세트를 평가하지만 다양한 다양하고 때로는 상충되는 조건에 따라.이 논문에서는 다양한 항목 유형 및 조건에서 다중 조건수 순위를 평가하기위한 벤치 마크 인 McRank를 소개하여 다중 조건수 순위의 작업을 정의하고 탐색합니다.McRank를 사용한 LLM에 대한 우리의 분석은 항목과 조건의 수와 복잡성이 증가함에 따라 성능이 크게 감소 함을 나타냅니다.이 제한을 극복하기 위해 조건을 추출하고 분류하는 것으로 구성된 새로운 분해 된 추론 방법을 제안한 다음 항목 (EXSIR)을 반복적으로 순위를 매 깁니다.우리의 광범위한 실험에 따르면이 분해 된 추론 방법은 LLM의 성능을 크게 향상시켜 기존 LLM에 비해 최대 12% 개선을 달성합니다.또한 다양한 조건 범주에서 LLMS 성능에 대한 자세한 분석을 제공하고 분해 단계의 효과를 조사합니다.또한, 우리는 방법을 사슬의 사슬 및 인코더 유형 순위 모델과 같은 기존 접근법과 비교하여 MCR 작업의 접근 방식의 우수성을 보여줍니다.우리는 데이터 세트와 코드를 출시했습니다.",2024.03.30,Pouya Pezeshkpour&&Estevam Hruschka,arxiv,https://arxiv.org/abs/2404.00211
Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order,"사전 예방 된 언어 모델은 여러 AI 애플리케이션을 뒷받침하지만 훈련에 대한 높은 계산 비용은 접근성을 제한합니다.Bloom 및 Starcoder와 같은 이니셔티브는 공동 커뮤니티 개발을위한 사전 간 모델에 대한 접근을 민주화하는 것을 목표로합니다.그러나 이러한 기존 모델은 제한된 다국어 기능, 지속적인 사전 여겨지는 치명적인 잊어 버린 반면, 처음부터의 사전 조정은 계산적으로 비싸고 AI 안전 및 개발 법칙을 준수하는 데 어려움을 겪고 있습니다.이 논문은 영어, 핀란드, 힌디어, 일본어, 베트남어 및 코드에 대해 훈련 된 15b 매개 변수 다국어 오픈 소스 모델 인 Aurora-M을 제시합니다.StarcoderPlus에서 지속적으로 4 억 3,500 억 명의 추가 토큰으로 사전에 사전에 Aurora-M은 총 훈련 토큰 수에서 2 조 토큰을 능가합니다.인간 검토 된 안전 지침에 미세 조정 된 최초의 오픈 소스 다국어 모델이므로 기존의 적색 팀 조정 고려 사항뿐만 아니라 안전에 대한 Biden-Harris 행정 명령에 명시된 특정 문제와도 개발을 조정합니다.인공 지능의 안전하고 신뢰할 수있는 개발 및 사용.Aurora-M은 다양한 작업과 언어에 걸쳐 엄격하게 평가되며, 특히 안전 평가에서 다국어 설정에서 대안을 잊어 버리고 성능이 우수한 대안에 대한 견고성을 보여줍니다.책임있는 오픈 소스 LLM 개발을 촉진하기 위해 Aurora-M과 그 변형은 HTTPS URL에서 출시됩니다.",2024.03.30,Taishi Nakamura&&Mayank Mishra&&Simone Tedeschi&&Yekun Chai&&Jason T Stillerman&&Felix Friedrich&&Prateek Yadav&&Tanmay Laud&&Vu Minh Chien&&Terry Yue Zhuo&&Diganta Misra&&Ben Bogin&&Xuan-Son Vu&&Marzena Karpinska&&Arnav Varma Dantuluri&&Wojciech Kusa&&Tommaso Furlanello&&Rio Yokota&&Niklas Muennighoff&&Suhas Pai&&Tosin Adewumi&&Veronika Laippala&&Xiaozhe Yao&&Adalberto Junior&&Alpay Ariyak&&Aleksandr Drozd&&Jordan Clive&&Kshitij Gupta&&Liangyu Chen&&Qi Sun&&Ken Tsui&&Noah Persaud&&Nour Fahmy&&Tianlong Chen&&Mohit Bansal&&Nicolo Monti&&Tai Dang&&Ziyang Luo&&Tien-Tung Bui&&Roberto Navigli&&Virendra Mehta&&Matthew Blumberg&&Victor May&&Huu Nguyen&&Sampo Pyysalo,arxiv,https://arxiv.org/abs/2404.00399
"MaGRITTe: Manipulative and Generative 3D Realization from Image, Topview and Text","사용자 지정 조건에서 3D 장면의 생성은 3D 애플리케이션에서 생산 부담을 완화하기위한 유망한 길을 제공합니다.이전 연구는 제한된 제어 조건으로 인해 원하는 장면을 실현하기 위해 상당한 노력이 필요했습니다.부분 이미지, 상단보기에 표시된 레이아웃 정보 및 텍스트 프롬프트를 사용하여 멀티 모달 조건에서 3D 장면을 제어하고 생성하는 방법을 제안합니다.이러한 조건을 결합하여 3D 장면을 생성하려면 다음과 같은 중요한 어려움이 필요합니다. (1) 큰 데이터 세트 생성, (2) 복합 조건의 상호 작용에 대한 반사 및 (3) 레이아웃 조건의 도메인 의존성.3D 장면 생성 프로세스를 주어진 조건에서 2D 이미지 생성 및 2D 이미지에서 3D 장면 생성으로 분해합니다.2D 이미지 생성은 부분 이미지 및 레이아웃의 작은 인공 데이터 세트로 사전 각화 된 텍스트-이미지 모델을 미세 조정하여 달성되며, 3D 장면 생성은 레이아웃 조건 깊이 추정 및 NERF (Neural Radiance Fields)에 의해 달성되므로 피하십시오.큰 데이터 세트의 생성.360도 이미지를 사용하여 공간 정보의 공통적 표현을 사용하면 다중 모드 조건 상호 작용을 고려하고 레이아웃 제어의 도메인 의존성을 감소시킵니다.실험 결과는 질적으로 그리고 정량적으로 제안 된 방법이 다중 모드 조건에 따라 실내에서 실외에 이르기까지 다양한 영역에서 3D 장면을 생성 할 수 있음을 입증했습니다.",2024.03.30,Takayuki Hara&&Tatsuya Harada,arxiv,https://arxiv.org/abs/2404.00345
Noise-Aware Training of Layout-Aware Language Models,"시각적으로 풍부한 문서 (VRD)는 언어 적 신호와 함께 시각적 기능을 사용하여 정보를 전파합니다.문서에서 명명 된 엔티티를 식별하는 사용자 정의 추출기 훈련 텍스트 및 시각적 모드에 주석이 달린 대상 문서 유형의 많은 인스턴스가 필요합니다.이것은 엔터프라이즈 시나리오에서 고가의 병목 현상으로, 수천 가지의 다양한 문서 유형에 대한 커스텀 추출기를 확장 가능한 방식으로 훈련시키고 자합니다.대상 문서 유형의 표지되지 않은 인스턴스에 대한 추출기 모델을 사전 훈련하고, 인간으로 표지 된 인스턴스의 미세 조정 단계는 이러한 시나리오에서는 작동하지 않으므로 추출기에 할당 된 최대 허용 훈련 시간을 능가합니다.우리는이 논문에서 소음 인식 훈련 방법 또는 NAT를 제안 하여이 시나리오를 다룹니다.NAT는 값 비싼 인간의 표지 된 문서를 인수하는 대신 약하게 레이블이 지정된 문서를 사용하여 추출기를 확장 가능한 방식으로 훈련시킵니다.Nat은 시끄럽고 약하게 레이블이 지정된 샘플로 인해 모델의 품질의 저하를 피하기 위해 각 훈련 샘플의 신뢰를 추정하고 훈련 중 불확실성 측정으로 통합합니다.우리는 NAT를 사용하여 여러 최첨단 추출기 모델을 훈련시킵니다.공개적으로 이용 가능한 여러 및 사내 데이터 세트에 대한 실험에 따르면 NAT 훈련 모델은 성능이 강력 할뿐만 아니라 매크로 -F1 점수 측면에서 전송 학습 기준을 최대 6% 능가하는 것으로 나타났습니다.더 많은 레이블 효율적-비슷한 성능을 얻는 데 필요한 인간 효율의 양을 최대 73%감소시킵니다.",2024.03.30,Ritesh Sarkhel&&Xiaoqi Ren&&Lauro Beltrao Costa&&Guolong Su&&Vincent Perot&&Yanan Xie&&Emmanouil Koukoumidis&&Arnab Nandi,arxiv,https://arxiv.org/abs/2404.00488
ST-LLM: Large Language Models Are Effective Temporal Learners,"LLMS (Lange Language Models)는 텍스트 이해와 생성에서 인상적인 기능을 보여 주었으며 비디오 수준에서 인간 AI 상호 작용을 촉진하기 위해 비디오 LLM에 대한 연구 노력을 촉구했습니다.그러나 비디오 기반 대화 시스템에서 비디오를 효과적으로 인코딩하고 이해하는 방법은 여전히 해결되어야합니다.이 논문에서는 간단하지만 탐구되지 않은 질문을 조사합니다. 모든 공간-시간 토큰을 LLM에 공급하여 LLM에 비디오 시퀀스 모델링 작업을 위임 할 수 있습니까?놀랍게도이 간단한 접근 방식은 비디오 이해의 상당한 개선을 제공합니다.이를 바탕으로, 우리는 LLM 내부의 공간-시간 서열 모델링을 갖춘 효과적인 비디오 LLM 기준 인 ST-LLM을 제안합니다.또한 LLM 내에서 압축되지 않은 비디오 토큰이 도입 한 오버 헤드 및 안정성 문제를 해결하기 위해 맞춤형 훈련 목표를 가진 동적 마스킹 전략을 개발합니다.특히 긴 비디오의 경우 효율성과 효율성의 균형을 맞추기 위해 글로벌 로컬 입력 모듈을 설계했습니다.결과적으로, 우리는 효율성과 안정성을 유지하면서 능숙한 공간-시간 모델링을 위해 LLM을 활용합니다.광범위한 실험 결과는 우리의 방법의 효과를 증명합니다.보다 간결한 모델 및 교육 파이프 라인을 통해 ST-LLM은 Videochatgpt-Bench 및 MVBench에 대한 새로운 최첨단 결과를 설정합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.03.30,Ruyang Liu&&Chen Li&&Haoran Tang&&Yixiao Ge&&Ying Shan&&Ge Li,arxiv,https://arxiv.org/abs/2404.00308
WavLLM: Towards Robust and Adaptive Speech Large Language Model,"LLM (Large Language Models)의 최근 발전은 자연 언어 처리 분야에 혁명을 일으켜 멀티 모달 인식과 세대로의 범위를 점차 확대했습니다.그러나, 청취 기능을 LLM에 효과적으로 통합하면 특히 다양한 상황에 걸쳐 일반화하고 복잡한 청각 과제를 실행하는 것과 관련하여 상당한 어려움이 있습니다.이 작업에서 우리는 듀얼 인코더가있는 강력하고 적응 형 스피치 큰 언어 모델 인 Wavllm과 2 단계 커리큘럼 학습 방식으로 최적화 된 신속한 인식 LORA 무게 어댑터를 소개합니다.듀얼 인코더를 활용하여 우리는 다른 유형의 음성 정보를 분리하여 Whisper Encoder를 사용하여 음성의 의미 론적 내용을 처리하고 Wavlm 인코더를 사용하여 스피커의 고유 한 특성을 포착합니다.커리큘럼 학습 프레임 워크 내에서 WAVLLM은 먼저 혼합 기본 단일 작업을 최적화 한 다음 기본 작업의 조합과 같은보다 복잡한 작업에 대한 고급 멀티 태스킹 교육을 통해 기본 기능을 구축합니다.다양한 작업 및 지침에 대한 유연성과 준수를 향상시키기 위해 두 번째 고급 멀티 태스크 교육 단계에서 신속한 인식 LORA 중량 어댑터가 도입됩니다.우리는 ASR, ST, SV, ER과 같은 작업을 포함한 Universal Speech 벤치 마크에서 제안 된 모델을 검증하고 SQA를위한 Gaokao English Listencrehension 세트 및 Speech Chain-of Thought (COT) 평가 세트와 같은 전문 데이터 세트에도 적용합니다.실험에 따르면 제안 된 모델은 동일한 모델 크기의 다양한 음성 작업에서 최첨단 성능을 달성하여 COT 접근법을 사용하여 복잡한 작업을 실행하는 데 강력한 일반화 기능을 보여줍니다.또한, 우리의 모델은 전문 교육없이 Gaokao 작업을 성공적으로 완료합니다.코드, 모델, 오디오 및 Gaokao 평가 세트는 \ url {this http url}에서 액세스 할 수 있습니다.",2024.03.31,Shujie Hu&&Long Zhou&&Shujie Liu&&Sanyuan Chen&&Hongkun Hao&&Jing Pan&&Xunying Liu&&Jinyu Li&&Sunit Sivasankaran&&Linquan Liu&&Furu Wei,arxiv,https://arxiv.org/abs/2404.00656
FlexiDreamer: Single Image-to-3D Generation with FlexiCubes,"텍스트 프롬프트 또는 단일 이미지의 3D 컨텐츠 생성은 최근 품질과 속도에서 놀라운 진전을 보였습니다.지배적 인 패러다임 중 하나는 일관된 멀티 뷰 이미지를 생성 한 다음 희박한 뷰 재구성을 포함하는 것입니다.그러나, 대상 토폴로지에 접근하기 위해 메쉬 표현을 직접 변형시키는 과제로 인해, 대부분의 방법론은 희소 뷰 재구성 동안 암시 적 표현 (예 : NERF)을 배우고 후 처리 후 추출에 의해 대상 메쉬를 획득한다.암시 적 표현은 풍부한 3D 정보를 효과적으로 모델링 할 수 있지만, 교육은 일반적으로 긴 수렴 시간을 수반합니다.또한, 암시 적 필드로부터의 추출 후 작동은 바람직하지 않은 시각적 유물로 이어진다.이 논문에서 우리는 목표 메시를 엔드 투 엔드 방식으로 재구성하는 새로운 단일 이미지-3D 생성 프레임 워크 인 FlexIdReamer를 제안합니다.Flexicubes로 알려진 유연한 그라디언트 기반 추출을 활용하여, 우리의 방법은 사후 처리에 의해 가져온 결함을 피하고 대상 메쉬의 직접 획득을 용이하게한다.더욱이, 우리는 인코딩 레벨을 플렉시 큐브에서 암시 적 필드로 점진적으로 활성화하여 단계별 최적화를위한 기하학적 세부 사항을 캡처하는 데 도움이되는 다중 해석 해시 그리드 인코딩 체계를 통합합니다.특히 FlexIdReamer는 단일 NVIDIA A100 GPU에서 약 1 분 안에 단일 뷰 이미지에서 밀도가 높은 3D 구조를 복구하여 이전 방법론을 큰 마진으로 능가합니다.",2024.04.01,Ruowen Zhao&&Zhengyi Wang&&Yikai Wang&&Zihan Zhou&&Jun Zhu,arxiv,https://arxiv.org/abs/2404.00987
Streaming Dense Video Captioning,"비디오에서 일시적으로 현지화 된 캡션을 예측하는 고밀도 비디오 캡션을위한 이상적인 모델은 긴 입력 비디오를 처리하고 풍부하고 세부적인 텍스트 설명을 예측하며 전체 비디오를 처리하기 전에 출력을 생성 할 수 있어야합니다.그러나 현재 최첨단 모델은 고정 된 수의 다운 샘플링 프레임을 처리하고 전체 비디오를 본 후 하나의 전체 예측을 만듭니다.우리는 두 가지 새로운 구성 요소로 구성된 스트리밍 밀도가 높은 비디오 캡션 모델을 제안합니다. 첫째, 메모리가 고정 된 크기 일 때 자의적으로 긴 비디오를 처리 할 수있는 클러스터링 토큰을 기반으로 새로운 메모리 모듈을 제안합니다.둘째, 전체 비디오가 처리되기 전에 모델이 예측할 수있는 스트리밍 디코딩 알고리즘을 개발합니다.우리의 모델은 이러한 스트리밍 능력을 달성하고 ActivityNet, YouCook2 및 Vitt의 3 가지 조밀 한 비디오 캡션 벤치 마크에서 최신의 ART를 크게 향상시킵니다.우리의 코드는 https url에서 릴리스됩니다.",2024.04.01,Xingyi Zhou&&Anurag Arnab&&Shyamal Buch&&Shen Yan&&Austin Myers&&Xuehan Xiong&&Arsha Nagrani&&Cordelia Schmid,arxiv,https://arxiv.org/abs/2404.01297
CosmicMan: A Text-to-Image Foundation Model for Humans,"우리는 우연한 인간 이미지를 생성하는 데 특화된 텍스트-이미지 파운데이션 모델 인 Cosmicman을 제시합니다.인간을위한 열등한 품질 및 텍스트 이미지 오정렬의 딜레마에 갇힌 현재의 일반 목적 파운데이션 모델과는 달리, Cosmicman은 세심한 외관, 합리적인 구조 및 상세한 조밀 한 내용으로 정확한 텍스트 이미지 정렬을 가진 사진 현실적인 인간 이미지를 생성 할 수 있습니다.Cosmicman의 성공의 핵심에는 데이터 및 모델에 대한 새로운 반사와 관점이 있습니다. (1) 우리는 데이터 품질과 확장 가능한 데이터 생산 흐름이 훈련 된 모델의 최종 결과에 필수적이라는 것을 발견했습니다.따라서, 우리는 새로운 데이터 생산 패러다임을 제안하고, 다른 사람을 주석을 달아라.이를 바탕으로, 우리는 대규모 데이터 세트 인 Cosmicman-HQ 1.0을 구축했으며, 평균 해상도는 1488x1255의 평균 해상도로 6 백만 개의 고품질의 실제 인간 이미지를 구성했으며, 다양한 과립 화에서 1,1500 만 개의 속성에서 유래 한 정확한 텍스트 주석으로 첨부했습니다.(2) 우리는 인간을위한 전문화 된 텍스트-이미지 기초 모델이 실용적이어야한다고 주장합니다. 고품질의 인간 이미지를 생성하는 데 효과적이지만 다운 스트리밍 작업에 쉽게 통합 할 수 있습니다.따라서, 우리는 고밀도 텍스트 설명과 이미지 픽셀 사이의 관계를 분해 방식으로 모델링하고 분해 된 분해 중심 반복 (대담한) 훈련 프레임 워크를 제시 할 것을 제안합니다.기존 텍스트-이미지 확산 모델의 교차 내역 기능을 원활하게 분해하고 추가 모듈을 추가하지 않고 주목을 다시 시작합니다.대담한 것을 통해, 우리는 연속 텍스트 공간을 인체 구조와 일치하는 여러 기본 그룹으로 명시 적으로 분산시키는 것이 바람에서 오정렬 문제를 해결하는 열쇠임을 보여줍니다.",2024.04.01,Shikai Li&&Jianglin Fu&&Kaiyuan Liu&&Wentao Wang&&Kwan-Yee Lin&&Wayne Wu,arxiv,https://arxiv.org/abs/2404.01294
Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward,"직접 선호도 최적화 (DPO)와 같은 선호도 모델링 기술은 LLM (Lange Language Model)의 일반화 능력을 향상시키는 데 효과적이었습니다.그러나 비디오 교육을 따르는 과제에서, 특히 생성 된 응답에서 환각을 감지하기위한 유익한 피드백을 제공하는 것은 여전히 중요한 과제입니다.이전의 연구는 선호도 모델링을 안내하기위한 대형 대형 멀티 모달 모델 (LMMS)을 보상 모델로 사용하여 탐구했지만 해당 비디오와 비교하여 생성 된 응답의 사실을 정확하게 평가하는 능력은 결정적으로 확립되지 않았습니다.이 논문은 비디오 컨텐츠의 대리로 자세한 비디오 캡션을 사용하는 새로운 프레임 워크를 소개하여 언어 모델 이이 정보를 비디오 질문 답변 (QA) 예측 점수를 얻기위한 증거로 통합 할 수 있도록합니다.우리의 접근 방식은 OpenAI GPT-4V 모델의 보상 메커니즘과의 강력한 정렬을 보여줍니다. 이는 비디오 프레임을 입력으로 직접 가져옵니다.또한 DPO를 통해이 맞춤형 보상을 적용하면 비디오 QA 작업에서 비디오 LMM의 성능이 크게 향상됨을 보여줍니다.",2024.04.01,Ruohong Zhang&&Liangke Gui&&Zhiqing Sun&&Yihao Feng&&Keyang Xu&&Yuanhan Zhang&&Di Fu&&Chunyuan Li&&Alexander Hauptmann&&Yonatan Bisk&&Yiming Yang,arxiv,https://arxiv.org/abs/2404.01258
Condition-Aware Neural Network for Controlled Image Generation,"우리는 이미지 생성 모델에 제어를 추가하는 새로운 방법 인 CAN (Condition-Aware Neural Network)을 제시합니다.이전 조건부 제어 방법과 병행하여 신경망의 가중치를 동적으로 조작하여 이미지 생성 프로세스를 제어 할 수 있습니다.이는 입력 조건에 따라 컨볼 루션/선형 레이어에 대한 조건부 가중치를 생성하는 조건증 중량 생성 모듈을 도입하여 달성됩니다.우리는 Imagenet의 클래스 조건 이미지 생성 및 Coco의 텍스트-이미지 생성에 대해 테스트합니다.DIT 및 UVIT를 포함한 확산 변압기 모델에 대해 지속적으로 크게 개선 할 수 있습니다.특히, 효율성 VIT (CAT)와 결합 할 수 있습니다. imagenet 512x512에서 2.78 FID를 달성하여 DIT-XL/2를 능가하면서 샘플링 단계 당 52 배 적은 MAC를 요구합니다.",2024.04.01,Han Cai&&Muyang Li&&Zhuoyang Zhang&&Qinsheng Zhang&&Ming-Yu Liu&&Song Han,arxiv,https://arxiv.org/abs/2404.01143
Measuring Style Similarity in Diffusion Models,"생성 모델은 이제 그래픽 디자이너와 아티스트가 널리 사용합니다.이전의 작품은 이러한 모델이 세대 동안 교육 데이터에서 컨텐츠를 기억하고 복제하는 것으로 나타났습니다.따라서 확산이 증가함에 따라 생성 된 이미지가 전문적인 목적으로 사용되기 전에 매번 이미지의 속성이 특정 교육 데이터에 기인한지 여부를 결정하기 위해 데이터베이스 검색을 수행하는 것이 중요해졌습니다.이 목적을위한 기존 도구는 유사한 시맨틱 컨텐츠의 이미지를 검색하는 데 중점을 둡니다.한편, 많은 예술가들은 텍스트-이미지 모델의 스타일 복제에 관심이 있습니다.우리는 이미지에서 스타일 디스크립터를 이해하고 추출하기위한 프레임 워크를 제시합니다.우리의 프레임 워크는 스타일이 색상, 텍스처, 모양 등을 포함하여 복잡하지만 의미있는 요소를 캡처하는 이미지의 주관적인 속성이라는 통찰력을 사용하여 큐 레이트 된 새로운 데이터 세트로 구성됩니다. 또한 스타일 디스크립터를 추출하는 방법을 제안합니다.생성 된 이미지의 스타일을 텍스트-이미지 모델의 교육 데이터 세트에 사용 된 이미지에 속하는 데 사용할 수 있습니다.우리는 다양한 스타일의 검색 작업에서 유망한 결과를 보여줍니다.우리는 또한 스타일 속성과 안정적인 확산 모델에서 일치하는 스타일 속성을 정 성적으로 그리고 정 성적으로 분석합니다.코드 및 아티팩트는 HTTPS URL에서 사용할 수 있습니다.",2024.04.01,Gowthami Somepalli&&Anubhav Gupta&&Kamal Gupta&&Shramay Palta&&Micah Goldblum&&Jonas Geiping&&Abhinav Shrivastava&&Tom Goldstein,arxiv,https://arxiv.org/abs/2404.01292
Getting it Right: Improving Spatial Consistency in Text-to-Image Models,"현재 T2I (Text-to-Image) 모델의 주요 단점 중 하나는 텍스트 프롬프트에 지정된 공간 관계를 충실히 따르는 이미지를 지속적으로 생성 할 수 없다는 것입니다.이 논문에서는이 제한에 대한 포괄적 인 조사를 제공하는 동시에 최첨단 성능을 달성하는 데이터 세트 및 방법을 개발합니다.첫째, 우리는 현재의 비전 언어 데이터 세트가 공간 관계를 충분히 나타내지 않는다는 것을 발견했다.이 병목 현상을 완화하기 위해, 우리는 널리 사용되는 4 개의 비전 데이터 세트에서 6 백만 이미지를 다시 캡션하여 최초의 공간 중심의 대규모 데이터 세트 인 Spright를 만듭니다.3 배 평가 및 분석 파이프 라인을 통해 Spright는 공간 관계를 캡처 할 때 기존 데이터 세트를 크게 향상 시킨다는 것을 알게됩니다.그 효능을 입증하기 위해, 우리는 Spright의 ~ 0.25% 만 활용하고 공간적으로 정확한 이미지를 생성하는 동시에 FID 및 CMMD 점수를 향상시키는 데 22% 개선을 달성합니다.둘째, 우리는 많은 수의 물체를 포함하는 이미지에 대한 훈련이 공간 일관성이 상당히 개선된다는 것을 발견했습니다.특히, 우리는 <500 이미지를 미세 조정하여 0.2133의 공간 점수로 T2I-Compbench에서 최첨단을 달성합니다.마지막으로, 통제 된 실험과 절제 세트를 통해 텍스트-이미지 모델의 공간 일관성에 영향을 미치는 요소에 대한 이해를 향상시킬 수있는 여러 결과를 기록합니다.우리는이 분야에 대한 추가 연구를 촉진하기 위해 데이터 세트와 모델을 공개적으로 발표합니다.",2024.04.01,Agneet Chatterjee&&Gabriela Ben Melech Stan&&Estelle Aflalo&&Sayak Paul&&Dhruba Ghosh&&Tejas Gokhale&&Ludwig Schmidt&&Hannaneh Hajishirzi&&Vasudev Lal&&Chitta Baral&&Yezhou Yang,arxiv,https://arxiv.org/abs/2404.01197
Are large language models superhuman chemists?,"대형 언어 모델 (LLM)은 인간 언어를 처리하고 명시 적으로 교육을받지 않은 작업을 수행 할 수있는 능력으로 인해 광범위한 관심을 끌었습니다.이것은 텍스트 형태로 자주있는 작고 다양한 데이터 세트의 문제에 직면하는 화학 과학과 관련이 있습니다.LLMS는 이러한 문제를 해결하는 약속을 보여 주었으며 화학적 특성을 예측하고 반응을 최적화하며 실험을 자율적으로 설계하고 수행하기 위해 점점 더 활용되고 있습니다.그러나, 우리는 여전히 LLM의 화학적 추론 능력에 대한 체계적인 이해를 가지고 있으며, 이는 모델을 개선하고 잠재적 피해를 완화하는 데 필요합니다.여기, 우리는 인간 화학자의 전문 지식에 대한 최첨단 LLM의 화학 지식과 추론 능력을 엄격하게 평가하기 위해 설계된 자동화 된 프레임 워크 인 ""Chembench""를 소개합니다.우리는 화학 과학의 광범위한 서브 필드를 위해 7,000 개 이상의 질문 응답 쌍을 선별했으며, 개방 및 폐쇄 소스 LLM을 선도하는 선도적 인 개방 및 폐쇄 소스 LLM을 평가했으며, 최고의 모델이 평균적으로 최고의 인간 화학자보다 우수한 것으로 나타났습니다.그러나이 모델은 인간 전문가가 쉬운 일부 화학적 추론 작업으로 어려움을 겪고 화학 물질의 안전 프로파일과 같은 과도하게 자신감 있고 오해의 소지가있는 예측을 제공합니다.이러한 결과는 LLM이 화학 작업에서 놀라운 능력을 보여 주지만 화학 과학에서 안전성과 유용성을 향상시키는 데 더 많은 연구가 중요하다는 이중 현실을 강조합니다.우리의 연구 결과는 또한 화학 커리큘럼에 대한 적응의 필요성을 나타내며 안전하고 유용한 LLM을 개선하기 위해 평가 프레임 워크를 지속적으로 개발하는 것의 중요성을 강조합니다.",2024.04.01,Adrian Mirza&&Nawaf Alampara&&Sreekanth Kunchapu&&Benedict Emoekabu&&Aswanth Krishnan&&Mara Wilhelmi&&Macjonathan Okereke&&Juliane Eberhardt&&Amir Mohammad Elahi&&Maximilian Greiner&&Caroline T. Holick&&Tanya Gupta&&Mehrdad Asgari&&Christina Glaubitz&&Lea C. Klepsch&&Yannik Köster&&Jakob Meyer&&Santiago Miret&&Tim Hoffmann&&Fabian Alexander Kreth&&Michael Ringleb&&Nicole Roesner&&Ulrich S. Schubert&&Leanne M. Stafast&&Dinga Wonanke&&Michael Pieler&&Philippe Schwaller&&Kevin Maik Jablonka,arxiv,https://arxiv.org/abs/2404.01475
Bigger is not Always Better: Scaling Properties of Latent Diffusion Models,"우리는 샘플링 효율에 중점을 둔 잠재 확산 모델 (LDMS)의 스케일링 특성을 연구합니다.개선 된 네트워크 아키텍처 및 추론 알고리즘은 확산 모델의 샘플링 효율을 효과적으로 향상시키는 것으로 나타 났지만, 샘플링 효율의 중요한 결정 요인 인 모델 크기의 역할은 철저히 조사되지 않았습니다.확립 된 텍스트-이미지 확산 모델에 대한 경험적 분석을 통해, 우리는 다양한 샘플링 단계에서 모델 크기가 샘플링 효율에 어떤 영향을 미치는지에 대한 심층적 인 조사를 수행합니다.우리의 연구 결과는 놀라운 추세를 공개합니다. 주어진 추론 예산에 따라 운영 될 때 소규모 모델은 종종 고품질 결과를 생성하는 데 더 큰 동등성을 능가합니다.또한, 우리는 다양한 확산 샘플러를 적용하고 다양한 다운 스트림 작업을 탐색하고, 이지화 후 모델을 평가하고, 훈련 컴퓨팅에 대한 성능을 비교함으로써 이러한 결과의 일반화 가능성을 보여주기 위해 연구를 확장했습니다.이러한 결과는 제한된 추론 예산 내에서 생성 기능을 향상시키기 위해 사용할 수있는 LDM 스케일링 전략의 개발을위한 새로운 경로를 열어줍니다.",2024.04.01,Kangfu Mei&&Zhengzhong Tu&&Mauricio Delbracio&&Hossein Talebi&&Vishal M. Patel&&Peyman Milanfar,arxiv,https://arxiv.org/abs/2404.01367
Stream of Search (SoS): Learning to Search in Language,"언어 모델은 훈련하는 동안 유익한 실수를 거의 나타내지 않습니다.그런 다음 그들은 다음 토큰을 넘어서 오류의 눈덩이로 고통 받고 몇 단계 앞서 자신의 행동의 결과를 예측하기 위해 고군분투하는 데 어려움을 겪고 있습니다.이 논문에서는 언어 검색 프로세스를 평평한 문자열 (SOS)으로 표현하여 언어 모델을 검색하는 방법을 보여줍니다.우리는 다양한 상징적 검색 전략을 캡처하는 검색을위한 통일 된 언어를 제안합니다.우리는 단순하면서도 어려운 카운트 다운 게임을 사용하여 접근 방식을 보여줍니다. 여기서 목표는 입력 번호를 산술 작업과 결합하여 대상 번호에 도달하는 것입니다.우리는 Heuristic Solvers에 의해 생성 된 검색 스트림 데이터 세트에서 Transformer 기반 언어 모델을 처음부터 사전에 전제합니다.우리는 SOS 사전 조정이 최적의 검색 궤적 만 예측하도록 훈련 된 모델보다 검색 정확도를 25% 증가 시킨다는 것을 발견했습니다.우리는이 모델을 두 가지 정책 개선 방법, 즉 APA (Advantage-Senseed Policy Alignment)와 자체 가르침 추론 (StAR)으로 추가로 제공합니다.Finetuned SOS 모델은 휴리스틱 솔버가 해결할 수없는 문제를 포함하여 이전에 해결되지 않은 문제의 36%를 해결합니다.우리의 결과는 언어 모델이 검색을 통해 문제를 해결하고, 다른 검색 전략을 유연하게 사용하도록 자체적으로 처리하고, 잠재적으로 새로운 것을 발견 할 수 있음을 나타냅니다.",2024.04.01,Kanishk Gandhi&&Denise Lee&&Gabriel Grand&&Muxin Liu&&Winson Cheng&&Archit Sharma&&Noah D. Goodman,arxiv,https://arxiv.org/abs/2404.03683
Poro 34B and the Blessing of Multilinguality,"최첨단 대형 언어 모델의 사전 조정에는 이제 대부분의 언어에서 사용할 수있는 것보다 훨씬 많은 수조 단어의 텍스트가 필요합니다.하나 이상의 언어로 텍스트를 포함시키는 것은 더 많은 사전화 데이터를 얻는 명백한 방법이지만, 다국어는 종종 저주로 간주되며, 대부분의 모델 훈련 노력은 개별 대형 언어에 계속해서 독점적으로 초점을 맞추고 있습니다.우리는 다국어가 축복이 될 수 있으며 다국어 교육을 통해 소규모 언어에 대한 단일 언어 모델의 능력을 크게 개선 할 수 있어야한다고 생각합니다.이 연구에서 우리는 핀란드어, 영어 및 프로그래밍 언어의 1 조의 토큰을 위해 훈련 된 340 억 개의 매개 변수 모델 인 PORO 34B를 소개하고 다국어 교육 접근법이 기존 모델의 기능보다 실질적으로 발전 할뿐만 아니라 모델을 생성 할 수 있음을 보여줍니다.핀란드의 경우도 번역이 뛰어나며 영어 및 프로그래밍 언어를 생성하는 데있어 수업 시간에 경쟁력이 있습니다.HTTPS URL에서 공개 라이센스 아래 모델 매개 변수, 스크립트 및 데이터를 해제합니다.",2024.04.02,Risto Luukkonen&&Jonathan Burdge&&Elaine Zosa&&Aarne Talman&&Ville Komulainen&&Väinö Hatanpää&&Peter Sarlin&&Sampo Pyysalo,arxiv,https://arxiv.org/abs/2404.01856
HyperCLOVA X Technical Report,"우리는 영어, 수학 및 코딩의 경쟁력과 함께 한국어 및 문화에 맞는 대형 언어 모델 (LLM) 제품군 인 Hyperclova X를 소개합니다.Hyperclova X는 한국, 영어 및 코드 데이터의 균형 잡힌 혼합에 대해 교육을 받았으며, 책임있는 AI에 대한 우리의 약속을 반영하는 엄격한 안전 지침을 준수하면서 고품질의 인간이 주어진 데이터 세트를 사용하여 교육을 조정했습니다.이 모델은 한국과 영어 모두에서 포괄적 인 추론, 지식, 상식, 사실, 코딩, 수학, 채팅, 지시 금고 및 무해 함을 포함한 다양한 벤치 마크에서 평가됩니다.Hyperclova X는 언어와 문화적 뉘앙스에 대한 깊은 이해로 한국에서 강력한 추론 능력을 보여줍니다.고유 한 이중 언어 특성과 다국어에 대한 확장에 대한 추가 분석은 여러 언어 쌍과 교차 언어 추론 작업 사이의 기계 번역을 포함하여 모델의 교차 숙련성과 표적화되지 않은 언어에 대한 강력한 일반화 능력을 강조합니다.우리는 Hyperclova X가 주권 LLM을 개발하는 지역이나 국가에 유용한 지침을 제공 할 수 있다고 생각합니다.",2024.04.02,Kang Min Yoo&&Jaegeun Han&&Sookyo In&&Heewon Jeon&&Jisu Jeong&&Jaewook Kang&&Hyunwook Kim&&Kyung-Min Kim&&Munhyong Kim&&Sungju Kim&&Donghyun Kwak&&Hanock Kwak&&Se Jung Kwon&&Bado Lee&&Dongsoo Lee&&Gichang Lee&&Jooho Lee&&Baeseong Park&&Seongjin Shin&&Joonsang Yu&&Seolki Baek&&Sumin Byeon&&Eungsup Cho&&Dooseok Choe&&Jeesung Han&&Youngkyun Jin&&Hyein Jun&&Jaeseung Jung&&Chanwoong Kim&&Jinhong Kim&&Jinuk Kim&&Dokyeong Lee&&Dongwook Park&&Jeong Min Sohn&&Sujung Han&&Jiae Heo&&Sungju Hong&&Mina Jeon&&Hyunhoon Jung&&Jungeun Jung&&Wangkyo Jung&&Chungjoon Kim&&Hyeri Kim&&Jonghyun Kim&&Min Young Kim&&Soeun Lee&&Joonhee Park&&Jieun Shin&&Sojin Yang&&Jungsoon Yoon&&Hwaran Lee&&Sanghwan Bae&&Jeehwan Cha&&Donghoon Ham&&Youngki Hong&&Yunki Hong&&Myunggeun Ji&&Yeguk Jin&&Chansong Jo&&Shinyoung Joo&&Seunghwan Jung&&Hyomin Kim&&Jungwhan Kim&&Minkyoung Kim&&Minseung Kim&&Sungdong Kim&&Yonghee Kim&&Youngjun Kim&&Donghyeon Ko&&Dughyun Lee&&Jaehong Lee&&Jieun Lee&&Jongjin Lee&&Min Young Lee&&Yehbin Lee&&Taehong Min&&Kiyoon Moon&&Jaesun Park&&Kyuyon Park&&Seunghyun Seo&&Gyubin Son&&Wonjoon Yoo&&Myungin You&&Doheon Ahn&&Homin Ahn&&Joohee Ahn&&Seongmin Ahn&&Chanwoo An&&Hyeryun An&&Junho An&&Sang-Min An&&Boram Byun&&Jongho Cha&&Minji Chang&&Seunggyu Chang&&Haesong Cho&&Youngdo Cho&&Dalnim Choi&&Daseul Choi&&Hyoseok Choi&&Minseong Choi&&Sangho Choi&&Seongjae Choi&&Wooyong Choi&&Sewhan Chun&&Dong Young Go&&Chiheon Ham&&Danbi Han&&Jaemin Han&&Mihak Hong&&Moonyoung Hong&&Sung Bum Hong&&Seongchan Hwang&&Eunbin Hyun&&Jinbae Im&&Jaehyung Jang&&Jaeni Jang&&Sihyeon Jang&&Sungwon Jang&&Joonha Jeon&&Yujin Jeon&&Daun Jeong&&Joonhyun Jeong&&Kyeongseok Jeong&&Mini Jeong&&Yeji Jeong&&Sol Jin&&Hanbyeol Jo&&Hanju Jo&&Minjung Jo&&Lee Jonghyun&&Chaeyoon Jung&&Hyungsik Jung&&Jaeuk Jung&&Ju Hwan Jung&&Kwangsun Jung&&Seungjae Jung&&Soonwon Ka&&Donghan Kang&&Soyoung Kang&&Taeho Kil&&Areum Kim&&Beomyoung Kim&&Byeongwook Kim&&Daehee Kim&&Dong-Gyun Kim&&Donggook Kim&&Donghyun Kim&&Euna Kim&&Eunchul Kim&&Geewook Kim&&Gyu Ri Kim&&Hanbyul Kim&&Heesu Kim&&Isaac Kim&&Jeonghoon Kim&&Jihye Kim&&Joonghoon Kim&&Minjae Kim&&Minsub Kim&&Pil Hwan Kim&&Sammy Kim&&Seokhun Kim&&Seonghyeon Kim&&Soojin Kim&&Soong Kim&&Soyoon Kim&&Sunyoung Kim&&Taeho Kim&&Wonho Kim&&Yoonsik Kim&&You Jin Kim&&Yuri Kim&&Beomseok Kwon&&Ohsung Kwon&&Yoo-Hwan Kwon&&Anna Lee&&Byungwook Lee&&Changho Lee&&Daun Lee&&Dongjae Lee&&Ha-Ram Lee&&Hodong Lee&&Hwiyeong Lee&&Hyunmi Lee&&Injae Lee&&Jaeung Lee&&Jeongsang Lee&&Jisoo Lee&&Joongjae Lee&&Juhan Lee&&Jung Hyun Lee&&Junghoon Lee&&Junwoo Lee&&Se Yun Lee&&Sujin Lee&&Sungjae Lee&&Sungwoo Lee&&Wonjae Lee&&Zoo Hyun Lee&&Jong Kun Lim&&Kun Lim&&Taemin Lim&&Yuri Min&&Nuri Na&&Jeongyeon Nam&&Kyeong-Min Nam&&Yeonseog Noh&&Biro Oh&&Hyangnam Oh&&Jung-Sik Oh&&Solgil Oh&&Yeontaek Oh&&Boyoun Park&&Cheonbok Park&&Dongju Park&&Hyeonjin Park&&Hyun Tae Park&&Hyunjung Park&&Jihye Park&&Jooseok Park&&Junghwan Park&&Jungsoo Park&&Miru Park&&Sang Hee Park&&Seunghyun Park&&Taerim Park&&Wonkyeong Park&&Hyunjoon Ryu&&Jeonghun Ryu&&Nahyeon Ryu&&Soonshin Seo&&Suk Min Seo&&Yoonjeong Shim&&Kyuyong Shin&&Wonkwang Shin&&Hyun Sim&&Mihyun Sim&&Woongseob Sim&&Hyejin Soh&&Bokyoung Son&&Hyunjun Son&&Seulah Son&&Chi-Yun Song&&Chiyoung Song&&Ka Yeon Song&&Minchul Song&&Seungmin Song&&Jisung Wang&&Matt Yeo&&Yonggoo Yeo&&Myeong Yeon Yi&&Moon Bin Yim&&Taehwan Yoo&&Youngjoon Yoo&&Sungmin Yoon&&Young Jin Yoon&&Hangyeol Yu&&Ui Seon Yu&&Xingdong Zuo&&Jeongin Bae&&Joungeun Bae&&Hyunsoo Cho&&Seonghyun Cho&&Yongjin Cho&&Taekyoon Choi&&Yera Choi&&Jiwan Chung&&Zhenghui Han&&Byeongho Heo&&Euisuk Hong&&Taebaek Hwang&&Seonyeol Im&&Sumin Jegal&&Sumin Jeon&&Yelim Jeong&&Yonghyun Jeong&&Can Jiang&&Juyong Jiang&&Jiho Jin&&Ara Jo&&Younghyun Jo&&Hoyoun Jung&&Juyoung Jung&&Dae Hee Kim&&Ginam Kim&&Hangyeol Kim&&Heeseung Kim&&Hyojin Kim&&Hyojun Kim&&Hyun-Ah Kim&&Jeehye Kim&&Jin-Hwa Kim&&Jiseon Kim&&Jonghak Kim&&Jung Yoon Kim&&Rak Yeong Kim&&Seoyoon Kim&&Sewon Kim&&Sooyoung Kim&&Sukyoung Kim&&Taeyong Kim&&Naeun Ko&&Bonseung Koo&&Heeyoung Kwak&&Haena Kwon&&Youngjin Kwon&&Boram Lee&&Bruce W. Lee&&Dagyeong Lee&&Erin Lee&&Euijin Lee&&Ha Gyeong Lee&&Hyojin Lee&&Hyunjeong Lee&&Jeeyoon Lee&&Jeonghyun Lee&&Jongheok Lee&&Joonhyung Lee&&Junhyuk Lee&&Mingu Lee&&Nayeon Lee&&Sangkyu Lee&&Se Young Lee&&Seulgi Lee&&Seung Jin Lee&&Suhyeon Lee&&Yeonjae Lee&&Yesol Lee&&Youngbeom Lee&&Yujin Lee&&Shaodong Li&&Tianyu Liu&&Seong-Eun Moon&&Taehong Moon&&Max-Lasse Nihlenramstroem&&Wonseok Oh&&Yuri Oh&&Hongbeen Park&&Hyekyung Park&&Nohil Park&&Sangjin Park&&Jiwon Ryu&&Miru Ryu&&Simo Ryu&&Ahreum Seo&&Hee Seo&&Kangdeok Seo&&Jamin Shin&&Seungyoun Shin&&Heetae Sin&&Jiangping Wang&&Lei Wang&&Ning Xiang&&Longxiang Xiao&&Jing Xu&&Seonyeong Yi&&Haanju Yoo&&Haneul Yoo&&Hwanhee Yoo&&Liang Yu&&Youngjae Yu&&Weijie Yuan&&Bo Zeng&&Qian Zhou&&Kyunghyun Cho&&Jung-Woo Ha&&Joonsuk Park&&Jihyun Hwang&&Hyoung Jo Kwon&&Soonyong Kwon&&Jungyeon Lee&&Seungho Lee&&Seungho Choi&&Sang-Woo Lee&&Jung Hwa Lim&&Nako Sung&&et al. (277 additional authors not shown),arxiv,https://arxiv.org/abs/2404.01954
LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models,"LLM (Lange Language Models)의 생성 기능을 활용하여 다양한 네트워크 특성에 맞게 조정 된 적응 형 비트 레이트 (ABR) 알고리즘을 자율적으로 설계하는 LLM-ABR을 제시합니다.강화 학습 프레임 워크 내에서 운영되는 LLM-ABR은 LLM이 상태 및 신경망 아키텍처와 같은 주요 구성 요소를 설계 할 수 있도록합니다.광대역, 위성, 4G 및 5G를 포함한 다양한 네트워크 설정에서 LLM-ABR을 평가합니다.LLM-ABR은 기본 ABR 알고리즘을 지속적으로 능가합니다.",2024.04.02,Zhiyuan He&&Aashish Gottipati&&Lili Qiu&&Francis Y. Yan&&Xufang Luo&&Kenuo Xu&&Yuqing Yang,arxiv,https://arxiv.org/abs/2404.01617
Long-context LLMs Struggle with Long In-context Learning,"대형 언어 모델 (LLM)은 32k 토큰을 초과하는 긴 시퀀스를 처리하는 데 큰 진전을 이루었습니다.그러나 그들의 성과 평가는 당황 및 합성 작업과 같은 지표에 크게 국한되었으며, 이는 미묘한 실제 시나리오에서 능력을 완전히 포착하지 못할 수 있습니다.이 연구는 극도의 라벨 분류 영역 내에서 긴 컨텍스트 학습에 중점을 둔 전문화 된 벤치 마크 (Longiclbench)를 소개합니다.우리는 2k에서 50k 토큰의 다른 입력 (몇 가지 샷 데모) 길이를 다루는 28 ~ 174 개의 클래스에 걸친 레이블 범위를 가진 6 개의 데이터 세트를 세 심하게 선택했습니다.우리의 벤치 마크는 LLM이 전체 입력을 이해하여 거대한 레이블 공간을 인식하여 올바른 예측을 할 필요가 있습니다.벤치 마크에서 13 개의 장거리 LLM을 평가합니다.긴 컨텍스트 LLM은 긴 컨텍스트 창을 효과적으로 활용하여 데모 길이가 짧은 덜 도전적인 작업에서 비교적 잘 수행한다는 것을 발견했습니다.그러나 174 개의 레이블을 사용한 가장 어려운 작업 발견에서 모든 LLM은 작업 정의를 이해하기 위해 노력하여 0에 가까운 성능에 도달합니다.이는 길고 컨텍스트가 풍부한 시퀀스를 처리하고 이해하기위한 현재 LLM 기능에서 주목할만한 간격을 시사합니다.추가 분석은 서열의 끝을 향해 제시된 라벨에 대한 예측을 선호하는 모델들 사이의 경향을 보여 주었다.긴 시퀀스에서 여러 조각에 대한 추론 능력은 아직 개선되지 않았습니다.우리의 연구는 긴 맥락의 이해와 추론이 여전히 기존 LLM들에게 어려운 과제임을 보여줍니다.우리는 Longiclbench가 미래의 장기 텍스트 LLM에 대한보다 현실적인 평가 역할을 할 수 있다고 생각합니다.",2024.04.02,Tianle Li&&Ge Zhang&&Quy Duc Do&&Xiang Yue&&Wenhu Chen,arxiv,https://arxiv.org/abs/2404.02060
Advancing LLM Reasoning Generalists with Preference Trees,"우리는 추론을 위해 최적화 된 대형 언어 모델 (LLMS) 제품군 인 Eurus를 소개합니다.Mistral-7b 및 Codellama-70B에서 Finetuned 인 Eurus 모델은 수학, 코드 생성 및 논리적 추론 문제를 다루는 다양한 벤치 마크 세트에서 오픈 소스 모델 중 최첨단 결과를 달성합니다.특히 EURUS-70B는 5 개의 작업을 다루는 12 개의 테스트에서 포괄적 인 벤치마킹을 통해 추론에서 GPT-3.5 터보를 이겼으며 Leetcode에서 33.3% 패스@1 정확도를 달성하고 Theoremqa에서 32.6%를 달성하여 두 가지 도전적인 벤치 마크에서 32.6%를 달성합니다.마진에 의한 모델 13.3%이상.EURU의 강력한 성능은 주로 복잡한 추론 작업을 위해 특별히 설계된 새로 구축 된 대규모 고품질 정렬 데이터 세트 인 UltrainterAct에 기인 할 수 있습니다.UltrainterAct는 감독 된 미세 조정 및 선호도 학습에 모두 사용할 수 있습니다.각 명령에 대해 (1) 통합 형식의 다양한 계획 전략을 가진 추론 체인, (2) 환경 및 비판과의 다중 회전 상호 작용 궤적 및 (3) 선호도 학습을 용이하게하기위한 쌍별 데이터를 포함합니다..UltrainterAct를 사용하면 추론 작업을위한 선호도 학습에 대한 심층적 인 탐색을 수행 할 수 있습니다.우리의 조사에 따르면 잘 확립 된 선호도 학습 알고리즘은 일반적인 대화에서의 효과와 비교하여 추론 작업에 적합하지 않을 수 있습니다.이에 영감을 얻은 우리는 Ultrainteract와 함께 강력한 보상 모델로 이어지는 새로운 보상 모델링 목표를 도출합니다.",2024.04.02,Lifan Yuan&&Ganqu Cui&&Hanbin Wang&&Ning Ding&&Xingyao Wang&&Jia Deng&&Boji Shan&&Huimin Chen&&Ruobing Xie&&Yankai Lin&&Zhenghao Liu&&Bowen Zhou&&Hao Peng&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.02078
CameraCtrl: Enabling Camera Control for Text-to-Video Generation,제어 가능성은 사용자가 원하는 컨텐츠를 만들 수 있기 때문에 비디오 생성에서 중요한 역할을합니다.그러나 기존 모델은 더 깊은 이야기 뉘앙스를 표현하는 영화 언어 역할을하는 카메라 포즈의 정확한 제어를 간과했습니다.이 문제를 완화하기 위해 Cameractrl을 소개하여 T2V (Text-to-Video) 모델을위한 정확한 카메라 포즈 제어를 가능하게합니다.카메라 궤적을 정확하게 매개 변수화 한 후 플러그 앤 플레이 카메라 모듈은 T2V 모델로 교육을 받고 다른 사람들은 손대지 않습니다.또한 다양한 데이터 세트의 효과에 대한 포괄적 인 연구가 수행되어 다양한 카메라 배포와 유사한 외관이있는 비디오가 실제로 제어 가능성과 일반화를 향상시킬 수 있음을 시사합니다.실험 결과는 정확하고 도메인 적응 형 카메라 컨트롤을 달성하는 데있어 카메라 크트L의 효과를 보여줍니다.프로젝트 웹 사이트는 다음과 같습니다.이 HTTPS URL.,2024.04.02,Hao He&&Yinghao Xu&&Yuwei Guo&&Gordon Wetzstein&&Bo Dai&&Hongsheng Li&&Ceyuan Yang,arxiv,https://arxiv.org/abs/2404.02101
Octopus v2: On-device language model for super agent,"언어 모델은 다양한 소프트웨어 응용 프로그램, 특히 자동 워크 플로와 관련된 작업에서 효과를 보여주었습니다.이 모델은 기능을 호출하는 데 중요한 능력을 가지고 있으며, 이는 AI 에이전트를 만드는 데 필수적입니다.클라우드 환경에서 대규모 언어 모델의 고성능에도 불구하고 종종 개인 정보 및 비용에 대한 우려와 관련이 있습니다.대기 시간 및 정확도로 얼굴 문제를 호출하는 기능을위한 현재 기기 모델.우리의 연구는 정확도와 대기 시간 모두에서 GPT-4의 성능을 능가하기 위해 20 억 파라미터의 기기 모델을 강화하고 컨텍스트 길이를 95 \%줄이는 새로운 방법을 제시합니다.헝겊 기반 기능 호출 메커니즘과 LLAMA-7B와 비교할 때, 우리의 방법은 대기 시간을 35 배 향상시킵니다.이 방법은 대기 시간을 생산 환경에서 다양한 에지 장치에 걸쳐 배포하기에 적합한 레벨로 줄어들어 실제 애플리케이션에 대한 성능 요건과 일치합니다.",2024.04.02,Wei Chen&&Zhiyuan Li,arxiv,https://arxiv.org/abs/2404.01744
3D Congealing: 3D-Aware Image Alignment in the Wild,"우리는 의미 적으로 유사한 물체를 캡처하는 2D 이미지에 대한 3D 인식 정렬의 새로운 문제인 3D Congealing을 제안합니다.표지되지 않은 인터넷 이미지 모음이 주어지면, 우리의 목표는 공유 시맨틱 부분을 입력에서 연관시키고 2D 이미지에서 공유 된 3D 표준 공간으로 지식을 집계하는 것입니다.우리는 모양 템플릿, 포즈 또는 카메라 매개 변수를 가정하지 않고 작업을 해결하는 일반적인 프레임 워크를 소개합니다.그 핵심은 기하학적 및 의미 론적 정보를 캡슐화하는 표준 3D 표현이 있습니다.이 프레임 워크는 각 입력 이미지에 대한 포즈와 함께 표준 표현을 최적화하고, 2D 픽셀 좌표가 3D 표준 프레임으로 뒤틀리는 형상 일치를 설명하는 심각한 좌표 맵을 최적화합니다.최적화 절차는 미리 훈련 된 이미지 생성 모델과 입력 이미지의 의미 정보에서 사전 지식을 융합시킵니다.전자는이 제약 부족 작업에 대한 강력한 지식 지침을 제공하는 반면, 후자는 미리 훈련 된 모델에서 교육 데이터 편향을 완화하는 데 필요한 정보를 제공합니다.당사의 프레임 워크는 서신 일치, 포즈 추정 및 이미지 편집과 같은 다양한 작업에 사용될 수 있으며, 도전적인 조명 조건 및 온라인 온라인 이미지 컬렉션에서 실제 이미지 데이터 세트에 대한 강력한 결과를 얻을 수 있습니다.",2024.04.02,Yunzhi Zhang&&Zizhang Li&&Amit Raj&&Andreas Engelhardt&&Yuanzhen Li&&Tingbo Hou&&Jiajun Wu&&Varun Jampani,arxiv,https://arxiv.org/abs/2404.02125
Mixture-of-Depths: Dynamically allocating compute in transformer-based language models,"변압기 기반 언어 모델은 입력 시퀀스에 걸쳐 플롭을 균일하게 퍼뜨립니다.이 작업에서 우리는 변압기가 대신 분열의 특정 위치에 플롭을 동적으로 할당하는 법을 배울 수 있음을 보여줍니다.우리의 방법은 주어진 계층에서 자체 변환 및 MLP 계산에 참여할 수있는 토큰 수 (k) 수를 캡핑하여 총 컴퓨팅 예산을 시행합니다.처리 할 토큰은 최상위 원조 메커니즘을 사용하여 네트워크에 의해 결정됩니다.Kis는 선험적으로 정의 되었으므로이 간단한 절차는 다른 조건부 계산 기술과 달리 알려진 텐서 크기의 정적 계산 그래프를 사용합니다.그럼에도 불구하고, ktokens의 정체성은 유동적이기 때문에,이 방법은 시간에 걸쳐 균일하게 플롭을 소비 할 수 있으며 모델 깊이 치수.따라서 컴퓨팅 지출은 전체적으로 총계에서 예측 가능하지만 토큰 수준에서는 역동적이고 컨텍스트에 민감합니다.이러한 방식으로 훈련 된 모델은 컴퓨팅을 동적으로 할당하는 법을 배울뿐만 아니라 효율적으로 그렇게합니다.이 모델은 등가 플롭 및 벽 클록 타임에 대한 기준 성능과 일치하지만 전방 패스 당 플롭의 일부가 필요하며, 후 훈련 후 샘플링 중에 단계에 50% 더 빠르게 50 \% 이상이 될 수 있습니다.",2024.04.02,David Raposo&&Sam Ritter&&Blake Richards&&Timothy Lillicrap&&Peter Conway Humphreys&&Adam Santoro,arxiv,https://arxiv.org/abs/2404.02258
MuLan: A Study of Fact Mutability in Language Models,"사실은 비상 사태의 대상이되며 다른 상황에서는 사실 또는 거짓일 수 있습니다.그러한 비상 사태 중 하나는 시간이 지남에 따라 일부 사실이 주어진 기간에 걸쳐 돌연변이되는 시간, 예를 들어 국가 회장 또는 챔피언십의 우승자입니다.신뢰할 수있는 언어 모델은 변한 사실을 이상적으로 식별하여 그에 따라 처리합니다.우리는 1 : 1과 1 : N 관계를 모두 다루는 시간 소지를 예상하는 영어 모델의 능력을 평가하기위한 벤치 마크인 Mulan을 만듭니다.우리는 돌연변이 가능한 사실이 불변의 사실과 다르게 인코딩되어 업데이트하기가 더 쉽다는 가설을 세웁니다.6 가지 대중적인 대형 언어 모델에 대한 자세한 평가에서 사실의 돌연변이에 따라 LLMS의 신뢰, 표현 및 업데이트 동작의 차이를 지속적으로 발견합니다.우리의 연구 결과는 LLM에 대한 시간에 대한 지식의 주입 및 유도에 대한 미래의 작업을 알려야합니다.",2024.04.03,Constanza Fierro&&Nicolas Garneau&&Emanuele Bugliarello&&Yova Kementchedjhieva&&Anders Søgaard,arxiv,https://arxiv.org/abs/2404.03036
Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction,"우리는 시각적자가 회귀 모델링 (VAR)을 제시하는 새로운 세대 패러다임을 제시하는 새로운 세대 패러다임을 제시하는 새로운 세대 패러다임을 제시하는 시각적 패러다임을 제시합니다.이 패러다임은 표준 Raster-Scan ""Next-에서 분기되는 거친""차세대 예측 ""또는""차세 해상도 예측 ""으로 이미지에 대한 자동 회귀 학습을 재정의합니다.토큰 예측 "".이 간단하고 직관적 인 방법론을 통해 AR (Autoregreastive) 변압기는 시각적 분포를 빠르게 배우고 잘 일반화 할 수 있습니다. VAR, 처음으로 AR 모델은 이미지 생성에서 확산 변압기를 능가합니다.ImageNet 256X256 벤치 마크에서 VAR은 Frechet Inception Disting (FID)을 18.65에서 1.80으로 개선하여 AR 기준을 크게 향상시킵니다.VAR은 이미지 품질, 추론 속도, 데이터 효율 및 확장 성을 포함한 여러 차원에서 확산 변압기 (DIT)를 능가하는 것으로 경험적으로 확인됩니다.VAR 모델을 스케일링하면 LLM에서 관찰 된 것과 유사한 명확한 전력 법률 스케일링 법칙을 보여줍니다.VAR은 이미지 인 페인팅, 아웃 페인팅 및 편집을 포함하여 다운 스트림 작업에서 제로 샷 일반화 능력을 보여줍니다.이 결과는 VAR이 LLM의 두 가지 중요한 속성, 즉 스케일링 법률과 제로 샷 작업 일반화를 처음에 모방했음을 시사합니다.우리는 시각적 생성 및 통합 학습을위한 AR/VAR 모델의 탐색을 촉진하기 위해 모든 모델과 코드를 발표했습니다.",2024.04.03,Keyu Tian&&Yi Jiang&&Zehuan Yuan&&Bingyue Peng&&Liwei Wang,arxiv,https://arxiv.org/abs/2404.02905
ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline,"대형 언어 모델 (LLMS)은 인간 언어의 우수한 마스터 링을 보여 주었지만 수학적 문제 해결이 필요한 실제 응용 프로그램에서 여전히 어려움을 겪고 있습니다.LLM의 수학을 향상시키기위한 많은 전략과 데이터 세트가 개발되었지만, 배포 된 LLM에서 언어와 수학적 기능을 동시에 유지하고 개선하는 것은 여전히 HTTP URL이 작업을 수행하는 데 어려움을 겪고 있습니다.LLM 정렬 단계.우리는 먼저 LLM 자체에서 일반적인 수학 크리티컬 모델을 훈련시켜 피드백 신호를 제공합니다.그런 다음 데이터 수집을 위해 LLM 자체 세대에 대한 거부 미세 조정 및 직접 선호도 최적화를 순차적으로 사용합니다.ChatGLM3-32B를 기반으로, 우리는 학계와 새로 만든 도전적인 데이터 세트 인 MathusereVal에 대한 일련의 실험을 수행합니다.결과에 따르면 파이프 라인이 LLM의 수학적 문제 해결을 크게 향상시키면서 언어 능력을 향상시켜 LLM이 2 배 더 커질 수 있습니다.관련 기술은 온라인 서빙 LLM 인 ChatGlm \ Footnote {this https url}}에 배포되었습니다.관련 평가 데이터 세트 및 스크립트는 \ url {this https url}에서 릴리스됩니다.",2024.04.03,Yifan Xu&&Xiao Liu&&Xinghan Liu&&Zhenyu Hou&&Yueyan Li&&Xiaohan Zhang&&Zihan Wang&&Aohan Zeng&&Zhengxiao Du&&Wenyi Zhao&&Jie Tang&&Yuxiao Dong,arxiv,https://arxiv.org/abs/2404.02893
On the Scalability of Diffusion-based Text-to-Image Generation,"LLM의 진화에는 모델과 데이터 크기를 확장하는 것이 매우 성공적이었습니다.그러나 확산 기반 텍스트-이미지 (T2I) 모델의 스케일링 법은 완전히 탐색되지 않습니다.또한 저렴한 비용으로 더 나은 성능을 위해 모델을 효율적으로 확장하는 방법도 불분명합니다.다양한 교육 설정과 고가의 교육 비용으로 인해 공정한 모델 비교가 매우 어렵습니다.이 작업에서, 우리는 600m 이미지까지 데이터 세트에서 0.4b에서 4b 매개 변수의 훈련 스케일링 UNET 및 변압기 변이체를 포함하여 데노 이어스 백본 및 훈련 세트를 모두 스케일링하는 데있어 광범위하고 엄격한 절제를 수행함으로써 확산 기반 T2I 모델의 스케일링 특성을 경험적으로 연구합니다.모델 스케일링의 경우 크로스주의 위치와 양이 기존 UNET 디자인의 성능을 구별합니다.변압기 블록을 증가시키는 것은 채널 번호를 증가시키는 것보다 텍스트 이미지 정렬을 향상시키는 데 더 매개 변수 효율적입니다.그런 다음 SDXL UNET보다 45% 더 작고 28% 빠른 효율적인 UNET 변형을 식별합니다.데이터 스케일링 측면에서, 우리는 교육 세트의 품질과 다양성이 단순히 데이터 세트 크기 이상의 문제를 보여줍니다.캡션 밀도 및 다양성을 높이면 텍스트 이미지 정렬 성능과 학습 효율이 향상됩니다.마지막으로, 모델 크기, 컴퓨팅 및 데이터 세트 크기의 스케일의 함수로서 텍스트-이미지 정렬 성능을 예측하기 위해 스케일링 함수를 제공합니다.",2024.04.03,Hao Li&&Yang Zou&&Ying Wang&&Orchid Majumder&&Yusheng Xie&&R. Manmatha&&Ashwin Swaminathan&&Zhuowen Tu&&Stefano Ermon&&Stefano Soatto,arxiv,https://arxiv.org/abs/2404.02883
Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models,"이 연구는 텍스트-조건 확산 모델에서 추론하는 동안 교차 적분의 역할을 탐구합니다.우리는 몇 가지 추론 단계 후에 교차 출력이 고정점으로 수렴한다는 것을 발견했다.따라서 수렴의 시점은 전체 추론 프로세스를 자연스럽게 두 단계로 나눕니다. 초기 시맨틱 계획 단계로,이 기간 동안 모델은 텍스트 지향적 시각적 의미를 계획하기 위해 교차 변형에 의존하고 그 이후의 충실도 면화 단계를 계획합니다.그 동안이 모델은 이전에 계획된 의미론에서 이미지를 생성하려고합니다.놀랍게도, 충실도 면제 단계에서 텍스트 조건을 무시하면 계산 복잡성을 줄일뿐만 아니라 모델 성능을 유지합니다.이는 효율적인 생성을 위해 Tgate라는 간단하고 훈련이없는 방법을 생성하며, 이는 수렴 후 크로스-내 출력을 캐시하고 나머지 추론 단계에서 고정시킵니다.MS-Coco 검증 세트에 대한 경험적 연구는 그 효과를 확인합니다.tgate의 소스 코드는이 https url에서 사용할 수 있습니다.",2024.04.03,Wentian Zhang&&Haozhe Liu&&Jinheng Xie&&Francesco Faccio&&Mike Zheng Shou&&Jürgen Schmidhuber,arxiv,https://arxiv.org/abs/2404.02747
Freditor: High-Fidelity and Transferable NeRF Editing by Frequency Decomposition,"이 논문은 주파수 분해로 고 충실도, 전송 가능한 NERF 편집을 가능하게합니다.최근 NERF 편집 파이프 라인은 2D 스타일을 3D 장면으로 들어 올리면서 흐릿한 결과를 겪고 2D 편집 사이의 불일치로 인한 상세 구조를 캡처하지 못합니다.우리의 중요한 통찰력은 이미지의 저주파 구성 요소가 고주파 부품에 비해 편집 후 다중보기 일관성이 있다는 것입니다.또한 외관 스타일은 주로 저주파 구성 요소에 전시되며 컨텐츠 세부 사항은 특히 고주파 부품에 있습니다.이는 저주파 구성 요소에 대한 편집을 수행하도록 동기를 부여하여 고 충실도 편집 장면을 초래합니다.또한 편집은 저주파 기능 공간에서 수행되므로 안정적인 강도 제어 및 새로운 장면 전송이 가능합니다.사진 데이터 세트에서 수행 된 포괄적 인 실험은 고 충실도 및 전송 가능한 NERF 편집의 우수한 성능을 보여줍니다.프로젝트 페이지는 \ url {this https url}에 있습니다.",2024.04.03,Yisheng He&&Weihao Yuan&&Siyu Zhu&&Zilong Dong&&Liefeng Bo&&Qixing Huang,arxiv,https://arxiv.org/abs/2404.02514
InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation,"튜닝이없는 확산 기반 모델은 이미지 개인화 및 사용자 정의 영역에서 상당한 잠재력을 보여주었습니다.그러나 이러한 주목할만한 진보에도 불구하고 현재 모델은 스타일 관련 이미지 생성을 생성하는 데 몇 가지 복잡한 과제를 계속해서 맞이합니다.첫째, 스타일의 개념은 본질적으로 소외되어 색상, 재료, 대기, 디자인 및 구조와 같은 다양한 요소를 포함합니다.둘째, 반전 기반 방법은 스타일의 저하가 발생하기 쉽고, 종종 세밀한 세부 사항이 상실됩니다.마지막으로, 어댑터 기반 접근법은 종종 스타일 강도와 텍스트 제어 성 사이의 균형을 달성하기 위해 각 기준 이미지에 대해 세심한 무게 튜닝이 필요합니다.이 논문에서 우리는 몇 가지 강력하지만 자주 간과되는 관찰을 조사하여 시작합니다.그런 다음 두 가지 주요 전략을 구현하여 이러한 문제를 해결하도록 설계된 프레임 워크 인 InstantStyle을 소개합니다. 1) 피처 공간 내에서 참조 이미지에서 스타일과 컨텐츠를 분리하는 간단한 메커니즘, 동일한 공간 내의 기능을 전제로합니다.서로 추가하거나 빼낼 수 있습니다.2) 참조 이미지의 주입은 독점적으로 스타일 특정 블록에만 주입하여 스타일 누출을 방지하고 더 많은 매개 변수가 많은 디자인을 특징 짓는 번거로운 무게 튜닝의 필요성을 방해합니다.스타일의 강도와 텍스트 요소의 제어 가능성.우리의 코드는 https url에서 사용할 수 있습니다.",2024.04.03,Haofan Wang&&Matteo Spinelli&&Qixun Wang&&Xu Bai&&Zekui Qin&&Anthony Chen,arxiv,https://arxiv.org/abs/2404.02733
Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models,"알고리즘 추론은 문제의 복잡한 패턴을 이해하고 솔루션을 향한 일련의 추론 단계로 분해하는 능력을 말합니다.알고리즘 추론의 이러한 특성은 다른 추론 과제에서 유망한 성능을 보여 주 었음에도 불구하고 대형 언어 모델 (LLM)에 어려움을 겪습니다.이러한 맥락에서, 최근의 일부 연구는 프로그래밍 언어 (예 : 파이썬)를 사용하여 엄격하고 정확한 구문에서 영감을 얻은 주어진 인스턴스/질문 (예 : 생각 프로그램)을 해결하는 데 필요한 논리를 표현합니다.그러나 단일 추론 호출 내에서 올바른 논리를 즉시 표현하는 실행 가능한 코드를 작성하는 것은 사소하지 않습니다.또한 인스턴스를 위해 특별히 생성 된 코드는 동일한 작업에서 발생하고 동일한 논리가 필요하더라도 다른 사람에게는 재사용 될 수 없습니다.이 논문은 언어 모델의 추론 과정을 두 단계로 분해하는 새로운 프레임 워크 인 Think-and-Execute를 제시합니다.(1) Think에서, 우리는 주어진 작업을 해결하기 위해 모든 사례에서 공유되는 작업 수준 논리를 발견 한 다음 Pseudocode로 논리를 표현합니다.(2) 실행에서, 우리는 생성 된 의사 코드를 각 인스턴스에 추가로 조정하고 코드의 실행을 시뮬레이션합니다.7 가지 알고리즘 추론 작업에 대한 광범위한 실험을 통해 생각과 실행의 효과를 보여줍니다.우리의 접근 방식은 인스턴스 별 추론 (예 : COT 및 POT)을 수행하는 몇 가지 강력한 기준선에 비해 LMS의 추론을 더 잘 향상시켜 작업 수준 논리를 발견하는 데 도움이됩니다.또한 자연 언어와 비교할 때 의사 코드는 자연어 지침을 따르도록 훈련을 받았음에도 불구하고 LMS의 추론을 더 잘 안내 할 수 있음을 보여줍니다.",2024.04.03,Hyungjoo Chae&&Yeonghyeon Kim&&Seungone Kim&&Kai Tzu-iunn Ong&&Beong-woo Kwak&&Moohyeon Kim&&Seonghwan Kim&&Taeyoon Kwon&&Jiwan Chung&&Youngjae Yu&&Jinyoung Yeo,arxiv,https://arxiv.org/abs/2404.02575
LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models,"인공 지능의 빠르게 진화하는 환경에서 멀티 모달 대형 언어 모델은 상당한 관심 분야로 떠오르고 있습니다.다양한 형태의 데이터 입력을 결합한이 모델이 점점 인기를 얻고 있습니다.그러나 내부 메커니즘을 이해하는 것은 여전히 복잡한 작업입니다.설명 도구와 메커니즘 분야에서 수많은 발전이 이루어졌지만 여전히 탐구해야 할 것이 많습니다.이 연구에서 우리는 대규모 시력 모델의 내부 메커니즘을 이해하기위한 새로운 대화식 응용 프로그램을 제시합니다.우리의 인터페이스는 답변을 생성하는 데 도움이되는 이미지 패치의 해석 가능성을 향상시키고 이미지의 출력을 접지시키는 데 언어 모델의 효능을 평가하도록 설계되었습니다.응용 프로그램을 통해 사용자는 시스템을 체계적으로 조사하고 시스템 제한을 발견하여 시스템 기능 향상을위한 길을 열 수 있습니다.마지막으로, 우리는 응용 프로그램이 인기있는 대형 멀티 모달 모델 인 Llava에서 실패 메커니즘을 이해하는 데 도움이 될 수있는 방법에 대한 사례 연구를 제시합니다.",2024.04.03,Gabriela Ben Melech Stan&&Raanan Yehezkel Rohekar&&Yaniv Gurwicz&&Matthew Lyle Olson&&Anahita Bhiwandiwalla&&Estelle Aflalo&&Chenfei Wu&&Nan Duan&&Shao-Yen Tseng&&Vasudev Lal,arxiv,https://arxiv.org/abs/2404.03118
ReFT: Representation Finetuning for Language Models,"매개 변수 효율적인 미세 조정 (PEFT) 메소드는 소수의 가중치에 대한 업데이트를 통해 대형 모델을 조정하려고합니다.그러나 많은 이전의 해석 가능성 작업에 따르면 표현이 풍부한 의미 정보를 인코딩하여 편집 표현이 더 강력한 대안 일 수 있음을 시사합니다.여기서, 우리는 \ textbf {expresionation finetuning (reft)} 방법의 가족을 개발 함으로써이 가설을 추구합니다.REFT 방법은 냉동 기본 모델에서 작동하며 숨겨진 표현에 대한 작업 별 중재를 학습합니다.우리는 REFT 패밀리, 저 순위 선형 하위 공간 REFT (loreft)의 강력한 인스턴스를 정의합니다.Loreft는 기존 PEFTS의 드롭 인 교체품이며 이전 최첨단 PEFT보다 매개 변수 효율적인 10x-50x 더 많은 중재를 배웁니다.우리는 8 개의 상식 추론 작업, 4 개의 산술 추론 작업, Alpaca-Eval v1.0 및 접착제에 대해 Loreft를 보여줍니다.이러한 모든 평가에서 Loreft는 효율성과 성능의 최고의 균형을 제공하며 거의 항상 최첨단 PEFT를 능가합니다.우리는이 HTTPS URL에 일반적인 REFT 교육 라이브러리를 공개적으로 출시합니다.",2024.04.04,Zhengxuan Wu&&Aryaman Arora&&Zheng Wang&&Atticus Geiger&&Dan Jurafsky&&Christopher D. Manning&&Christopher Potts,arxiv,https://arxiv.org/abs/2404.03592
MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens,"이 논문은 비디오 이해를 위해 특별히 설계된 멀티 모달 대형 언어 모델 (LLM) 인 Minigpt4-Video를 소개합니다.이 모델은 시간적 시각적 및 텍스트 데이터를 모두 처리 할 수있어 비디오의 복잡성을 이해하는 데 능숙합니다.시각적 기능을 단일 이미지를 위해 LLM 공간으로 번역하고 다양한 이미지 텍스트 벤치 마크에서 인상적인 결과를 얻은 Minigpt-V2의 성공을 바탕으로 모델의 기능을 확장하여 일련의 프레임을 처리 할 수 있습니다.비디오.Minigpt4-Video는 시각적 콘텐츠를 고려할뿐만 아니라 텍스트 대화를 통합하여 모델이 시각적 및 텍스트 구성 요소와 관련된 쿼리에 효과적으로 답변 할 수 있습니다.제안 된 모델은 기존 최첨단 방법을 능가하여 MSVD, MSRVTT, TGIF 및 TVQA 벤치 마크에서 각각 4.22%, 1.13%, 20.82%및 13.1%의 이득을 기록합니다.우리의 모델과 코드는 공개적으로 이용 가능했습니다 Herethis https url",2024.04.04,Kirolos Ataallah&&Xiaoqian Shen&&Eslam Abdelrahman&&Essam Sleiman&&Deyao Zhu&&Jian Ding&&Mohamed Elhoseiny,arxiv,https://arxiv.org/abs/2404.03413
Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?,"LLM (Led-Team Langues) 모델 (LLM)에 다양한 탈옥 공격이 제안되었으며 LLM의 취약한 보호 조치가 밝혀졌습니다.게다가, 일부 방법은 텍스트 양식에 국한되지 않으며 시각적 입력을 교란시켜 MLLM (Multimodal Lange Language Models)으로 탈옥 공격을 확장합니다.그러나 보편적 평가 벤치 마크가 없으면 성과 재생산과 공정한 비교가 복잡해집니다.게다가, SOTA (Stop-Source 최첨단) 모델, 특히 GPT-4V와 같은 MLLM에 대한 포괄적 인 평가가 부족합니다.이러한 문제를 해결하기 위해이 작업은 먼저 11 가지 안전 정책을 다루는 1445 개의 유해한 질문으로 포괄적 인 탈옥 평가 데이터 세트를 구축합니다.이 데이터 세트를 기반으로, SOTA 독점 모델 및 오픈 소스 모델을 포함하여 11 개의 서로 다른 LLM 및 MLLM에 대해 광범위한 빨간 팀 실험이 수행됩니다.그런 다음 평가 된 결과에 대한 깊은 분석을 수행하고 (1) GPT4 및 GPT-4V는 오픈 소스 LLM 및 MLLM에 비해 탈옥 공격에 대한 더 나은 견고성을 보여줍니다.(2) LLAMA2 및 Qwen-VL-Chat은 다른 오픈 소스 모델에 비해 더 강력합니다.(3) 시각적 탈옥 방법의 양도성은 텍스트 탈옥 방법에 비해 비교적 제한적입니다.데이터 세트와 코드는 여기에서 https://anonymous.4open.science/r/red_teaming_gpt4-c1ce/readme.md를 참조하십시오.",2024.04.04,Shuo Chen&&Zhen Han&&Bailan He&&Zifeng Ding&&Wenqian Yu&&Philip Torr&&Volker Tresp&&Jindong Gu,arxiv,https://arxiv.org/abs/2404.03411
AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent,"대형 언어 모델 (LLMS)은 웹 탐색과 같은 많은 지능형 에이전트 작업에 연료를 공급했지만 대부분의 기존 에이전트는 세 가지 요소로 인해 실제 웹 페이지에서 만족하는 것과는 거리가 멀다.HTML 텍스트는 모델 처리 용량을 초과하고 (3) 웹의 개방형 도메인 특성으로 인한 의사 결정의 복잡성.도전에 비추어, 우리는 ChatGLM3-6B에 구축 된 GPT-4 외식 자동 웹 내비게이션 에이전트 인 AutoweBGLM을 개발합니다.인간 브라우징 패턴에서 영감을 얻은 우리는 웹 페이지를 나타내는 HTML 단순화 알고리즘을 설계하여 중요한 정보를 간결하게 보존합니다.우리는 교과 과정 훈련을위한 웹 브라우징 데이터를 구축하기 위해 하이브리드 휴먼 -AI 방법을 사용합니다.그런 다음 강화 학습 및 거부 샘플링을 통해 모델을 부트 스트랩하여 웹 페이지 이해력, 브라우저 작업 및 효율적인 작업 분해를 더욱 촉진합니다.테스트를 위해 실제 웹 브라우징 작업을위한 이중 언어 벤치 마크 (Autowebbench)를 설정합니다.우리는 다양한 웹 내비게이션 벤치 마크에서 AutoweBGLM을 평가하여 개선 사항을 밝히고 실제 환경을 다루는 데 있어서도 근본적인 과제를 보여줍니다.관련 코드, 모델 및 데이터는 \ url {this https url}에서 릴리스됩니다.",2024.04.04,Hanyu Lai&&Xiao Liu&&Iat Long Iong&&Shuntian Yao&&Yuxuan Chen&&Pengbo Shen&&Hao Yu&&Hanchen Zhang&&Xiaohan Zhang&&Yuxiao Dong&&Jie Tang,arxiv,https://arxiv.org/abs/2404.03648
CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching,확산 모델은 텍스트-이미지 생성 분야에서 큰 성공을 보여주었습니다.그러나 텍스트 프롬프트와 이미지 사이의 오정렬을 완화하는 것은 여전히 어려운 일입니다.오정렬의 근본 원인은 광범위하게 조사되지 않았습니다.우리는 잘못 정렬이 부적절한 토큰주의 활성화로 인해 발생한다는 것을 관찰합니다.우리는이 현상을 확산 모델의 불충분 한 조건 활용에도 추가로 평가합니다. 이는 훈련 패러다임으로 인해 발생합니다.이 문제를 해결하기 위해 이미지-텍스트 개념 매칭 메커니즘을 사용하여 엔드 투 엔드 확산 모델 미세 조정 전략 인 Comat을 제안합니다.이미지 캡션 모델을 활용하여 이미지-텍스트 정렬을 측정하고 확산 모델을 안내하여 무시 된 토큰을 다시 방문합니다.속성 바인딩 문제를 해결하기 위해 새로운 속성 농도 모듈도 제안됩니다.이미지 또는 사람의 선호도 데이터가 없으면 20k 텍스트 프롬프트 만 사용하여 SDXL을 미세 조정하여 COMAT-SDXL을 얻습니다.광범위한 실험에 따르면 COMAT-SDXL은 두 개의 텍스트-이미지 정렬 벤치 마크에서 기준 모델 SDXL을 훨씬 능가하고 시작 성능을 달성합니다.,2024.04.04,Dongzhi Jiang&&Guanglu Song&&Xiaoshi Wu&&Renrui Zhang&&Dazhong Shen&&Zhuofan Zong&&Yu Liu&&Hongsheng Li,arxiv,https://arxiv.org/abs/2404.03653
Training LLMs over Neurally Compressed Text,"이 논문에서는 고도로 압축 된 텍스트에 대한 대형 언어 모델 (LLM)을 훈련한다는 아이디어를 탐구합니다.표준 서브 워드 토큰 화제는 작은 요인으로 텍스트를 압축하지만 신경 텍스트 압축기는 훨씬 더 높은 압축률을 달성 할 수 있습니다.신경 압축 텍스트를 통해 LLM을 직접 훈련 할 수 있다면, 이는 긴 텍스트 스팬을 쉽게 처리 할뿐만 아니라 훈련 및 서비스 효율성의 장점을 부여합니다.이 목표의 주요 장애물은 강한 압축이 학습에 적합하지 않은 불투명 출력을 생성하는 경향이 있다는 것입니다.특히, 우리는 산술 코딩을 통해 순진하게 압축 된 텍스트가 LLM에 의해 쉽게 학습 할 수 없다는 것을 알았습니다.이를 극복하기 위해, 우리는 텍스트가 각각 동일한 비트 길이로 압축하는 블록으로 분할되는 새로운 압축 기술 인 Equal-Info Windows를 제안합니다.이 방법을 사용하여, 우리는 규모로 향상되는 신경 압축 텍스트에 대한 효과적인 학습을 보여주고, 수신성 및 추론 속도 벤치 마크에 대한 넓은 마진으로 바이트 수준 기준선보다 성능이 우수합니다.우리의 방법은 동일한 매개 변수 수로 훈련 된 모델에 대한 서브 워드 토큰 화제보다 당황 스러움을 더 많이 제공하지만 서열 길이가 짧은 이점이 있습니다.시퀀스 길이가 짧 으면 자동 회귀 생성 단계가 적고 대기 시간이 줄어 듭니다.마지막으로, 우리는 학습성에 기여하는 속성에 대한 광범위한 분석을 제공하고, 고압 토큰 화제의 성능을 더욱 향상시키는 방법에 대한 구체적인 제안을 제공합니다.",2024.04.04,Brian Lester&&Jaehoon Lee&&Alex Alemi&&Jeffrey Pennington&&Adam Roberts&&Jascha Sohl-Dickstein&&Noah Constant,arxiv,https://arxiv.org/abs/2404.03626
RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis,"우리는 텍스트 음성 (TTS) 합성을위한 강력한 언어 모델링 방법 인 Rall-E를 제시합니다.LLMS (Largin Language Models)를 기반으로 한 이전 작업은 제로 샷 TT에 대한 인상적인 성능을 보여 주지만, 이러한 방법은 불안정한 프로디 (이상한 피치 및 리듬/지속 시간) 및 높은 워드 오류율 (WER)과 같은 강력한 견고성으로 어려움을 겪고 있습니다.자가 회귀 예측 스타일의 언어 모델로 인해.Rall-e의 핵심 아이디어는 COT (Chain-of-Ethought) 프롬프트이며,이 작업은 LLM 기반 TTS의 견고성을 향상시키기 위해 작업을 더 간단한 단계로 분해합니다.이 아이디어를 달성하기 위해 Rall-E First는 입력 텍스트의 Prosody 기능 (피치 및 지속 시간)을 예측하고 COT 스타일의 음성 토큰을 예측하기 위해 중간 조건으로 사용합니다.둘째, Rall-E는 음성 토큰을 예측할 때 해당 음운 및 프로 시저 기능에 중점을 두도록 변압기에서 자체 소지 중량의 컴퓨팅을 안내하기 위해 예측 된 지속 시간 프롬프트를 사용합니다.포괄적 인 목표 및 주관적 평가 결과 강력한 기준선 방법 Vall-E와 비교하여 Rall-E는 6.3 \%(재실행없이) 및 2.1 \%(재실행 포함)에서 제로 샷 TTS의 WER을 크게 향상 시킨다는 것을 보여줍니다.각각 22.8 \%및 1.0 \%.또한, 우리는 Rall-E가 Vall-e에 어려운 문장을 올바르게 합성하고 오류율을 68 \%to4 \%에서 감소 시킨다는 것을 보여줍니다.",2024.04.04,Detai Xin&&Xu Tan&&Kai Shen&&Zeqian Ju&&Dongchao Yang&&Yuancheng Wang&&Shinnosuke Takamichi&&Hiroshi Saruwatari&&Shujie Liu&&Jinyu Li&&Sheng Zhao,arxiv,https://arxiv.org/abs/2404.03204
PointInfinity: Resolution-Invariant Point Diffusion Models,"우리는 효율적인 포인트 구름 확산 모델 인 PointInfinity를 제시합니다.우리의 핵심 아이디어는 고정 크기의 해상도 불변의 잠재적 표현으로 변압기 기반 아키텍처를 사용하는 것입니다.이를 통해 저해상도 포인트 클라우드로 효율적인 훈련을 가능하게하면서 추론 중에 고해상도 포인트 구름이 생성 될 수 있습니다.더 중요한 것은 훈련 분해능을 넘어 테스트 시간 해상도를 스케일링하면 생성 된 포인트 구름과 표면의 충실도가 향상됨을 보여줍니다.우리는이 현상을 분석하고 확산 모델에서 일반적으로 사용되는 분류기가없는 지침에 대한 링크를 그려서 추론 중에 충실도와 변동성을 거래 할 수 있음을 보여줍니다.CO3D에 대한 실험은 PointInfinity가 최첨단 품질로 고해상도 포인트 구름 (최대 131k 포인트, Point-E보다 31 배)을 효율적으로 생성 할 수 있음을 보여줍니다.",2024.04.04,Zixuan Huang&&Justin Johnson&&Shoubhik Debnath&&James M. Rehg&&Chao-Yuan Wu,arxiv,https://arxiv.org/abs/2404.03566
CodeEditorBench: Evaluating Code Editing Capability of Large Language Models,"코드의 LLM (Large Language Models)은 빠르게 발전하고 있으며 코드 편집은 중요한 기능으로 나타납니다.우리는 디버깅, 번역, 연마 및 요구 사항 전환을 포함하여 코드 편집 작업에서 LLM의 성능을 엄격하게 평가하도록 설계된 평가 프레임 워크 인 CodeeditorBench를 소개합니다.코드 생성에만 초점을 둔 기존 벤치 마크와 달리 Codeeditorbench는 실제 시나리오와 소프트웨어 개발의 실질적인 측면을 강조합니다.다양한 프로그래밍 언어, 복잡성 수준 및 편집 작업을 다루는 5 가지 소스에서 다양한 코딩 문제와 시나리오를 선별합니다.19 개의 LLM의 평가에 따르면 폐쇄 소스 모델 (특히 Gemini-Ultra 및 GPT-4)은 CodeeditorBench의 오픈 소스 모델을 능가하여 문제 유형 및 신속한 감도에 따라 모델 성능의 차이를 강조합니다.CodeeditorBench는 코드 편집 기능을 평가하기위한 강력한 플랫폼을 제공하여 LLM의 발전을 촉진하는 것을 목표로합니다.커뮤니티가 데이터 세트를 확장하고 신흥 LLM을 벤치마킹 할 수 있도록 모든 프롬프트와 데이터 세트를 출시 할 것입니다.CodeeditorBench를 도입함으로써 우리는 코드 편집에서 LLM의 발전에 기여하고 연구원과 실무자에게 귀중한 자원을 제공합니다.",2024.04.04,Jiawei Guo&&Ziming Li&&Xueling Liu&&Kaijing Ma&&Tianyu Zheng&&Zhouliang Yu&&Ding Pan&&Yizhi LI&&Ruibo Liu&&Yue Wang&&Shuyue Guo&&Xingwei Qu&&Xiang Yue&&Ge Zhang&&Wenhu Chen&&Jie Fu,arxiv,https://arxiv.org/abs/2404.03543
Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences,"이 논문은 강력한 Oracle의 선호도 피드백을 사용하여 LLM (Lange Language Model)을 훈련시켜 모델이 반복적으로 개선되도록 도와줍니다.훈련 후 LLM에 대한 전형적인 접근법은 전통적으로 보상 학습과 후속 정책 최적화를 분리하는 인간 피드백 (RLHF)의 강화 학습을 포함합니다.그러나 이러한 보상 최대화 접근법은 복잡한 비정규 적 또는 주기적 선호 관계를 표현하지 못하는 ""포인트 현저한""보상 (예 : Bradley-Terry 모델)의 특성에 의해 제한됩니다.RLHF 쇼의 발전 보상 학습 및 정책 최적화는 안정성에 대한 단일 대조적 목표로 병합 될 수 있지만 여전히 보상 최대화 프레임 워크에 묶여 있습니다.최근에, 새로운 연구의 물결은 ""쌍별""또는 일반적인 선호도보다 직접 최적화하는 데 유리한 보상 최대화 추정을 회피합니다.이 백서에서는 일반적인 선호도를 최적화함으로써 이론적 인 일반성과 대조적 인 학습의 단순성과 안정성과 결혼 할 수 있고 확장 가능한 알고리즘 인 DNO (Direct Nash Optimization)를 소개합니다.DNO는 회귀 기반 목표를 사용하여 배치 된 정책 알고리즘이기 때문에 구현은 간단하고 효율적입니다.또한 DNO는 반복적으로 단조로운 개선을 즐기며 강력한 교사 (예 : GPT-4)에서도 개선하는 데 도움이됩니다.우리의 실험에서, DNO에 의해 정렬 된 결과 7b 매개 변수 ORCA-2.5 모델은 Alpacaeval 2.0에서 GPT-4 터보에 대한 최신 승리률을 달성합니다 (응답 길이를 제어 한 후에도)초기화 모델에 비해 26% (7% ~ 33%)의 이득.Mistral Large, Self-Rewarding LM (70b 매개 변수) 및 이전 버전의 GPT-4를 포함하여 훨씬 더 많은 매개 변수로 모델을 능가합니다.",2024.04.04,Corby Rosset&&Ching-An Cheng&&Arindam Mitra&&Michael Santacroce&&Ahmed Awadallah&&Tengyang Xie,arxiv,https://arxiv.org/abs/2404.03715
CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues,"지시 조정 데이터 세트의 최근 발전은 주로 수학적 또는 논리적 추론과 같은 특정 작업에 중점을두고 있습니다.대화의 주제 관련성을 유지하기 위해 언어 모델을 조정하기 위해 설계된 데이터에는 주목할만한 차이가있었습니다. 챗봇을 제작에 배치하는 데 중요한 측면입니다.우리는 언어 모델이 작업 중심 상호 작용 중에 당면한 주제에 집중할 수 있도록 CanttalkaboutThis DataSet을 소개합니다.그것은 다른 도메인의 광범위한 대화 주제에 대한 합성 대화로 구성됩니다.이 대화는 의도적으로 챗봇을 사전 정의 된 주제에서 전환시키는 산만 턴으로 산재합니다.이 데이터 세트의 미세 조정 언어 모델은 할당 된 역할을 수행하는 데 탄력적으로 만들어주고 GPT-4 터보 및 Mixtral-Intruct와 같은 일반 목적 교육 LLM에 비해 국소 일관성을 유지하는 능력을 향상시킵니다.또한, 예비 관찰은이 데이터 세트의 교육 모델도 세밀한 지시에 따라 작업에 대한 성능을 향상 시킨다고 제안합니다.",2024.04.04,Makesh Narsimhan Sreedhar&&Traian Rebedea&&Shaona Ghosh&&Christopher Parisien,arxiv,https://arxiv.org/abs/2404.03820
"No ""Zero-Shot"" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance","웹 크롤링 된 사전 조정 데이터 세트는 분류/검색 클립 및 이미지 생성에 대한 안정적인 확산과 같은 멀티 모달 모델의 인상적인 ""제로 샷""평가 성능에 기초합니다.그러나, ""제로 샷""일반화의 개념은 이러한 멀티 모달 모델에 대해 얼마나 의미가 없는지 불분명합니다. 예전의 데이터 세트가 ""제로 샷""평가 중에 타겟팅 된 다운 스트림 개념을 어느 정도까지 포함하는지 알려지지 않았기 때문입니다.이 작업에서 우리는 다음과 같이 묻습니다. 다운 스트림 개념에 대한 멀티 모달 모델의 성능은 전처리 데이터 세트에서 이러한 개념의 빈도에 영향을 받는가?300GB 이상의 데이터 아티팩트를 생성하는 34 개의 모델과 5 개의 표준 사전 계통 데이터 세트 (CC-3M, CC-12M, YFCC-15M, LAION-400M, LAION-ASSHETICS) 에서이 질문을 종합적으로 조사합니다.우리는 ""제로 샷""일반화를 나타내는 것 외에도, 멀티 모달 모델은 샘플 비효율적 인 로그 라이어 스케일링 경향에 따라 다운 스트림 ""제로 샷""성능의 선형 개선을 달성하기 위해 기하 급수적으로 더 많은 데이터가 필요하다는 것을 발견했습니다.이 추세는 사전 여과와 다운 스트림 데이터 세트 사이의 샘플 수준 유사성을 제어하고 순수 합성 데이터 분포에 대한 테스트를 제어 할 때에도 지속됩니다.또한, 분석을 바탕으로 샘플링 된 긴 꼬리 데이터의 벤치마킹 모델에 따라, 우리는 보드 전체의 멀티 모달 모델이 제대로 작동하지 않음을 보여줍니다.우리는이 긴 꼬리 테스트 세트를 ""Let it Wag!""로 기부합니다.이 방향으로의 추가 연구를위한 벤치 마크.종합하면, 우리의 연구는 대규모 훈련 패러다임 하에서 ""제로 샷""일반화 기능의 열쇠가 여전히 발견되어야한다는 것을 의미하는 교육 데이터에 대한 기하 급수적 인 필요성을 보여줍니다.",2024.04.04,Vishaal Udandarao&&Ameya Prabhu&&Adhiraj Ghosh&&Yash Sharma&&Philip H.S. Torr&&Adel Bibi&&Samuel Albanie&&Matthias Bethge,arxiv,https://arxiv.org/abs/2404.04125
Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model,"이 연구에서, 우리는 LLM을 개발할 때 중국어의 우선 순위를 정하는 데 대한 중추적 인 전환을 보여주는 2B 대형 언어 모델 (LLM) 인 CT-LLM을 소개합니다.CT-LLM은 처음부터 독창적으로 시작하여 주로 중국어 텍스트 데이터를 통합하여 기존의 방법론에서 발산되어 8 천억 개의 중국 토큰, 3 천억 개의 영어 토큰 및 1,000 억 코드 토큰을 포함하여 1,200 억 개의 토큰을 사용하여 중국어 텍스트 데이터를 주로 통합함으로써 기존의 방법론에서 분기됩니다.이 전략적 구성은 중국어를 이해하고 처리하는 데있어 모델의 탁월한 능력을 촉진하며, 정렬 기술을 통해 더욱 향상되었습니다.CT-LLM은 CHC- 벤치에서 놀라운 성능을 보여 주면서 중국어 작업에 탁월하며 SFT를 통해 영어로의 능력을 보여줍니다.이 연구는 영어 Corpora에서 LLM을 주로 훈련시키는 패러다임에 도전 한 다음 다른 언어에 적응하여 LLM 교육 방법론에 대한 지평을 넓히는 데 도전합니다.획득 한 대규모 적절한 전제 중국 코퍼스 (MAP-CC), 잘 선택된 다 분야 중국 하드 케이스 벤치 마크 (CHC- 벤치)를 포함한 세부 데이터 처리 절차를 포함하여 중국 LLM을 훈련시키는 전체 프로세스를 개방형 소싱함으로써2B 사이즈 중국 Tiny LLM (CT-LLM), 우리는 학계와 산업 모두에서 추가 탐사와 혁신을 촉진하여보다 포괄적이고 다재다능한 언어 모델을위한 길을 열어줍니다.",2024.04.05,Xinrun Du&&Zhouliang Yu&&Songyang Gao&&Ding Pan&&Yuyang Cheng&&Ziyang Ma&&Ruibin Yuan&&Xingwei Qu&&Jiaheng Liu&&Tianyu Zheng&&Xinchen Luo&&Guorui Zhou&&Binhang Yuan&&Wenhu Chen&&Jie Fu&&Ge Zhang,arxiv,https://arxiv.org/abs/2404.04167
Robust Gaussian Splatting,"이 논문에서는 핸드 헬드 전화 캡처의 재구성과 같은 실제 애플리케이션에 대한 견고성을 개선하기 위해 블러, 불완전한 카메라 포즈 및 색상 불일치를 포함하여 3D 가우시안 플래팅 (3DG)의 일반적인 오류 소스를 다룹니다.우리의 주요 기여는 카메라 포즈에 대한 가우시안 분포로 모션 블러를 모델링하는 것과 관련하여 카메라 포즈 세분화와 모션 블러 수정을 통합적인 방식으로 해결할 수 있습니다.또한, 우리는 Defocus 블러 보상 및 주변 조명, 그림자로 인한 색상의 컨텐츠 또는 다양한 흰색 밸런싱 설정과 같은 카메라 관련 요소로 인해 메커니즘을 제안합니다.우리의 제안 된 솔루션은 훈련 효율 및 렌더링 속도 측면에서 이점을 유지하면서 3DG 제제와 완벽한 방식으로 통합됩니다.우리는 Scannet ++ 및 DeBlur-Nerf를 포함한 관련 벤치 마크 데이터 세트에 대한 기여를 실험적으로 검증하여 최첨단 결과를 얻어 관련 기준선에 대한 일관된 개선을 실험적으로 검증합니다.",2024.04.05,François Darmon&&Lorenzo Porzi&&Samuel Rota-Bulò&&Peter Kontschieder,arxiv,https://arxiv.org/abs/2404.04211
Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation,"다중 모달 시맨틱 세분화는 특히 저조도 또는 과다 노출 된 환경과 같은 불리한 조건에서 AI 에이전트의 인식 및 장면 이해를 크게 향상시킵니다.기존 RGB와 함께 열 및 깊이와 같은 추가 양식 (x- 모형)을 활용하면 보완적인 정보가 제공되어보다 강력하고 신뢰할 수있는 세분화가 가능합니다.이 작업에서 우리는 선택적 구조화 된 상태 공간 모델 인 Mamba를 사용하여 멀티 모달 의미 론적 세분화를위한 시암 맘바 네트워크 인 Sigma를 소개합니다.제한된 로컬 수용 필드 또는 VITS (Vision Cleartive Fields)가 제한된 로컬 수용 필드 (VIT)를 사용하여 CNN에 의존하는 기존의 방법과 달리, 우리의 모델은 선형 복잡성으로 글로벌 수용 필드 커버리지를 달성합니다.시암 인코더를 사용하고 맘바 퓨전 메커니즘을 혁신함으로써, 우리는 다른 양식에서 필수 정보를 효과적으로 선택합니다.그런 다음 디코더가 모델의 채널 별 모델링 능력을 향상시키기 위해 개발됩니다.우리의 방법 인 Sigma는 RGB-thermal 및 RGB-Depth 세분화 작업 모두에서 엄격하게 평가되며, 그 우월성을 입증하고 다중 모드 인식 작업에서 State Space Model (SSM)의 첫 번째 성공적인 적용을 표시합니다.이 https url에서 코드를 사용할 수 있습니다.",2024.04.05,Zifu Wan&&Yuhao Wang&&Silong Yong&&Pingping Zhang&&Simon Stepputtis&&Katia Sycara&&Yaqi Xie,arxiv,https://arxiv.org/abs/2404.04256
Social Skill Training with Large Language Models,사람들은 갈등 해결과 같은 사회적 기술에 의존하여 효과적으로 의사 소통하고 일과 개인 생활에서 번성합니다.그러나 사회 기술을위한 실습 환경은 일반적으로 대부분의 사람들에게 손이 닿지 않습니다.사회적 기술 훈련을보다 이용할 수 있고 접근 가능하며 초대 할 수있는 방법은 무엇입니까?커뮤니케이션 및 심리학의 학제 간 연구를 바탕 으로이 관점 논문은 특수 분야에 들어가는 사회적 기술 장벽을 식별합니다.그런 다음 일반적인 프레임 워크를 통해 소셜 기술 훈련을위한 큰 언어 모델을 활용하는 솔루션을 제시합니다.우리의 AI 파트너 인 AI 멘토 프레임 워크는 체험 학습을 현실적인 연습과 맞춤형 피드백과 병합합니다.이 작업은 궁극적으로 인력 개발 및 사회적 평등에 대한 광범위한 영향을 해결하기 위해 학제 간 혁신을 요구합니다.,2024.04.05,Diyi Yang&&Caleb Ziems&&William Held&&Omar Shaikh&&Michael S. Bernstein&&John Mitchell,arxiv,https://arxiv.org/abs/2404.04204
SpatialTracker: Tracking Any 2D Pixels in 3D Space,"비디오에서 조밀하고 장거리 픽셀 동작을 회복하는 것은 어려운 문제입니다.어려움의 일부는 3D-2D 프로젝션 프로세스에서 발생하여 2D 모션 도메인의 폐색 및 불연속으로 이어집니다.2D 모션은 복잡 할 수 있지만, 우리는 기본 3D 운동이 종종 단순하고 저 차원 일 수 있다고 주장합니다.이 작업에서는 이미지 투영으로 인한 문제를 완화하기 위해 3D 공간의 포인트 궤적을 추정 할 것을 제안합니다.SpatialTracker라는 우리의 방법은 단금 깊이 추정기를 사용하여 2D 픽셀을 3D로 들어 올리며 트리플란 표현을 사용하여 각 프레임의 3D 함량을 효율적으로 나타내며 변압기를 사용하여 3D 궤적을 추정하기 위해 반복 업데이트를 수행합니다.3D를 추적하면 ARAP (Rigid-As-Arsible) 제약 조건을 활용하는 동시에 픽셀을 다른 강성 부품으로 픽셀로 포함하는 강성 임베딩을 동시에 학습 할 수 있습니다.광범위한 평가에 따르면 우리의 접근 방식은 특히 평면 외 회전과 같은 도전적인 시나리오에서 질적 및 정량적으로 최첨단 추적 성능을 달성합니다.",2024.04.05,Yuxi Xiao&&Qianqian Wang&&Shangzhan Zhang&&Nan Xue&&Sida Peng&&Yujun Shen&&Xiaowei Zhou,arxiv,https://arxiv.org/abs/2404.04319
Koala: Key frame-conditioned long video-LLM,"긴 비디오 질문 답변은 단기 활동을 인식하고 세밀한 관계에 대한 추론을 포함하는 어려운 과제입니다.최첨단 비디오 대형 언어 모델 (VLLM)은 새로운 작업에 대한 출현 능력으로 인해 실행 가능한 솔루션으로 약속을 잡습니다.그러나 수백만 초 긴 비디오에 대한 교육을 받았음에도 불구하고 VLLM은 몇 분 길이의 비디오를 이해하고 이에 대한 질문에 정확하게 답변 할 수 없습니다.이 한계를 해결하기 위해, 우리는 더 긴 비디오를 일반화하기 위해 사전 각인 VLLM을 적응시키기 위해 학습 가능한 시공간의 쿼리를 소개하는 Key Frame Condited Long Video-LLM (Koala)을 소개하는 가볍고 자체 감독 된 접근법을 제안합니다.우리의 접근 방식은 짧고 긴 비디오 순간을 이해하기 위해 스파 스 비디오 키 프레임에서 계산 된 비주얼 토큰의 조건을 조정하는 두 개의 새로운 토큰 화기를 소개합니다.우리는 Howto100m에 대한 제안 된 접근 방식을 훈련시키고 장거리 비디오 이해 벤치 마크에 대한 효과를 보여줍니다. 여기서 모든 작업에서 최첨단 대형 모델을 3-6% 성능이 우수합니다.놀랍게도, 우리는 또한 우리의 접근 방식이 사전에 취한 VLLM이 긴 비디오를 이해하는 데 도움이 될뿐만 아니라 단기 행동 인식에 대한 정확성을 향상 시킨다는 것을 경험적으로 보여줍니다.",2024.04.05,Reuben Tan&&Ximeng Sun&&Ping Hu&&Jui-hsien Wang&&Hanieh Deilamsalehy&&Bryan A. Plummer&&Bryan Russell&&Kate Saenko,arxiv,https://arxiv.org/abs/2404.04346
PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations,"모델링 및 렌더링 사진 아바타는 많은 응용 분야에서 매우 중요합니다.그러나 시각적 관찰로부터 3D 아바타를 구축하는 기존의 방법은 옷을 입은 인간을 재구성하기 위해 고군분투합니다.우리는 역 렌더링과 역 물리학을 결합하여 복장 비디오 데이터와 의류 패브릭의 물리적 매개 변수와 함께 인간의 모양과 모양을 자동으로 추정하는 새로운 프레임 워크 인 Physavatar를 소개합니다.이를 위해, 본 발명자들은 공간 중심 메쉬 추적을위한 메쉬 정렬 4D 가우스 기술을 채택하여 물리적으로 기반 역 렌더러를 사용하여 고유 재료 특성을 추정합니다.Physavatar는 물리 시뮬레이터를 통합하여 구배 기반 최적화를 사용하여 원칙적으로 의류의 물리적 매개 변수를 추정합니다.이 새로운 기능을 통해 Physavatar는 훈련 데이터에서 볼 수없는 움직임 및 조명 조건에서 느슨한 옷을 입은 아바타의 고품질 소설 렌더링을 만들 수 있습니다.이는 루프에서 물리학과 물리 기반 역 렌더링을 사용하여 사진을 사용하여 사진을 찍는 디지털 인간을 모델링하는 데 큰 발전을 가져옵니다.프로젝트 웹 사이트는 다음과 같습니다.이 HTTPS URL",2024.04.05,Yang Zheng&&Qingqing Zhao&&Guandao Yang&&Wang Yifan&&Donglai Xiang&&Florian Dubost&&Dmitry Lagun&&Thabo Beeler&&Federico Tombari&&Leonidas Guibas&&Gordon Wetzstein,arxiv,https://arxiv.org/abs/2404.04421
Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models,"트랜스포머는 컴퓨터 비전 및 자연어 처리 (NLP) 분야의 발전을 촉진했습니다.그러나 상당한 계산 복잡성은 고해상도 이미지 생성과 같은 장기 텍스트 작업에서 응용 프로그램에 제한을 제기합니다.이 논문은 NLP에 사용 된 RWKV 모델에서 조정 된 일련의 아키텍처를 소개하며, 확산 RWKV라고하는 이미지 생성 작업에 적용되는 확산 모델에 맞게 조정 된 필수 수정이 있습니다.변압기와의 확산과 유사하게, 우리의 모델은 추가 조건으로 순서대로 패치 리화 된 입력을 효율적으로 처리하고 효과적으로 확장하여 대규모 매개 변수와 광범위한 데이터 세트를 모두 수용하도록 설계되었습니다.그것의 독특한 이점은 감소 된 공간 집계 복잡성에 나타나 고해상도 이미지를 처리하는 데 능숙하게 만들어 창 또는 그룹 캐시 된 작업의 필요성을 제거합니다.조건 및 무조건 이미지 생성 작업 모두에 대한 실험 결과는 Diffison-RWKV가 FID의 기존 CNN 또는 변압기 기반 확산 모델과 동등한 성능을 달성하거나 총체 계산 플롭 사용량을 크게 줄이는 동시에 성능을 달성합니다.",2024.04.06,Zhengcong Fei&&Mingyuan Fan&&Changqian Yu&&Debang Li&&Junshi Huang,arxiv,https://arxiv.org/abs/2404.04478
DATENeRF: Depth-Aware Text-based Editing of NeRFs,"확산 모델의 최근 발전은 텍스트 프롬프트를 기반으로 2D 이미지를 편집하는 데 놀라운 능력을 보여주었습니다.그러나 개별 2D 프레임을 편집하면 여러 뷰에서 불일치를 초래할 수 있으므로 이러한 기술을 신경 방사선 필드 (NERF)에서 편집하기 위해 이러한 기술을 확장하는 것은 복잡합니다.우리의 중요한 통찰력은 NERF 장면의 형상 이이 2D 편집을 통합하는 브리지 역할을 할 수 있다는 것입니다.이 형상을 사용하여 각 2D 이미지 수정의 일관성을 향상시키기 위해 깊이 조절 된 Controlnet을 사용합니다.또한, 우리는 NERF 장면의 깊이 정보를 활용하여 다른 이미지에 2D 편집을 배포하여 오류에 대한 견고성과 리샘플링 문제를 보장하는 인 페인팅 접근법을 소개합니다.우리의 결과는이 방법론이 텍스트 중심 NERF 장면 편집을위한 기존 주요 방법보다 더 일관되고 생생하고 세부적인 편집을 달성한다는 것을 보여줍니다.",2024.04.06,Sara Rojas&&Julien Philip&&Kai Zhang&&Sai Bi&&Fujun Luan&&Bernard Ghanem&&Kalyan Sunkavall,arxiv,https://arxiv.org/abs/2404.04526
Aligning Diffusion Models by Optimizing Human Utility,"우리는 예상되는 인간 유용성의 최대화로서 정렬 목표를 공식화함으로써 텍스트-이미지 확산 모델을 정렬하기위한 새로운 접근법 인 확산 -KTO를 제시한다.이 목표는 각 세대에 독립적으로 적용되므로 확산 -KTO는 비용이 많이 드는 쌍 선호도 데이터를 수집하거나 복잡한 보상 모델을 훈련시킬 필요가 없습니다.대신, 우리의 목표에는 간단한 이미지 당 이진 피드백 신호가 필요합니다 (예 :풍부하게 제공되는 좋아하거나 싫어하는 것.확산 -KTO를 사용한 미세 조정 후, 텍스트-이미지 확산 모델은 인간의 판단 및 PickScore 및 ImageRower와 같은 자동 평가 지표 모두에서 감독 된 미세 조정 및 확산 -DPO를 포함한 기존 기술에 비해 우수한 성능을 나타냅니다.전반적으로, 확산 -KTO는 쉽게 이용 가능한 이미지 별 이진 신호를 활용할 수있는 잠재력을 해제하고 텍스트-이미지 확산 모델을 인간 선호도와 정렬하는 적용 가능성을 확대합니다.",2024.04.06,Shufan Li&&Konstantinos Kallidromitis&&Akash Gokul&&Yusuke Kato&&Kazuki Kozuka,arxiv,https://arxiv.org/abs/2404.04465
BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion,"세부 사항과 컨트롤로 고해상도의 인간 중심 장면을 생성하는 것은 기존 텍스트-이미지 확산 모델에 대한 과제입니다.이 도전은 제한된 훈련 이미지 크기, 텍스트 인코더 용량 (제한된 토큰) 및 여러 인간과 관련된 복잡한 장면을 생성하는 고유의 어려움에서 비롯됩니다.현재의 방법은 훈련 크기 한계 만 해결하려고 시도했지만 종종 심각한 인공물로 인간 중심의 장면을 생성했습니다.우리는 이전 한계를 극복하는 새로운 프레임 워크 인 Beyondscene을 제안하고, 기존의 사전 여분의 확산 모델을 사용하여 탁월한 텍스트 이미지 통신 및 자연성을 가진 절묘한 고해상도 (8K 이상) 인간 중심 장면을 생성합니다.Beyondscene은 단계적이고 계층 적 접근 방식을 사용하여 처음에 여러 인간의 예를 들어 생성 및 확산 모델의 토큰 한계를 넘어서는 세부적인 설명에서 중요한 요소에 중점을 둔 상세한 기본 이미지를 생성 한 다음 기본 이미지를 더 높은 해상 출력으로 완벽하게 변환하여 초과이미지 크기를 훈련하고 세부 사항을 통합하여 우리의 새로운 인스턴스 인식 계층 적 확대 프로세스를 통한 텍스트와 인스턴스를 통합하여 제안 된 고주파 전방 확산 및 적응 형 조인트 확산으로 구성됩니다.이후 세부는 상세한 텍스트 설명 및 자연과의 대응 측면에서 기존의 방법을 능가하며, 고도의 재교육이 비싼 재교육없이 고해상도의 인간 중심 장면 생성에서 고급 응용 프로그램의 길을 열어줍니다.프로젝트 페이지 :이 HTTPS URL.",2024.04.06,Gwanghyun Kim&&Hayeon Kim&&Hoigi Seo&&Dong Un Kang&&Se Young Chun,arxiv,https://arxiv.org/abs/2404.04544
"ByteEdit: Boost, Comply and Accelerate Generative Image Editing","확산 기반 생성 이미지 편집의 최근 발전은 심오한 혁명을 일으켜 이미지가 돋보이는 작업의 풍경을 재구성하고 작업을 수행했습니다.이러한 보폭에도 불구하고, 현장은 다음을 포함하여 고유 한 도전에 맞서지 않는다. i) 열등한 품질;ii) 일관성 불량;iii) 불충분 한 도구 준수;iv) 차선의 생성 효율성.이러한 장애물을 해결하기 위해, 우리는 Byteedit, 혁신적인 피드백 학습 프레임 워크 인 Byteedit를 생성 된 이미지 편집 작업을 강화, 준수 및 가속화하도록 세 심하게 설계되었습니다.Byteedit는 미학 및 이미지 텍스트 정렬을 향상시키는 데 전념하는 이미지 보상 모델을 완벽하게 통합하는 한편 출력의 일관성을 높이기 위해 조정 된 조밀 한 픽셀 레벨 보상 모델을 도입합니다.또한, 우리는 모델의 추론 속도를 신속하게하기 위해 선구적인 적대 및 진보적 인 피드백 학습 전략을 제안합니다.광범위한 대규모 사용자 평가를 통해 Byteedit은 Adobe, Canva 및 Meitu를 포함한 주요 생성 이미지 편집 제품을 세대 품질과 일관성 모두에서 능가한다는 것을 보여줍니다.ByteeDit-outpainting은 기준선 모델과 비교할 때 각각 품질 및 일관성이 각각 388% 및 135%의 놀라운 향상을 나타냅니다.실험은 또한 우리의 가속 모델이 품질과 일관성 측면에서 우수한 성능 결과를 유지한다는 사실을 알게되었습니다.",2024.04.07,Yuxi Ren&&Jie Wu&&Yanzuo Lu&&Huafeng Kuang&&Xin Xia&&Xionghui Wang&&Qianqian Wang&&Yixing Zhu&&Pan Xie&&Shiyin Wang&&Xuefeng Xiao&&Yitong Wang&&Min Zheng&&Lean Fu,arxiv,https://arxiv.org/abs/2404.04860
MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators,"T2V (Text-to-Video Generation)의 최근 발전은 텍스트 설명에서 고품질 일반 비디오를 종합하는 데 놀라운 성공을 거두었습니다.T2V에서 크게 간과 된 문제는 기존 모델이 실제 세계에 대한 물리적 지식을 적절하게 인코딩하지 않았으므로 생성 된 비디오는 움직임이 제한되고 변동이 제한적인 경향이 있다는 것입니다.이 논문에서는 시간 경과 비디오에서 실제 물리 지식을 배우고 변성 생성을 구현하는 변성 시간 경과 비디오 생성 모델 인 \ textbf {Magictime}을 제안합니다.먼저, 공간 및 시간 훈련을 해체하고, 변성 비디오에서 더 많은 물리적 지식을 인코딩하고, 미리 훈련 된 T2V 모델을 변환하여 변성 비디오를 생성하기위한 MagicAdapter 체계를 설계합니다.둘째, 우리는 변형 범위가 더 넓고 극적인 물체 변성 프로세스를 다루는 변성 시간 경과 비디오에 적응하기 위해 동적 프레임 추출 전략을 소개하여 일반 비디오보다 더 많은 물리적 지식을 구현합니다.마지막으로, 우리는 변성 비디오 프롬프트에 대한 이해를 향상시키기 위해 마술 텍스트 인코더를 소개합니다.또한, 우리는 \ textbf {chronomagic}이라는 타임 랩스 비디오 텍스트 데이터 세트를 만듭니다.광범위한 실험은 고품질의 역동적 인 변성 비디오를 생성하기위한 Magictime의 우수성과 효과를 보여줍니다. 시간 경과 비디오 생성은 물리적 세계의 변성 시뮬레이터를 구축하는 유망한 경로임을 시사합니다.",2024.04.07,Shenghai Yuan&&Jinfa Huang&&Yujun Shi&&Yongqi Xu&&Ruijie Zhu&&Bin Lin&&Xinhua Cheng&&Li Yuan&&Jiebo Luo,arxiv,https://arxiv.org/abs/2404.05014
MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation,"이 백서에서는 MOMA를 제시합니다 : 유연한 제로 샷 기능을 자랑하는 개방형 변형, 훈련이없는 개인화 된 이미지 모델을 제시합니다.기초 텍스트-이미지 모델이 빠르게 발전함에 따라 강력한 이미지-이미지 번역에 대한 수요가 증가합니다.이러한 요구를 해결하여 MOMA는 주제 중심의 개인화 된 이미지 생성을 전문으로합니다.Open-Source, Multimodal Lange Language Model (MLLM)을 사용하여 MOMA는 기능 추출기 및 발전기로 이중 역할을 수행하도록 훈련시킵니다.이 접근법은 참조 이미지 및 텍스트 프롬프트 정보를 효과적으로 상승하여 귀중한 이미지 기능을 생성하여 이미지 확산 모델을 용이하게합니다.생성 된 기능을 더 잘 활용하기 위해 이미지 기능을 이미지 확산 모델로 효율적으로 전송하여 생성 된 이미지에서 대상 객체의 유사성을 향상시키는 새로운 자체 변환 단축키 방법을 추가로 소개합니다.놀랍게도, 튜닝이없는 플러그 앤 플레이 모듈로서, 우리의 모델은 단일 참조 이미지 만 필요하며, 세부적인 충실도, 향상된 아이덴티티 보존 및 신실함을 가진 이미지를 생성 할 때 기존 메소드를 능가합니다.우리의 작업은 오픈 소스이므로 이러한 발전에 대한 보편적 인 접근을 제공합니다.",2024.04.08,Kunpeng Song&&Yizhe Zhu&&Bingchen Liu&&Qing Yan&&Ahmed Elgammal&&Xiao Yang,arxiv,https://arxiv.org/abs/2404.05674
SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing,"개인 콘텐츠의 효과적인 편집은 개인이 창의성을 표현하고 시각적 이야기 내에서 사로화하는 이야기를 직조하고 시각적 컨텐츠의 전반적인 품질과 영향을 높이는 데 중추적 인 역할을합니다.따라서이 작업에서 우리는 컨텍스트를 변경하지 않고 참조에 의해 주어진 개인화 된 개념으로 이미지의 객체를 스왑 할 수있는 새로운 프레임 워크 인 Swapanything을 소개합니다.Swapanything은 (1) 주요 주제가 아닌 임의의 대상 및 부품의 정확한 제어, (2) 문맥 픽셀의 더 충실한 보존, (3) 개인화 된 개념의 더 나은 적응이미지에.먼저, 우리는 TARBONTED 변수 교환을 제안합니다. 우리는 충실한 맥락 보존 및 초기 시맨틱 개념 교환을 위해 잠재 기능 맵 및 마스크 된 변수를 스왑 마스크 변수에 대한 지역 제어를 적용하기 위해 대상 변수 스왑을 제안합니다.그런 다음 이미지 생성 프로세스 중에 대상 위치, 모양, 스타일 및 내용 측면에서 시맨틱 개념을 원본 이미지에 원래 이미지로 원래 이미지에 원활하게 조정하여 모양 적응을 도입합니다.인간 및 자동 평가에 대한 광범위한 결과는 개인화 된 스왑에 대한 기준선 방법에 대한 접근 방식의 상당한 개선을 보여줍니다.또한 Swapanything은 단일 객체, 다중 객체, 부분 객체 및 크로스 도메인 교환 작업에서 정확하고 충실한 교환 능력을 보여줍니다.Swapanything은 텍스트 기반 스와핑 및 객체 삽입과 같은 스와핑 이외의 작업에서 큰 성능을 달성합니다.",2024.04.08,Jing Gu&&Yilin Wang&&Nanxuan Zhao&&Wei Xiong&&Qing Liu&&Zhifei Zhang&&He Zhang&&Jianming Zhang&&HyunJoon Jung&&Xin Eric Wang,arxiv,https://arxiv.org/abs/2404.05717
Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs,"멀티 모달 대형 언어 모델 (MLLM)의 최근 발전은 주목할 만하지 않았지만, 이러한 일반 도메인 MLLM은 종종 사용자 인터페이스 (UI) 화면과 효과적으로 이해하고 상호 작용할 수있는 능력이 부족합니다.이 논문에서는 참조, 접지 및 추론 능력이 장착 된 모바일 UI 화면에 대한 이해를 높이기 위해 새로운 MLLM 인 Ferret-UI를 제시합니다.UI 스크린은 일반적으로 더 길쭉한 종횡비를 나타내고 자연 이미지보다 작은 관심 객체 (예 : 아이콘, 텍스트)를 포함한다는 점을 감안할 때, 우리는 흰 족제비 위에 ""모든 해상도""를 통합하여 세부 사항을 확대하고 향상된 시각적 기능을 활용합니다.구체적으로, 각 스크린은 원래 종횡비 (예 : 초상화 스크린의 수평 구분 및 조경 스크린의 수직 분할)를 기반으로 2 개의 하위 이미지로 나뉩니다.두 하위 이미지는 LLM으로 보내기 전에 별도로 인코딩됩니다.우리는 아이콘 인식, 텍스트 찾기 및 위젯 목록과 같은 광범위한 기본 UI 작업에서 교육 샘플을 세 심하게 수집합니다.이 샘플은 정확한 참조 및 접지를 용이하게하기 위해 영역 주석으로 명령을 따르는 것을 위해 형식화됩니다.모델의 추론 능력을 강화하기 위해 자세한 설명, 인식/상호 작용 대화 및 기능 추론을 포함하여 고급 작업을위한 데이터 세트를 추가로 컴파일합니다.선별 된 데이터 세트에 대한 교육 후 Ferret-UI는 UI 화면의 뛰어난 이해력과 개방형 지침을 실행하는 기능을 보여줍니다.모델 평가를 위해, 우리는 위에서 언급 한 모든 작업을 포괄하는 포괄적 인 벤치 마크를 설정합니다.Ferret-UI는 대부분의 오픈 소스 UI MLLM을 넘어선뿐만 아니라 모든 기본 UI 작업에서 GPT-4V를 능가합니다.",2024.04.08,Keen You&&Haotian Zhang&&Eldon Schoop&&Floris Weers&&Amanda Swearngin&&Jeffrey Nichols&&Yinfei Yang&&Zhe Gan,arxiv,https://arxiv.org/abs/2404.05719
YaART: Yet Another ART Rendering Technology,"빠르게 진행되는 생성 모델의 분야에서 효율적이고 고유 한 텍스트-이미지 확산 시스템의 개발은 중요한 프론티어를 나타냅니다.이 연구는 인간 피드백 (RLHF)의 강화 학습을 사용하여 인간 선호도에 정렬 된 새로운 생산 등급 텍스트-이미지 Cascaded 확산 모델 인 Yaart를 소개합니다.Yaart가 개발하는 동안 특히 모델 및 교육 데이터 세트 크기의 선택에 중점을 둡니다. 이전에 텍스트-이미지 계단식 확산 모델에 대해 체계적으로 조사되지 않은 측면.특히, 우리는 이러한 선택이 훈련 프로세스의 효율성과 생성 된 이미지의 품질에 어떤 영향을 미치는지 종합적으로 분석합니다.또한, 우리는 고품질 이미지의 소규모 데이터 세트에 대한 교육을받은 모델이 더 큰 데이터 세트에 대한 교육을받은 모델과 성공적으로 경쟁하여 확산 모델 교육의보다 효율적인 시나리오를 설정할 수 있음을 보여줍니다.품질 관점에서 Yaart는 기존의 많은 최첨단 모델보다 사용자가 지속적으로 선호합니다.",2024.04.08,Sergey Kastryulin&&Artem Konev&&Alexander Shishenya&&Eugene Lyapustin&&Artem Khurshudov&&Alexander Tselousov&&Nikita Vinokurov&&Denis Kuznedelev&&Alexander Markovich&&Grigoriy Livshits&&Alexey Kirillov&&Anastasiia Tabisheva&&Liubov Chubarova&&Marina Kaminskaia&&Alexander Ustyuzhanin&&Artemii Shvetsov&&Daniil Shlenskii&&Valerii Startsev&&Dmitrii Kornilov&&Mikhail Romanov&&Artem Babenko&&Sergei Ovcharenko&&Valentin Khrulkov,arxiv,https://arxiv.org/abs/2404.05666
MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding,"LLM (Large Language Model)의 성공으로 비전 모델을 LLM에 통합하여 Vision-Language Foundation 모델을 구축하는 것이 최근에 훨씬 더 많은 관심을 끌었습니다.그러나 기존의 LLM 기반의 대형 멀티 모드 모델 (예 : 비디오 롤라, 비디오 캣)은 짧은 비디오 이해를 위해 제한된 수의 프레임 만 사용할 수 있습니다.이 연구에서 우리는 주로 장기 비디오 이해를위한 효율적이고 효과적인 모델을 설계하는 데 중점을 둡니다.대부분의 기존 작업과 같이 더 많은 프레임을 동시에 처리하려고 시도하는 대신 온라인 방식으로 비디오를 처리하고 메모리 뱅크에 과거 비디오 정보를 저장할 것을 제안합니다.이를 통해 우리의 모델은 LLMS의 컨텍스트 길이 제약 조건 또는 GPU 메모리 한계를 초과하지 않고 장기 분석을 위해 과거 비디오 컨텐츠를 참조 할 수 있습니다.우리의 메모리 뱅크는 상용으로 현재의 멀티 모달 LLM에 완벽하게 통합 될 수 있습니다.우리는 장기 비디오 이해, 비디오 질문 응답 및 비디오 캡션과 같은 다양한 비디오 이해 작업에 대한 광범위한 실험을 수행하며, 모델은 여러 데이터 세트에서 최첨단 공연을 달성 할 수 있습니다.https url에서 사용 가능한 코드.",2024.04.08,Bo He&&Hengduo Li&&Young Kyun Jang&&Menglin Jia&&Xuefei Cao&&Ashish Shah&&Abhinav Shrivastava&&Ser-Nam Lim,arxiv,https://arxiv.org/abs/2404.05726
UniFL: Improve Stable Diffusion via Unified Feedback Learning,"확산 모델은 이미지 생성 분야에 혁명을 일으켜 고품질 모델의 확산과 다양한 다운 스트림 애플리케이션을 이끌어 냈습니다.그러나 이러한 상당한 발전에도 불구하고 현재 경쟁 솔루션은 여전히 시각적 품질이 열등한, 미적 매력 부족 및 포괄적 인 솔루션없이 비효율적 인 추론을 포함한 몇 가지 한계를 겪고 있습니다.이러한 과제를 해결하기 위해, 우리는 피드백 학습을 활용하여 확산 모델을 포괄적으로 향상시키는 통합 프레임 워크 인 UNIFL을 제시합니다.UNIFL은 SD1.5 및 SDXL과 같은 다양한 확산 모델에 적용 할 수있는 보편적이고 효과적이며 일반화 가능한 솔루션으로 두드러집니다.특히 UNIFL은 세 가지 주요 구성 요소를 통합합니다. 시각적 품질을 향상시키는 지각 피드백 학습;미적 호소력을 향상시키는 분리 된 피드백 학습;그리고 추론 속도를 최적화하는 적대적 피드백 학습.심층 실험과 광범위한 사용자 연구는 생성 된 모델의 품질과 가속도를 모두 향상시키는 제안 된 방법의 우수한 성능을 검증합니다.예를 들어, UNIFL은 생성 품질 측면에서 17%의 사용자 선호도를 능가하고 LCM 및 SDXL Turbo보다 4 단계 추론에서 57% 및 20%를 능가합니다.또한 Lora, Controlnet 및 Animatediff를 포함한 다운 스트림 작업에서 접근 방식의 효능을 확인했습니다.",2024.04.08,Jiacheng Zhang&&Jie Wu&&Yuxi Ren&&Xin Xia&&Huafeng Kuang&&Pan Xie&&Jiashi Li&&Xuefeng Xiao&&Weilin Huang&&Min Zheng&&Lean Fu&&Guanbin Li,arxiv,https://arxiv.org/abs/2404.05595
CodecLM: Aligning Language Models with Tailored Synthetic Data,"명령 튜닝은 LLMS (Lange Language Models)를 특정 작업 명령어와 정렬하는 열쇠로 나타 났으며, 따라서 다음 토닉 예측 목표와 사용자의 실제 목표 사이의 불일치를 완화시킵니다.인간이 데이터를 수집하거나 주석을 달기위한 노동 및 시간 비용을 줄이기 위해 연구원들은 LLM의 사용을 탐색하여 교육 정렬 합성 데이터를 생성하기 시작합니다.최근의 연구는 다양한 지침을 생성하고 LLM을 적용하여 교육 복잡성을 높이고 종종 다운 스트림 사용 사례를 무시하는 데 중점을 둡니다.다른 대상 명령 분포 및 LLM에서 더 나은 명령어를 따르는 능력을 이끌어 내기 위해 고품질 데이터를 조정하는 방법은 확실하지 않습니다.이를 위해, 우리는 다른 다운 스트림 명령 분포 및 LLM과 LLM 정렬에 대한 고품질 합성 데이터를 적응 적으로 생성하기위한 일반적인 프레임 워크 인 CodeClm을 소개합니다.Encode-Decode 원칙을 바탕으로 LLM을 코덱으로 사용하여 데이터 생성 프로세스를 안내합니다.먼저 시드 명령어를 메타 데이터로 인코딩하는데, 이는 대상 명령 분포를 캡처하기 위해 온라인으로 생성 된 간결한 키워드 인 다음 메타 데이터를 디코딩하여 맞춤형 명령어를 작성합니다.또한 데이터 효율적인 샘플을 조정하기 위해 디코딩 중에 자기 흡기와 대조 필터링을 도입합니다.벤치 마크에 따른 4 개의 오픈 도메인 교육에 대한 광범위한 실험은 현재 최첨단 예술가에 대한 CodeClm의 효과를 검증합니다.",2024.04.08,Zifeng Wang&&Chun-Liang Li&&Vincent Perot&&Long T. Le&&Jin Miao&&Zizhao Zhang&&Chen-Yu Lee&&Tomas Pfister,arxiv,https://arxiv.org/abs/2404.05875
SambaLingo: Teaching Large Language Models New Languages,"LLM의 광범위한 가용성에도 불구하고 다양한 언어에 걸쳐 능력과 가용성에 상당한 격차가 남아 있습니다.이러한 문제를 해결하기위한 한 가지 방법은 기존 미리 훈련 된 LLM을 취하고 새로운 언어로 계속 훈련하는 것입니다.이전 작품은 언어 적응을 실험했지만 모범 사례 및 방법론에 관한 많은 질문이 다루어지지 않았습니다.이 논문에서는 LLM을 새로운 언어에 적응시키는 것에 대한 포괄적 인 조사를 제시합니다.우리의 연구는 어휘 확장, 직접 선호도 최적화 및 저주적 언어의 인간 정렬에 대한 데이터 부족 문제를 포함 하여이 프로세스의 주요 구성 요소를 다룹니다.우리는이 실험을 9 개의 언어와 2 개의 매개 변수 척도 (7b 및 70b)에 걸쳐 확장합니다.우리는 우리의 모델을 LLAMA 2, AYA-101, XGLM, Bloom 및 기존 언어 전문가와 비교하여 이전에 게시 된 모든 기준선을 능가합니다.또한 모든 평가 코드 및 체크 포인트는 향후 연구를 촉진하기 위해 공개됩니다.",2024.04.08,Zoltan Csaki&&Bo Li&&Jonathan Li&&Qiantong Xu&&Pian Pawakapan&&Leon Zhang&&Yun Du&&Hengyu Zhao&&Changran Hu&&Urmish Thakker,arxiv,https://arxiv.org/abs/2404.05829
Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence,우리는 RWKV (RWKV-4) 아키텍처에서 개선 된 시퀀스 모델 인 Eagle (RWKV-5) 및 Finch (RWKV-6)를 제시합니다.우리의 건축 설계 발전에는 다중 머리 매트릭스 값 상태와 RNN의 추론 효율 특성을 유지하면서 표현성을 향상시키는 동적 재발 메커니즘이 포함됩니다.우리는 1.12 조 토큰과 강화 된 다국어를위한 탐욕스러운 매칭을 기반으로 한 빠른 토큰 화기를 가진 새로운 다국어 코퍼스를 소개합니다.우리는 0.46 ~ 75 억 파라미터의 4 개의 Eagle 모델과 1.6 및 31 억 매개 변수의 2 개의 Finch 모델을 훈련 시켰으며 다양한 벤치 마크에서 경쟁력있는 성능을 달성한다는 것을 발견했습니다.Apache 2.0 라이센스에 따라 Huggingface의 모든 모델을 출시합니다.모델 :이 https urltraining code at :이 https urlinference 코드 at :이 https urltime-parallel training code at :이 https url,2024.04.08,Bo Peng&&Daniel Goldstein&&Quentin Anthony&&Alon Albalak&&Eric Alcaide&&Stella Biderman&&Eugene Cheah&&Xingjian Du&&Teddy Ferdinan&&Haowen Hou&&Przemysław Kazienko&&Kranthi Kiran GV&&Jan Kocoń&&Bartłomiej Koptyra&&Satyapriya Krishna&&Ronald McClelland Jr.&&Niklas Muennighoff&&Fares Obeid&&Atsushi Saito&&Guangyu Song&&Haoqin Tu&&Stanisław Woźniak&&Ruichong Zhang&&Bingchen Zhao&&Qihang Zhao&&Peng Zhou&&Jian Zhu&&Rui-Jie Zhu,arxiv,https://arxiv.org/abs/2404.05892
WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents,"웹 에이전트 연구 영역에서 일반화와 정확성을 모두 달성하는 것은 여전히 어려운 문제입니다.웹 사이트 구조의 높은 차이로 인해 기존 접근법이 종종 실패합니다.또한 기존의 미세 조정 및 텍스트 내 학습 기술은 여러 웹 사이트에서 일반화되지 않습니다.우리는 Wilbur를 소개합니다. Wilbur는 차별화 가능한 순위 모델과 새로운 명령 합성 기술을 사용하여 이전 실행의 작업 데모와 함께 블랙 박스 대형 언어 모델의 프롬프트를 최적으로 채우는 접근 방식을 소개합니다.엔드 투 엔드 성공률을 극대화하기 위해 실수를 배우고 회복하는 지능형 역 추적 메커니즘도 제안합니다.마지막으로, 우리는 순위 모델이 LLM의 대표적 목표를 샘플링하고 에이전트를 실행하고 수동 주석이 없어서 자동으로 평가하는 생성 자동 교과 과정의 데이터에 대해 교육을받을 수 있음을 보여줍니다.Wilbur는 WebVoyager 벤치 마크에서 최첨단 결과를 달성하여 텍스트 전용 모델을 전체 8%, 특정 웹 사이트에서 최대 36%를 꺾었습니다.동일한 벤치 마크에서 Wilbur는 텍스트 입력 만 수신 되었음에도 불구하고 강력한 멀티 모달 모델의 5% 이내에 있으며, 추가 분석에 따르면 상당수의 실패는 웹 작동의 엔지니어링 문제로 인한 것입니다.",2024.04.08,Michael Lutz&&Arth Bohra&&Manvel Saroyan&&Artem Harutyunyan&&Giovanni Campagna,arxiv,https://arxiv.org/abs/2404.05902
Hash3D: Training-free Acceleration for 3D Generation,"3D 생성 모델링의 진화는 2D 확산 모델의 채택에 의해 현저히 추진되어왔다.이러한 진보에도 불구하고, 성가신 최적화 프로세스 자체는 효율성에 중요한 장애물을 나타냅니다.이 논문에서는 모델 교육없이 3D 세대를위한 범용 가속 인 Hash3d를 소개합니다.HASH3D의 중심은 카메라 위치에서 렌더링 된 이미지와 근접성에서 확산 시간 단계에서 피처 맵 중복성이 널리 퍼져 있다는 통찰력입니다.주변 타임 스펙 및 카메라 각도에서 이러한 기능 맵을 효과적으로 해시하고 재사용함으로써 Hash3D는 중복 계산을 실질적으로 방지하여 3D 세대 작업에서 확산 모델의 추론을 가속화합니다.우리는 적응 형 그리드 기반 해싱을 통해이를 달성합니다.놀랍게도,이 기능 공유 메커니즘은 생성 속도를 높일뿐만 아니라 합성 된 3D 객체의 부드러운 일관성을 향상시키고 일관성을 강화합니다.5 개의 텍스트-3D 및 3 개의 이미지-3D 모델을 다루는 실험은 최적화 속도를 높이고 효율성을 1.3 ~ 4 배 향상시키는 HASH3D의 다목적 성을 보여줍니다.또한 HASH3D와 3D 가우시안 플래팅과의 통합은 3D 모델 생성 속도를 높이고 텍스트-3D 처리를 약 10 분으로 줄이고 이미지-3D 변환을 약 30 초로 줄입니다.프로젝트 페이지는이 https url입니다.",2024.04.09,Xingyi Yang&&Xinchao Wang,arxiv,https://arxiv.org/abs/2404.06091
MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies,"최대 10 조의 매개 변수로 대형 언어 모델 (LLM) 개발에 대한 급격한 관심은 자원 효율성과 실질 비용에 관한 우려와 관련이 있습니다.이 시나리오는 소규모 언어 모델 (SLMS)의 잠재력을 자원 효율적인 대안으로 탐색하는 것의 중요성을 강조합니다.이러한 맥락에서, 우리는 MINICPM, 특히 1.2B 및 2.4B 비 에비 딩 매개 변수 변형을 소개하며, 각 범주에서 탁월 할뿐만 아니라 7B-13B LLMS와 동등한 기능을 보여줍니다.SLM에 중점을 두면서 우리의 접근 방식은 미래의 LLM 연구를위한 모델 및 데이터 차원 모두에서 확장 성을 나타냅니다.모델 스케일링과 관련하여, 우리는 안정적이고 최적의 스케일링을 위해 광범위한 모델 풍동 실험을 사용합니다.데이터 스케일링의 경우, 지속적인 교육 및 도메인 적응에 도움이되는 WARMUP-STABLE-DECAY (WSD) 학습 속도 스케줄러 (LRS)를 소개합니다.우리는 WSD LRS에서 발생한 흥미로운 훈련 역학에 대한 심층 분석을 제시합니다.WSD LRS를 사용하면 모델과 데이터 축에 대한 광범위한 재교육 실험없이 데이터 모델 스케일링 법을 효율적으로 연구 할 수 있습니다. 여기서 Chinchilla 최적보다 훨씬 높은 컴퓨팅 최적의 데이터 모델 비율을 도출합니다.또한, 우리는 MINICPM-DPO, MINICPM-MOE 및 MINICPM-128K를 포함한 MINICPM 패밀리를 소개합니다.MinICPM 모델은 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.09,Shengding Hu&&Yuge Tu&&Xu Han&&Chaoqun He&&Ganqu Cui&&Xiang Long&&Zhi Zheng&&Yewei Fang&&Yuxiang Huang&&Weilin Zhao&&Xinrong Zhang&&Zheng Leng Thai&&Kaihuo Zhang&&Chongyi Wang&&Yuan Yao&&Chenyang Zhao&&Jie Zhou&&Jie Cai&&Zhongwu Zhai&&Ning Ding&&Chao Jia&&Guoyang Zeng&&Dahai Li&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.06395
Reconstructing Hand-Held Objects in 3D,"손에 의해 조작 된 물체 (즉, Manipulanda)는 특히 야생 RGB 이미지 나 비디오에서 재구성하기가 어렵습니다.손은 객체의 대부분을 막을뿐만 아니라 물체는 종종 소수의 이미지 픽셀에서만 볼 수 있습니다.동시에이 설정에서 두 개의 강한 앵커가 나타납니다. (1) 3D 손이 물체의 위치와 스케일을 명확하게하는 데 도움이되며 (2) Manipulanda 세트는 가능한 모든 물체에 비해 작습니다.이러한 통찰력을 염두에두고, 우리는 큰 언어/비전 모델 및 3D 객체 데이터 세트의 최근 혁신을 바탕으로 핸드 헬드 객체 재구성을위한 확장 가능한 패러다임을 제시합니다.우리의 모델 MCC-Hand-Bobject (MCC-HO)는 단일 RGB 이미지와 3D 핸드를 입력으로 유추하여 손과 물체 구조를 공동으로 재구성합니다.그 후, 우리는 GPT-4 (v)를 사용하여 이미지의 객체와 일치하는 3D 객체 모델을 검색하고 모델을 네트워크에 인출 된 지오메트리에 엄격하게 정렬합니다.우리는이 정렬 검색 재구성 재구성 (RAR)이라고합니다.실험에 따르면 MCC-HO는 실험실 및 인터넷 데이터 세트에서 최첨단 성능을 달성하고 RAR을 사용하여 손으로 객체 상호 작용의 야만적 인 이미지에 대한 3D 레이블을 자동으로 얻는 방법을 보여줍니다.",2024.04.09,Jane Wu&&Georgios Pavlakos&&Georgia Gkioxari&&Jitendra Malik,arxiv,https://arxiv.org/abs/2404.06507
MuPT: A Generative Symbolic Music Pretrained Transformer,"이 논문에서는 음악의 사전 훈련에 대형 언어 모델 (LLM)의 적용을 탐구합니다.음악 모델링에서 MIDI의 일반적인 사용은 잘 확립되어 있지만, 우리의 연구 결과는 LLM이 본질적으로 ABC 표기법과 더 호환되며, 이는 디자인 및 강점과 더 밀접하게 일치하여 음악 구성에서 모델의 성능을 향상시킵니다.세대 동안 다른 트랙의 잘못 정렬 된 측정과 관련된 과제를 해결하기 위해 여러 음악적 트랙에서 일관성을 보존하는 것을 목표로하는 동기화 된 멀티 트랙 ABC 표기법 (SMT-ABC 표기법)의 개발을 제안합니다.우리의 기여에는 최대 8192 개의 토큰을 처리 할 수있는 일련의 모델이 포함되어 있으며 교육 세트에서 상징적 인 음악 데이터의 90%를 차지합니다.또한, 우리는 모델 성능에 대한 상징적 음악 스케일링 법 (SMS Law)의 의미를 탐구합니다.결과는 음악 생성에 대한 미래의 연구를위한 유망한 방향을 나타냅니다. 공개 소스 기여를 통해 커뮤니티 주도 연구를위한 광범위한 자원을 제공합니다.",2024.04.09,Xingwei Qu&&Yuelin Bai&&Yinghao Ma&&Ziya Zhou&&Ka Man Lo&&Jiaheng Liu&&Ruibin Yuan&&Lejun Min&&Xueling Liu&&Tianyu Zhang&&Xinrun Du&&Shuyue Guo&&Yiming Liang&&Yizhi Li&&Shangda Wu&&Junting Zhou&&Tianyu Zheng&&Ziyang Ma&&Fengze Han&&Wei Xue&&Gus Xia&&Emmanouil Benetos&&Xiang Yue&&Chenghua Lin&&Xu Tan&&Stephen W. Huang&&Wenhu Chen&&Jie Fu&&Ge Zhang,arxiv,https://arxiv.org/abs/2404.06393
InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD,"LVLM (Large Vision-Language Model) 분야는 상당한 발전을 보였지만 제한된 해상도로 인해 세밀한 시각적 컨텐츠를 이해하는 데 어려움을 겪었습니다.최근의 노력은 LVLM의 고해상도 이해 기능을 향상시키기위한 노력을 기울 였지만 약 1500 x 1500 픽셀에 캡핑되어 상대적으로 좁은 해상도 범위로 제한됩니다.이 논문은 최대 4K HD (3840 x 1600) 이상의 LVLM 해상도 기능을 높이기위한 획기적인 탐사 인 Internlm-Xcomposer2-4KHD를 나타냅니다.동시에 모든 시나리오에서 초고 해상도가 필요하지 않을 수 있다는 점을 고려할 때 336 픽셀에서 4K 표준까지 다양한 해상도를 지원하여 적용 범위를 크게 확장시킵니다.구체적으로,이 연구는 자동 패치 구성을 통한 새로운 확장 : 동적 해상도를 도입하여 패치 디비전 패러다임을 발전시킵니다.훈련 이미지 종횡비를 유지하는 반면, 패치 카운트가 자동으로 변경되고 미리 훈련 된 비전 변압기 (VIT) (336 x 336)를 기반으로 레이아웃을 구성하여 336 픽셀에서 4K 표준으로 동적 훈련 해상도를 초래합니다.우리의 연구는 최대 4K HD까지 훈련 해상도를 스케일링하면 잠재적 인 개선의 천장에 도달하지 않고 일관된 성능 향상으로 이어집니다.Internlm-Xcomposer2-4KHD는 16 개의 벤치 마크 중 10 개에서 GPT-4V 및 Gemini Pro와 일치하거나 능가하는 훌륭한 기능을 보여줍니다.7B 매개 변수가있는 Internlm-Xcomposer2-4KHD 모델 시리즈는 HTTPS URL에서 공개적으로 사용할 수 있습니다.",2024.04.09,Xiaoyi Dong&&Pan Zhang&&Yuhang Zang&&Yuhang Cao&&Bin Wang&&Linke Ouyang&&Songyang Zhang&&Haodong Duan&&Wenwei Zhang&&Yining Li&&Hang Yan&&Yang Gao&&Zhe Chen&&Xinyue Zhang&&Wei Li&&Jingwen Li&&Wenhai Wang&&Kai Chen&&Conghui He&&Xingcheng Zhang&&Jifeng Dai&&Yu Qiao&&Dahua Lin&&Jiaqi Wang,arxiv,https://arxiv.org/abs/2404.06512
LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders,"LLM (Large Decoder 전용 언어 모델)은 오늘날의 NLP 작업 및 벤치 마크의 대부분의 최신 모델입니다.그러나 커뮤니티는 텍스트 임베딩 작업을 위해 이러한 모델을 천천히 채택하고 있으며, 이는 풍부한 상황에 맞는 표현이 필요합니다.이 작업에서는 디코더 전용 LLM을 강력한 텍스트 인코더로 변환 할 수있는 단순한 감독 접근법 인 LLM2VEC를 소개합니다.LLM2VEC는 세 가지 간단한 단계로 구성됩니다. 1) 양방향주의 가능성, 2) 다음 토큰 예측, 3) 감독되지 않은 대조 학습.우리는 1.3b ~ 7b 매개 변수 범위의 3 가지 인기있는 LLM에 적용하여 LLM2VEC의 효과를 보여주고 영어 단어 및 시퀀스 수준 작업에서 변환 된 모델을 평가합니다.우리는 단어 수준 작업에 큰 마진으로 인코더 전용 모델을 능가하고 대규모 텍스트 임베드 벤치 마크 (MTEB)에서 감독되지 않은 최신 성능에 도달합니다.또한, LLM2VEC와 감독 된 대조 학습을 결합 할 때, 우리는 공개적으로 이용 가능한 데이터 만 훈련하는 모델 중에서 MTEB에 대한 최첨단 성과를 달성합니다.우리의 강력한 경험적 결과와 광범위한 분석은 값 비싼 적응 또는 합성 GPT-4 생성 데이터의 필요없이 LLM이 매개 변수 효율적인 방식으로 범용 텍스트 인코더로 효과적으로 변환 될 수 있음을 보여줍니다.",2024.04.09,Parishad BehnamGhader&&Vaibhav Adlakha&&Marius Mosbach&&Dzmitry Bahdanau&&Nicolas Chapados&&Siva Reddy,arxiv,https://arxiv.org/abs/2404.05961
OmniFusion Technical Report,"작년에 멀티 모달 아키텍처는 AI 기반 접근 방식 및 솔루션에서 혁명을 일으켜 LLM (Lange Language Models)의 기능을 확장했습니다.시각적 양식을위한 사전 간 LLM과 어댑터를 기반으로 \ textit {omnifusion} 모델을 제안합니다.우리는 더 나은 텍스트 및 시각적 데이터 커플 링 (MLP 및 변압기 어댑터), 다양한 클립 VIT 기반 인코더 (SIGLIP, InternVit 등) 및 퓨즈 접근 방식, 이미지 인코딩 방법 (전체 이미지 또는 타일 인코딩) 및 2 개의 7B LLM (독점 및 오픈 소스 미스트랄).8 개의 시각적 언어 벤치 마크에 대한 실험은 Open-Source Llava와 같은 솔루션과 비교하여 다양한 VQA 작업과 관련하여 최고의 전능 설정 설정의 최고 점수를 보여줍니다 : Vizwiz, Pope, MM-Vet, Scienceqa, Mmbench, TextVQA, VQAV2, MMMU.또한 Omnifusion은 가정용, 관광, 문화, 의약품, 필기 및 스캔 방정식 인식 등 다양한 영역에서 고도로 분해 된 답변을 제공하는 다양한 상황을 제안합니다. Mistral 기반의 전능 행사 모델은 가중치, 교육을 가진 오픈 소스 솔루션입니다.이 HTTPS URL에서 사용 가능한 추론 스크립트.",2024.04.09,Elizaveta Goncharova&&Anton Razzhigaev&&Matvey Mikhalchuk&&Maxim Kurkin&&Irina Abdullaeva&&Matvey Skripkin&&Ivan Oseledets&&Denis Dimitrov&&Andrey Kuznetsov,arxiv,https://arxiv.org/abs/2404.06212
Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion,"2D 확산 모델의 빠른 발전으로 인해 3D 컨텐츠 제작은 최근 상당한 진전을 이루었습니다.유망한 솔루션 중 하나는 미리 훈련 된 2D 확산 모델의 미세 조정을 포함하여 멀티 뷰 이미지를 생성하기위한 용량을 활용하며, 이는 Fast-Nerfs 또는 대규모 재구성 모델과 같은 방법을 통해 정확한 3D 모델로 들어 올립니다.그러나 불일치가 여전히 존재하고 생성 된 해상도가 제한되어 있기 때문에 이러한 방법의 생성 결과는 여전히 복잡한 질감과 복잡한 형상이 부족합니다.이 문제를 해결하기 위해 간단한 SDS 최적화 (\ sim15min)를 통해 거친 생성 결과를 크게 개선하는 멀티 뷰 조절 확산 모델 인 Magic-Boost를 제안합니다.이전 텍스트 또는 단일 이미지 기반 확산 모델과 비교하여 Magic-Boost는 의사 합성 다중 뷰 이미지로부터 높은 일관성을 가진 이미지를 생성 할 수있는 강력한 기능을 보여줍니다.입력 이미지의 ID와 잘 맞는 정확한 SDS 지침을 제공하여 초기 생성 결과의 형상 및 질감 모두에서 로컬 세부 사항을 풍부하게합니다.광범위한 실험에 따르면 Magic-Boost는 거친 입력을 크게 향상시키고 풍부한 기하학적 및 조직적 세부 사항을 가진 고품질 3D 자산을 생성합니다.(프로젝트 페이지 :이 https url)",2024.04.09,Fan Yang&&Jianfeng Zhang&&Yichun Shi&&Bowen Chen&&Chenxu Zhang&&Huichao Zhang&&Xiaofeng Yang&&Jiashi Feng&&Guosheng Lin,arxiv,https://arxiv.org/abs/2404.06429
Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models,"많은 사람들이 다양한 작업 세트에 LLM (Lange Language Model)을 적용 할 수있는 방법을 보여 주었지만 데이터 오염 및 암기의 중요한 문제는 종종 광택이 발생합니다.이 작업에서 우리는 표식 데이터에 대한이 문제를 해결합니다.구체적으로, 우리는 언어 모델이 훈련 중에 표 데이터 세트를 보았는지 여부를 평가하기 위해 다양한 다양한 기술을 소개합니다.이 조사에 따르면 LLM은 많은 대중적인 표준 데이터 세트가 구두로 암기했음을 보여줍니다.그런 다음 훈련 중에 보이는 데이터 세트에서 LLM의 소수의 학습 성능을 교육 후 출시 된 데이터 세트의 성능에 비교합니다.우리는 훈련 중에 보이는 데이터 세트에서 LLM이 더 잘 수행되며, 이는 암기가 과결을 일으킨다는 것을 나타냅니다.동시에 LLM은 새로운 데이터 세트에서 사소한 성능을 보여 주며 놀랍게도 데이터 변환에 강력합니다.그런 다음 LLM의 텍스트 내 통계 학습 능력을 조사합니다.미세 조정 없이는 제한적이라고 생각합니다.이것은 새로운 데이터 세트에서 소수의 성능이 LLM의 세계 지식 때문이라는 것을 시사합니다.전반적으로, 우리의 결과는 LLM이 사전 훈련 중에 평가 데이터 세트를 보았는지 여부를 테스트하는 것의 중요성을 강조합니다.우리는 우리가 개발 한 노출 테스트를 https url에서 tabmemcheck python 패키지로 사용할 수 있도록합니다.",2024.04.09,Sebastian Bordt&&Harsha Nori&&Vanessa Rodrigues&&Besmira Nushi&&Rich Caruana,arxiv,https://arxiv.org/abs/2404.06209
Revising Densification in Gaussian Splatting,"이 논문에서, 우리는 3D 가우시안 스플릿 (3DG)에서 적응 밀도 제어 (ADC)의 한계를 다룬다.ADC는 자동 3D 포인트 원시 관리, 밀도 화 및 가지 치열 제어를 위해 도입되었지만 밀도 로직의 특정 제한 사항이 있습니다.우리의 주요 기여는 3DG의 밀도 제어를위한보다 원칙적인 픽셀-오류 구동 공식화이며, 픽셀 당 오차 기능을 밀도의 기준으로 활용합니다.또한 장면 당 생성 된 총 프리미티브 수를 제어하는 메커니즘을 도입하고 클로닝 작업 중에 ADC의 현재 불투명도 처리 전략에서 편향을 수정합니다.우리의 접근 방식은 방법의 효율성을 희생하지 않고 다양한 벤치 마크 장면에서 일관된 품질 향상으로 이어집니다.",2024.04.09,Samuel Rota Bulò&&Lorenzo Porzi&&Peter Kontschieder,arxiv,https://arxiv.org/abs/2404.06109
RULER: What's the Real Context Size of Your Long-Context Language Models?,"긴 산만 텍스트 ( ""Haystack"")에서 정보 ( ""바늘"")를 검색하는 능력을 조사하는 Beless-in-A-Haystack (NIAH) 테스트는 장거리 텍스트 언어를 평가하기 위해 널리 채택되었습니다.모델 (LMS).그러나이 간단한 검색 기반 테스트는 피상적 인 형태의 장기 텍스트 이해만을 나타냅니다.장기 텍스트 LMS에 대한보다 포괄적 인 평가를 제공하기 위해 맞춤형 시퀀스 길이 및 작업 복잡성을위한 유연한 구성을 가진 새로운 합성 벤치 마크 규칙을 만듭니다.통치자는 바닐라 Niah 테스트를 확장하여 다양한 유형과 양의 바늘을 가진 변형을 포함합니다.또한 Ruler는 컨텍스트에서 검색을 넘어서 행동을 테스트하기 위해 새로운 작업 카테고리 멀티 홉 추적 및 집계를 소개합니다.우리는 통치자에 13 개의 대표적인 작업이있는 10 개의 장거리 LM을 평가합니다.바닐라 NIAH 테스트에서 거의 완벽한 정확도를 달성하더라도 모든 모델은 컨텍스트 길이가 증가함에 따라 큰 성능 감소를 나타냅니다.이 모델들은 모두 32k 토큰 이상의 컨텍스트 크기를 주장하지만 4 개의 모델 (GPT-4, Command-R, Yi-34B 및 Mixtral) 만 32k 길이의 만족스러운 성능을 유지할 수 있습니다.컨텍스트 길이 200k를 지원하는 Yi-34B에 대한 우리의 분석은 입력 길이와 작업 복잡성을 증가시킬 때 개선의 넓은 공간을 보여줍니다.우리는 오픈 소스 통치자가 장기 텍스트 LMS의 포괄적 인 평가를 박차 를가합니다.",2024.04.09,Cheng-Ping Hsieh&&Simeng Sun&&Samuel Kriman&&Shantanu Acharya&&Dima Rekesh&&Fei Jia&&Yang Zhang&&Boris Ginsburg,arxiv,https://arxiv.org/abs/2404.06654
Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior,"Text-to-3D Generation은 대규모 텍스트-이미지 확산 모델을 통해 놀라운 성공을 거두었습니다.그럼에도 불구하고, 방법론을 도시 규모로 확장하는 패러다임은 없습니다.수많은 요소, 복잡한 배열 관계 및 광대 한 규모로 특징 지어진 도시 장면은 효과적인 모델 최적화를위한 모호한 텍스트 설명의 해석 가능성에 대한 강력한 장벽을 제시합니다.이 작업에서, 우리는 추가 사전으로 작용하여 작곡 3D 레이아웃 표현을 텍스트-3D 패러다임에 도입하여 한계를 극복합니다.그것은 단순한 기하학적 구조와 명백한 배열 관계를 갖는 의미 론적 프리미티브 세트로 구성되어 텍스트 설명을 보완하고 조향 가능한 생성을 가능하게합니다.이에 따라, 우리는 두 가지 수정을 제안합니다. (1) 모델 최적화 부적합을 해결하기 위해 레이아웃 유도 변형 점수 증류를 도입합니다.3D 레이아웃의 기하학적 및 시맨틱 제약 조건으로 점수 증류 샘플링 프로세스를 조정합니다.(2) 도시 장면의 무한한 특성을 처리하기 위해, 우리는 확장 가능한 해시 그리드 구조로 3D 장면을 나타내며, 도시 장면의 규모가 점점 점진적으로 적응됩니다.광범위한 실험은 우리의 프레임 워크가 처음으로 1000m 이상의 운전 거리를 차지하는 대규모 도시 장면으로 텍스트-3D 세대를 확장하는 프레임 워크의 기능을 입증합니다.우리는 또한 다양한 장면 편집 데모를 제시하여 조향 가능한 도시 장면 생성의 힘을 보여줍니다.웹 사이트 :이 https url.",2024.04.10,Fan Lu&&Kwan-Yee Lin&&Yan Xu&&Hongsheng Li&&Guang Chen&&Changjun Jiang,arxiv,https://arxiv.org/abs/2404.06780
Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention,"이 작업은 트랜스포머 기반 대형 언어 모델 (LLM)을 제한된 메모리 및 계산으로 무한대 입력으로 확장하는 효율적인 방법을 도입합니다.제안 된 접근 방식의 핵심 요소는 인피니트 (Infini-Attention)라는 새로운주의 기술입니다.Infini-Intention은 압축 메모리를 바닐라주의 메커니즘에 통합하고 단일 변압기 블록에서 마스크 된 로컬주의 및 장기 선형주의 메커니즘을 모두 구축합니다.우리는 장거리 텍스트 언어 모델링 벤치 마크, 1M 시퀀스 길이 패스 키 컨텍스트 블록 검색 및 1B 및 8B LLM을 갖춘 500K 길이의 책 요약 작업에 대한 접근 방식의 효과를 보여줍니다.우리의 접근 방식은 최소한의 경계 메모리 매개 변수를 소개하고 LLM에 대한 빠른 스트리밍 추론을 가능하게합니다.",2024.04.10,Tsendsuren Munkhdalai&&Manaal Faruqui&&Siddharth Gopal,arxiv,https://arxiv.org/abs/2404.07143
RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion,"우리는 텍스트 설명에서 일반적인 전진 3D 장면을 생성하는 기술인 Realmdreamer를 소개합니다.우리의 기술은 복잡한 텍스트 프롬프트와 일치하도록 3D 가우시안 플래팅 표현을 최적화합니다.최첨단 텍스트-이미지 생성기를 사용하여 샘플을 3D로 들어 올리고 폐색 볼륨을 계산하여 이러한 Splats를 초기화합니다.그런 다음 이미지 조건 확산 모델을 사용한 3D 인 페인팅 작업으로 여러 뷰 에서이 표현을 최적화합니다.올바른 기하학적 구조를 배우기 위해, 우리는 인화 모델의 샘플에 컨디셔닝하여 깊이 확산 모델을 통합하여 풍부한 기하학적 구조를 제공합니다.마지막으로, 이미지 생성기의 날카로운 샘플을 사용하여 모델을 정합합니다.특히, 우리의 기술은 비디오 또는 멀티 뷰 데이터가 필요하지 않으며 여러 객체로 구성된 다양한 스타일의 다양한 고품질 3D 장면을 종합 할 수 있습니다.일반성은 추가로 단일 이미지에서 3D 합성을 허용합니다.",2024.04.10,Jaidev Shriram&&Alex Trevithick&&Lingjie Liu&&Ravi Ramamoorthi,arxiv,https://arxiv.org/abs/2404.07199
BRAVE: Broadening the visual encoding of vision-language models,"VLM (Vision-Language Models)은 일반적으로 비전 인코더로 구성됩니다 (예 :클립 및 인코딩 된 기능을 해석하여 다운 스트림 작업을 해결하는 언어 모델 (LM).놀라운 진보에도 불구하고 VLM은 비전 인코더의 제한된 기능으로 인해 몇 가지 단점이 있습니다 (예 :특정 이미지 기능, 시각적 환각 등에 대한 ""실명"". 이러한 문제를 해결하기 위해 VLM의 시각적 인코딩 기능을 넓히는 것을 연구합니다.우리는 먼저 VLM 작업을 해결하기 위해 다른 유도 편향을 가진 여러 비전 인코더를 포괄적으로 벤치마킹합니다.우리는 다른 작업에서 일관되게 최고의 성능을 달성하는 단일 인코딩 구성이 없으며, 다른 바이어스를 가진 인코더는 놀랍게도 유사하게 수행 할 수 있음을 관찰합니다.이에 의해 동기를 부여하면서, 우리는 Brave라는 이름의 방법을 소개하여 여러 냉동 인코더의 기능을 냉동 LM에 입력으로 직접 공급할 수있는보다 다재다능한 표현으로 통합됩니다.Brave는 광범위한 캡션 및 VQA 벤치 마크에서 최첨단 성능을 달성하고 위에서 언급 한 VLM의 문제를 크게 줄이며 기존 방법보다 더 적은 수의 훈련 가능한 매개 변수를 요구하고보다 압축 된 표현을 갖습니다.우리의 결과는 VLM에 대한보다 광범위하고 상황에 맞는 시각적 이해를 위해 다른 시각적 편향을 통합 할 수있는 잠재력을 강조합니다.",2024.04.10,Oğuzhan Fatih Kar&&Alessio Tonioni&&Petra Poklukar&&Achin Kulshrestha&&Amir Zamir&&Federico Tombari,arxiv,https://arxiv.org/abs/2404.07204
Adapting LLaMA Decoder to Vision Transformer,"이 연구는 원래 LLM (Lange Language Models) 용으로 설계된 LLAMA와 같은 디코더 전용 변압기가 컴퓨터 비전 분야에 적응할 수 있는지 여부를 조사합니다.우리는 먼저 Llama의 건축과 일치하는 표준 VIT 단계별 단계별 ""Llamafy""를 ""llamafy""하고, 자체 소지에 캐주얼 마스크를 직접 적용하면주의 붕괴 문제가 발생하여 네트워크 교육에 실패합니다.우리는이 도전을 극복하기 위해 시퀀스 후 클래스 토큰 기술로 이미지 토큰 뒤에있는 클래스 토큰을 재배치하여 인과 적자 변환이 전체 이미지의 정보를 효율적으로 캡처 할 수 있도록하는 것이 좋습니다.또한, 우리는 최적화 동작을 촉진하기 위해 훈련을 시작할 때 자체 변환에 대한 캐주얼 마스크를 점차적으로 도입하는 소프트 마스크 전략을 개발합니다.Image Llama (Illama)로 불리는 맞춤형 모델은 건축의 라마와 유사하며 직접적인 감독 학습을 가능하게합니다.인과 적자 변환은 계산 효율성을 높이고주의지도 순위를 높여 복잡한 표현을 배웁니다.Illama는 인코더 전용 대응 자로 성능을 발휘하여 5.7m 매개 변수로 75.1% Imagenet Top-1 정확도를 달성합니다.모델을 ~ 310m로 확장하고 ImageNet-21K에서 사전 훈련하면 정확도가 86.0%로 향상됩니다.광범위한 실험은 캘리브레이션, 모양-텍스처 바이어스, 양자화 호환성, ADE20K 세분화 및 CIFAR 전송 학습과 같은 Illama의 신뢰할 수있는 특성을 보여줍니다.우리는 우리의 연구가 LLM의 물결에서 시각적 모델 디자인에 대한 새로운 견해를 만들 수 있기를 바랍니다.미리 훈련 된 모델과 코드는 여기에서 제공됩니다.",2024.04.10,Jiahao Wang&&Wenqi Shao&&Mengzhao Chen&&Chengyue Wu&&Yong Liu&&Kaipeng Zhang&&Songyang Zhang&&Kai Chen&&Ping Luo,arxiv,https://arxiv.org/abs/2404.06773
DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting,"가상 현실 애플리케이션에 대한 수요가 증가함에 따라 몰입 형 3D 자산을 제작하는 것의 중요성을 강조했습니다.우리는 몇 분 안에 야만적 인 환경을위한 포괄적 인 360^{\ circ} 장면의 생성을 용이하게하는 텍스트-3d 360^{\ circ} 장면 생성 파이프 라인을 제시합니다.우리의 접근 방식은 2D 확산 모델의 생성력을 활용하고 자체 반영을 자극하여 고품질의 전 세계적으로 일관된 파노라마 이미지를 만듭니다.이 이미지는 예비 ""플랫""(2d) 장면 표현 역할을합니다.그 후, 그것은 실시간 탐색을 가능하게하기 위해 3D 가우시안으로 들어 올려 진 3D 가우시안으로 들어 올려집니다.일관된 3D 지오메트리를 생성하기 위해, 파이프 라인은 2D 단안 깊이를 전 세계적으로 최적화 된 포인트 클라우드에 정렬하여 공간적으로 일관된 구조를 구성합니다.이 지점 클라우드는 3D 가우스의 중심의 초기 상태 역할을합니다.단일 뷰 입력에 내재 된 보이지 않는 문제를 해결하기 위해 정규화로 합성 및 입력 카메라보기에 시맨틱 및 기하학적 제약을 부과합니다.이들은 가우시안의 최적화를 안내하며 보이지 않는 지역의 재건을 돕습니다.요약하면, 우리의 방법은 360^{\ circ} 관점 내에서 전 세계적으로 일관된 3D 장면을 제공하여 기존 기술에 비해 강화 된 몰입 형 경험을 제공합니다.프로젝트 웹 사이트 :이 HTTP URL",2024.04.10,Shijie Zhou&&Zhiwen Fan&&Dejia Xu&&Haoran Chang&&Pradyumna Chari&&Tejas Bharadwaj&&Suya You&&Zhangyang Wang&&Achuta Kadambi,arxiv,https://arxiv.org/abs/2404.06903
ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback,"텍스트-이미지 확산 모델의 제어 가능성을 향상시키기 위해 Controlnet과 같은 기존의 노력은 이미지 기반 조건부 제어를 통합합니다.이 논문에서는 기존 방법이 이미지 조건부 컨트롤과 일치하는 이미지를 생성하는 데 여전히 중요한 도전에 직면한다는 것을 보여줍니다.이를 위해 생성 된 이미지와 조건부 컨트롤 사이의 픽셀 레벨 사이클 일관성을 명시 적으로 최적화하여 제어 가능한 생성을 향상시키는 새로운 접근법 인 Controlnet ++를 제안합니다.구체적으로, 입력 조건부 제어의 경우, 미리 훈련 된 판별 보상 모델을 사용하여 생성 된 이미지의 해당 조건을 추출한 다음 입력 조건부 제어 및 추출 된 조건 사이의 일관성 손실을 최적화합니다.간단한 구현은 임의의 소음에서 이미지를 생성 한 다음 일관성 손실을 계산하는 것이지만, 이러한 접근 방식은 여러 샘플링 타임 스텝에 대한 그라디언트를 저장해야하므로 상당한 시간과 메모리 비용이 발생합니다.이를 해결하기 위해 노이즈를 추가하여 입력 이미지를 의도적으로 방해하는 효율적인 보상 전략을 소개 한 다음 보상 미세 조정을 위해 단일 단계 거부 이미지를 사용합니다.이는 이미지 샘플링과 관련된 광범위한 비용을 피하여보다 효율적인 보상 미세 조정을 허용합니다.광범위한 실험에 따르면 Controlnet ++는 다양한 조건부 제어 하에서 제어 성을 크게 향상시킨다.예를 들어 세분화 마스크, 라인 아트 모서리 및 깊이 조건에 대해 각각 7.9% MIOU, 13.4% SSIM 및 7.6% RMSE의 ControlNet보다 개선을 달성합니다.",2024.04.11,Ming Li&&Taojiannan Yang&&Huafeng Kuang&&Jie Wu&&Zhaoning Wang&&Xuefeng Xiao&&Chen Chen,arxiv,https://arxiv.org/abs/2404.07987
JetMoE: Reaching Llama2 Performance with 0.1M Dollars,"LLM (Lange Language Models)은 놀라운 결과를 얻었지만, 그들의 자원 수요가 증가하는 것은 강력하고 접근 가능한 초인간 지능의 개발에 중요한 장애물이되었습니다.이 보고서는 신중하게 혼합 된 오픈 소스 코퍼라와 30,000 H100 GPU 시간의 1.25T 토큰을 사용하여 0.1 백만 달러 미만의 새로운 LLM 인 Jetmoe-8B를 소개합니다.저렴한 비용에도 불구하고 Jetmoe-8B는 LLAMA2-7B 모델과 Jetmoe-8B-Chat가 LLAMA2-13B-CHAT 모델을 능가하는 인상적인 성능을 보여줍니다.이러한 결과는 LLM 교육이 일반적으로 생각하는 것보다 훨씬 비용 효율적 일 수 있음을 시사합니다.Jetmoe-8B는 주의력과 피드 포워드 전문가로 구성된 효율적인 드물게 게이팅 된 SMOE (Smoe) 아키텍처를 기반으로합니다.두 층 모두 드물게 활성화되어 Jetmoe-8b는 8b 매개 변수를 갖는 반면 각 입력 토큰에 대해 2B 만 활성화하여 LLAMA2-7B에 비해 추론 계산을 약 70% 감소시킵니다.또한 Jetmoe-8B는 공개 데이터 세트 및 교육 코드 만 사용하여 매우 개방적이고 학문 친화적입니다.모든 교육 매개 변수 및 데이터 혼합물은이 보고서에서 열린 기초 모델의 개발에 미래의 노력을 촉진하기 위해 자세히 설명되어 있습니다.이 투명성은 접근 가능하고 효율적인 LLM 분야의 협업과 추가 발전을 장려하는 것을 목표로합니다.모델 가중치는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Yikang Shen&&Zhen Guo&&Tianle Cai&&Zengyi Qin,arxiv,https://arxiv.org/abs/2404.07413
LLoCO: Learning Long Contexts Offline,"자체 변환 메커니즘의 2 차 계산 및 메모리 오버 헤드와 생성 중 실질적인 KV 캐시 크기로 인해 LLM (Lang Contex)을 처리하는 것은 여전히 큰 언어 모델 (LLMS)의 과제로 남아 있습니다.우리는 컨텍스트 압축 및 도메인 매개 변수 효율적인 결합을 통해 오프라인 컨텍스트를 학습 함으로써이 문제를 해결하기위한 새로운 접근법을 제안합니다.우리의 방법을 통해 LLM은 원래 컨텍스트를 간결하게 표현하고 관련 정보를 효율적으로 검색하여 질문에 정확하게 답변 할 수 있습니다.LORA를 사용하여 컨텍스트 압축, 검색 및 매개 변수 효율적인 양조를 결합한 기술 인 Lloco를 소개합니다.우리의 접근 방식은 최대 128k 토큰을 처리하기 위해 4K 토큰 LLAMA2-7B 모델의 효과적인 컨텍스트 창을 확장합니다.우리는 여러 장기 텍스트 질문 응답 데이터 세트에 대한 접근 방식을 평가하여 Lloco가 추론 중에 30 \ Timesfewer 토큰을 사용하면서 텍스트 내 학습보다 훨씬 성능이 우수 함을 보여줍니다.Lloco는 최대 7.62 \ Timesspeed-Up을 달성하고 긴 문서 질문에 대한 비용을 크게 줄여서 효율적인 긴 상황 처리를위한 유망한 솔루션입니다.우리의 코드는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Sijun Tan&&Xiuyu Li&&Shishir Patil&&Ziyang Wu&&Tianjun Zhang&&Kurt Keutzer&&Joseph E. Gonzalez&&Raluca Ada Popa,arxiv,https://arxiv.org/abs/2404.07979
HGRN2: Gated Linear RNNs with State Expansion,"계층 적으로 게이트 된 선형 RNN (HGRN, Qin et al. 2023)은 효율적인 추론을 제공하면서 언어 모델링에서 경쟁력있는 교육 속도와 성능을 보여주었습니다.그러나 HGRN의 반복 상태 크기는 비교적 작으며,이 문제는 선형주의에서 영감을 얻은이 문제를 제한하여 간단한 외부 제품 기반 상태 확장 메커니즘을 도입하여 재발 상태 크기를 소개하지 않고도 크게 확대 될 수 있습니다.추가 매개 변수.선형주의 형태는 하드웨어 효율적인 교육을 허용합니다. 우리의 광범위한 실험은 언어 모델링, 이미지 분류 및 장거리 분야에서 HGRN1보다 HGRN2의 이점을 확인합니다.제어 된 실험 설정;또한 전체 교육 토큰을 사용하면서 다운 스트림 평가에서 많은 오픈 소스 3B 모델과 경쟁적으로 수행합니다.",2024.04.11,Zhen Qin&&Songlin Yang&&Weixuan Sun&&Xuyang Shen&&Dong Li&&Weigao Sun&&Yiran Zhong,arxiv,https://arxiv.org/abs/2404.07904
Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models,"안내는 이미지 생성 확산 모델에서 최고의 성능을 추출하는 데 중요한 기술입니다.전통적으로, 이미지의 샘플링 체인 전체에 일정한 지침 가중치가 적용되었습니다.우리는 지침이 체인의 시작 (높은 노이즈 레벨)에 대해 분명히 유해하고, 끝까지 (저음 수준)에 크게 불필요하며 중간에서만 유리하다는 것을 보여줍니다.따라서 우리는이를 특정 범위의 노이즈 레벨로 제한하여 추론 속도와 결과 품질을 모두 향상시킵니다.이 제한된 지침 간격은 Imagenet-512의 레코드 FID를 1.81에서 1.40으로 크게 향상시킵니다.우리는 그것이 안정적인 확산 XL의 대규모 설정을 포함하여 서로 다른 샘플러 매개 변수, 네트워크 아키텍처 및 데이터 세트에서 정량적이고 질적으로 유리하다는 것을 보여줍니다.따라서 우리는지도를 사용하는 모든 확산 모델에서 지침 간격을 과복 매개 변수로 노출하는 것이 좋습니다.",2024.04.11,Tuomas Kynkäänniemi&&Miika Aittala&&Tero Karras&&Samuli Laine&&Timo Aila&&Jaakko Lehtinen,arxiv,https://arxiv.org/abs/2404.07724
OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments,"최소한의 인간 개입으로 복잡한 컴퓨터 작업을 달성하는 자율적 인 에이전트는 인간 컴퓨터 상호 작용을 변화시켜 접근성과 생산성을 크게 향상시킬 수 있습니다.그러나 기존 벤치 마크는 대화식 환경이 부족하거나 특정 응용 프로그램 또는 도메인에 특정한 환경으로 제한되어 실제 컴퓨터 사용의 다양하고 복잡한 특성을 반영하지 않으므로 작업 범위 및 에이전트 확장 성을 제한합니다.이 문제를 해결하기 위해, 우리는 Ubuntu, Windows 및 MacOS와 같은 다양한 운영 체제에서 지원하는 작업 설정, 실행 기반 평가 및 대화식 학습을위한 최초의 확장 가능한 실제 컴퓨터 환경 인 Osworld를 소개합니다..Osworld는 임의의 응용 프로그램과 관련된 개방형 컴퓨터 작업을 평가하기위한 통합 된 통합 컴퓨터 환경 역할을 할 수 있습니다.Osworld를 바탕으로 Open Domains, OS 파일 I/O 및 여러 응용 프로그램에 걸친 워크 플로에서 실제 웹 및 데스크탑 앱과 관련된 369 개의 컴퓨터 작업의 벤치 마크를 만듭니다.각 작업 예제는 실제 컴퓨터 사용 사례에서 파생되며 신뢰할 수 있고 재현 가능한 평가를위한 자세한 초기 상태 설정 구성 및 사용자 정의 실행 기반 평가 스크립트가 포함되어 있습니다.Osworld에서 최첨단 LLM/VLM 기반 에이전트에 대한 광범위한 평가는 컴퓨터 보조자 역할을 수행하는 능력이 상당한 결함을 보여줍니다.인간은 작업의 72.36% 이상을 달성 할 수 있지만, 최고의 모델은 12.24%의 성공 만 달성하며, 주로 GUI 근거 및 운영 지식으로 어려움을 겪고 있습니다.Osworld를 사용한 포괄적 인 분석은 이전 벤치 마크에서는 불가능한 멀티 모달 일반 요원을 개발하기위한 귀중한 통찰력을 제공합니다.우리의 코드, 환경, 기준선 모델 및 데이터는 HTTPS URL에서 공개적으로 제공됩니다.",2024.04.11,Tianbao Xie&&Danyang Zhang&&Jixuan Chen&&Xiaochuan Li&&Siheng Zhao&&Ruisheng Cao&&Toh Jing Hua&&Zhoujun Cheng&&Dongchan Shin&&Fangyu Lei&&Yitao Liu&&Yiheng Xu&&Shuyan Zhou&&Silvio Savarese&&Caiming Xiong&&Victor Zhong&&Tao Yu,arxiv,https://arxiv.org/abs/2404.07972
Transferable and Principled Efficiency for Open-Vocabulary Segmentation,"사전 훈련 된 기초 시력-언어 모델의 최근 성공은 OVS (Open-Vocabulary Segmentation)를 가능하게합니다.유망한 성능에도 불구하고,이 접근법은 두 가지 과제에 대한 무거운 계산 간접비를 도입합니다. 1) 백본의 큰 모델 크기;2) 미세 조정 중에 비싼 비용.이러한 과제는이 OVS 전략이 실제 시나리오에서 널리 적용되고 저렴 해지는 것을 방해합니다.모델 압축 및 효율적인 미세 조정과 같은 전통적인 방법은 이러한 과제를 해결할 수 있지만 종종 휴리스틱에 의존합니다.이는 해당 솔루션을 쉽게 전송할 수 없으며 다른 모델에서 재 훈련이 필요하다는 것을 의미합니다.효율적인 OV의 맥락에서, 우리는 교육 비용이 낮은 소규모 모델을 활용하여 대규모 비전 언어 기초 모델을 기반으로 이전 OVS 작업과 비교할 수있는 성능을 달성하는 것을 목표로합니다.핵심 전략은 우리의 효율성을 하나의 OVS 프레임 워크에서 다른 사용자 정의없이 다른 OVS 프레임 워크에서 다른 사람으로 원활하게 전송할 수 있도록하는 것입니다.다양한 OVS 벤치 마크에 대한 포괄적 인 실험은 이전 작품에 대한 세분화 정확도와 계산 비용 사이의 우수한 상충 관계를 보여줍니다.우리의 코드는이 https url에서 사용할 수 있습니다",2024.04.11,Jingxuan Xu&&Wuyang Chen&&Yao Zhao&&Yunchao Wei,arxiv,https://arxiv.org/abs/2404.07448
Best Practices and Lessons Learned on Synthetic Data for Language Models,"AI 모델의 성공은 데이터 부족, 개인 정보 보호 문제 및 높은 비용으로 인해 얻기가 어려울 수있는 크고 다양하며 고품질 데이터 세트의 가용성에 의존합니다.합성 데이터는 실제 패턴을 모방하는 인공 데이터를 생성함으로써 유망한 솔루션으로 등장했습니다.이 백서는 합성 데이터 연구에 대한 개요를 제공하고 응용 프로그램, 과제 및 향후 방향을 논의합니다.우리는 우선 예술의 경험적 증거를 제시하여 그 효과를 보여주고 사실 성, 충실도 및 편견을 보장하는 것의 중요성을 강조합니다.우리는보다 강력하고 포괄적이며 신뢰할 수있는 언어 모델을 구축하기 위해 합성 데이터의 책임감을 강조합니다.",2024.04.11,Ruibo Liu&&Jerry Wei&&Fangyu Liu&&Chenglei Si&&Yanzhe Zhang&&Jinmeng Rao&&Steven Zheng&&Daiyi Peng&&Diyi Yang&&Denny Zhou&&Andrew M. Dai,arxiv,https://arxiv.org/abs/2404.07503
Rho-1: Not All Tokens Are What You Need,"이전 언어 모델 사전 훈련 방법은 모든 훈련 토큰에 다음 번의 예측 손실을 균일하게 적용했습니다.이 규범에 도전하면서, 우리는 ""코퍼스의 모든 토큰이 언어 모델 훈련에 똑같이 중요하지는 않습니다""라고 주장합니다.우리의 초기 분석은 언어 모델의 토큰 수준의 훈련 역학을 탐구하여 다른 토큰에 대한 뚜렷한 손실 패턴을 드러냅니다.이러한 통찰력을 활용하여 Rho-1이라는 새로운 언어 모델을 소개합니다.Corpus의 다음 토큰을 예측하는 법을 배우는 전통적인 LM과 달리 RHO-1은 선택적 언어 모델링 (SLM)을 사용하는데, 이는 원하는 분포와 정렬 된 유용한 토큰을 선택적으로 훈련시킵니다.이 접근법은 참조 모델을 사용하여 사전 트레인 토큰의 점수를 매긴 다음 더 높은 손실로 토큰에 집중된 손실로 언어 모델을 훈련시키는 것이 포함됩니다.15B OpenWebMath Corpus에서 지속적으로 사전 여면을 할 때 RHO-1은 9 개의 수학 작업에서 최대 30%의 몇 번의 정확도가 절대적으로 개선됩니다.미세 조정 후, RHO-1-1B 및 7B는 수학 데이터 세트에서 각각 40.6% 및 51.8%의 최첨단 결과를 달성했습니다.또한, 80B 일반 토큰의 사전 여지가있을 때 RHO-1은 15 가지 다양한 작업에서 6.8% 평균 향상을 달성하여 언어 모델 사전 훈련의 효율성과 성능을 모두 증가시킵니다.",2024.04.11,Zhenghao Lin&&Zhibin Gou&&Yeyun Gong&&Xiao Liu&&Yelong Shen&&Ruochen Xu&&Chen Lin&&Yujiu Yang&&Jian Jiao&&Nan Duan&&Weizhu Chen,arxiv,https://arxiv.org/abs/2404.07965
Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models,"흰 족제비는 지역 이해를 대형 언어 모델 (LLM)에 원활하게 통합하여 참조 및 접지 기능을 용이하게하지만, 미리 훈련 된 고정 시각 인코더에 의해 제한되고 더 넓은 작업에서 잘 수행되지 않았다.이 작품에서 우리는 흰 족제비로 업그레이드 한 Ferret-V2, 세 가지 주요 디자인을 공개합니다.(1) 모든 해상도 접지 및 참조 : 더 높은 이미지 해상도를 쉽게 처리하는 유연한 접근 방식으로 이미지를 처리하고 이해하는 모델의 능력을 향상시킵니다.(2) 다중 부문 시각 인코딩 : 추가 DINOV2 인코더를 통합 함으로써이 모델은 글로벌 및 세분화 된 시각 정보에 대한 더 좋고 다양한 기본 컨텍스트를 학습합니다.(3) 3 단계 훈련 패러다임 : 이미지 캡션 정렬 외에도 최종 명령 튜닝 전에 고해상도 조밀 한 정렬에 대한 추가 단계가 제안됩니다.실험에 따르면 Ferret-V2는 고해상도 스케일링 및 세밀한 시각적 처리 덕분에 흰 족제비 및 기타 최첨단 방법에 비해 상당한 개선을 제공합니다.",2024.04.11,Haotian Zhang&&Haoxuan You&&Philipp Dufter&&Bowen Zhang&&Chen Chen&&Hong-You Chen&&Tsu-Jui Fu&&William Yang Wang&&Shih-Fu Chang&&Zhe Gan&&Yinfei Yang,arxiv,https://arxiv.org/abs/2404.07973
From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples,"우리는 사전 훈련 된 대형 언어 모델 (예 : LLAMA2, GPT-4, Claude 3 등)이 추가 교육 또는 그라디언트 업데이트없이 텍스트 내 예제를 제공 할 때 선형 및 비선형 회귀를 수행 할 수있는 방법을 분석합니다.우리의 연구 결과에 따르면 몇 가지 대형 언어 모델 (예 : GPT-4, Claude 3)은 임의의 산림, 포장 또는 그라디언트 부스팅과 같은 전통적인 감독 방법의 성능 경쟁 (또는 성능 성능)로 회귀 작업을 수행 할 수 있습니다.예를 들어, 까다로운 Friedman #2 회귀 데이터 세트에서 Claude 3은 Adaboost, SVM, Random Forest, KNN 또는 Gradient Boosting과 같은 많은 감독 된 방법을 능가합니다.그런 다음 대형 언어 모델의 성능이 텍스트 내 모범의 수를 얼마나 잘 확장하는지 조사합니다.우리는 온라인 학습에서 후회의 개념에서 빌리며 LLM이 하위 선회 후회를 얻을 수 있음을 경험적으로 보여줍니다.",2024.04.11,Robert Vacareanu&&Vlad-Andrei Negru&&Vasile Suciu&&Mihai Surdeanu,arxiv,https://arxiv.org/abs/2404.07544
RecurrentGemma: Moving Past Transformers for Efficient Open Language Models,우리는 Google의 소설 그리핀 아키텍처를 사용하는 오픈 언어 모델 인 RecurrentGemma를 소개합니다.그리핀은 선형 재발과 지역주의를 결합하여 언어에 대한 탁월한 성능을 달성합니다.고정 된 크기의 상태가있어 메모리 사용을 줄이고 긴 시퀀스에서 효율적인 추론을 가능하게합니다.우리는 2B 비 embedding 매개 변수와 명령 조정 된 변형을 가진 미리 훈련 된 모델을 제공합니다.두 모델 모두 더 적은 수의 토큰에 대해 훈련을 받았음에도 불구하고 Gemma-2B와 비슷한 성능을 달성합니다.,2024.04.11,Aleksandar Botev&&Soham De&&Samuel L Smith&&Anushan Fernando&&George-Cristian Muraru&&Ruba Haroun&&Leonard Berrada&&Razvan Pascanu&&Pier Giuseppe Sessa&&Robert Dadashi&&Léonard Hussenot&&Johan Ferret&&Sertan Girgin&&Olivier Bachem&&Alek Andreev&&Kathleen Kenealy&&Thomas Mesnard&&Cassidy Hardin&&Surya Bhupatiraju&&Shreya Pathak&&Laurent Sifre&&Morgane Rivière&&Mihir Sanjay Kale&&Juliette Love&&Pouya Tafti&&Armand Joulin&&Noah Fiedel&&Evan Senter&&Yutian Chen&&Srivatsan Srinivasan&&Guillaume Desjardins&&David Budden&&Arnaud Doucet&&Sharad Vikram&&Adam Paszke&&Trevor Gale&&Sebastian Borgeaud&&Charlie Chen&&Andy Brock&&Antonia Paterson&&Jenny Brennan&&Meg Risdal&&Raj Gundluru&&Nesh Devanathan&&Paul Mooney&&Nilay Chauhan&&Phil Culliton&&Luiz GUStavo Martins&&Elisa Bandy&&David Huntsperger&&Glenn Cameron&&Arthur Zucker&&Tris Warkentin&&Ludovic Peran&&Minh Giang&&Zoubin Ghahramani&&Clément Farabet&&Koray Kavukcuoglu&&Demis Hassabis&&Raia Hadsell&&Yee Whye Teh&&Nando de Frietas,arxiv,https://arxiv.org/abs/2404.07839
Audio Dialogues: Dialogues dataset for audio and music understanding,"오디오 이해를위한 기존 데이터 세트는 주로 자연 언어로 오디오를 설명하기위한 단일 회전 상호 작용 (예 : 오디오 캡션, 오디오 질문 응답)에 중점을 두어 대화식 대화를 통해 오디오 이해를 제한합니다.이 차이를 해결하기 위해, 우리는 일반 오디오 사운드 및 음악을위한 163.8k 샘플을 포함하는 다중 회전 대화 데이터 세트를 소개합니다.대화 외에도 오디오 대화에는 여러 입력 오디오를 이해하고 비교할 수있는 질문 응답 쌍이 있습니다.오디오 대화 상자는 기존 데이터 세트의 프롬프트 기반 접근 방식 및 캡션 주석을 활용하여 LLM (Lange Language Model)을 사용하여 다중 턴 대화를 생성합니다.오디오 대화의 복잡성과 적용 가능성을 보여주기 위해 제안 된 데이터 세트에서 기존 오디오 구축 된 대형 언어 모델을 평가합니다.데이터 세트를 생성하기위한 코드는 공개적으로 제공됩니다.자세한 프롬프트 및 생성 된 대화는 데모 웹 사이트 HTTPS URL에서 찾을 수 있습니다.",2024.04.11,Arushi Goel&&Zhifeng Kong&&Rafael Valle&&Bryan Catanzaro,arxiv,https://arxiv.org/abs/2404.07616
Sparse Laneformer,"차선 탐지는 자율 주행의 근본적인 작업이며 딥 러닝이 등장함에 따라 큰 진전을 이루었습니다.이전의 앵커 기반 방법은 종종 조밀 한 앵커를 설계하며, 이는 훈련 데이터 세트에 크게 의존하고 추론 중에 고정 된 상태로 유지됩니다.우리는 레인 검출에 밀집된 앵커가 필요하지 않다는 것을 분석하고 희소 한 앵커 메커니즘을 기반으로 변압기 기반 차선 검출 프레임 워크를 제안합니다.이를 위해, 우리는 전통적인 명시 적 앵커 대신 위치 인식 레인 쿼리와 각도 쿼리를 가진 스파 스 앵커를 생성합니다.우리는 수평 지각주의 (HPA)를 채택하여 수평 방향을 따라 레인 특징을 집계하고 레인 앵글 크로스주의 (LACA)를 채택하여 레인 쿼리와 각도 쿼리 사이의 상호 작용을 수행합니다.또한 차선 예측을 추가로 개선하기 위해 변형 가능한 교차주의에 기초하여 레인 지각주의 (LPA)를 제안합니다.Sparse Laneformer라는 우리의 방법은 구현하기 쉬우 며 엔드 투 엔드 훈련 가능입니다.광범위한 실험에 따르면 스파 스 란 형성체는 최첨단 방법, 예를 들어 LANEFORMER를 3.0% F1 점수로, O2SFormer를 0.7% F1 점수만큼 동일한 RESNET-34 백본으로 CULANE에서 MAC의 MAC를 능가합니다.",2024.04.11,Ji Liu&&Zifeng Zhang&&Mingjie Lu&&Hongyang Wei&&Dong Li&&Yile Xie&&Jinzhang Peng&&Lu Tian&&Ashish Sirasao&&Emad Barsoum,arxiv,https://arxiv.org/abs/2404.07821
On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation,"자연어를 추가 지침으로 통합하여 단안 깊이 추정의 최근 발전이 이루어졌습니다.인상적인 결과를 낳지 만, 언어의 영향, 특히 일반화와 견고성 측면에서 언어의 영향은 여전히 탐구되지 않습니다.이 백서에서는이 이전의 영향을 정량화 하여이 격차를 해결하고 다양한 설정에서 그 효과를 벤치마킹하기위한 방법을 소개합니다.우리는 객체 중심의 3 차원 공간 관계를 전달하는 ""저수준""문장을 생성하고, 추가 언어 사전으로 통합하고 깊이 추정에 대한 하류 영향을 평가합니다.우리의 주요 발견은 현재 언어 유도 깊이 추정기가 장면 수준 설명에서만 최적으로 성능을 발휘하고 낮은 수준의 설명으로 반 직관적으로 악화된다는 것입니다.추가 데이터를 활용하더라도 이러한 방법은 지시 된 적대적 공격에 대한 강력하지 않으며 분포 이동이 증가함에 따라 성능 감소.마지막으로, 미래의 연구를위한 토대를 제공하기 위해, 우리는 실패 지점을 식별하고 이러한 단점을 더 잘 이해할 수있는 통찰력을 제공합니다.깊이 추정을 위해 언어를 사용하여 점점 더 많은 방법으로, 우리의 연구 결과는 실제 환경에서 효과적인 배포를 위해 신중한 고려가 필요한 기회와 함정을 강조합니다.",2024.04.12,Agneet Chatterjee&&Tejas Gokhale&&Chitta Baral&&Yezhou Yang,arxiv,https://arxiv.org/abs/2404.08540
COCONut: Modernizing COCO Segmentation,"최근 수십 년 동안 비전 커뮤니티는 데이터 세트 벤치 마크의 발전으로 인해 시각적 인식의 놀라운 진전을 목격했습니다.특히, 확립 된 Coco 벤치 마크는 현대 탐지 및 세분화 시스템의 개발을 추진했습니다.그러나 Coco Segmentation 벤치 마크는 지난 10 년 동안 비교적 느리게 개선되었습니다.사물 인스턴스에 대한 거친 다각형 주석이 원래 장착 된이 제품은 물건 영역에 대한 거친 슈퍼 픽셀 주석을 점차적으로 통합하여 파노스틱 세분화 주석을 생성하기 위해 휴리스틱으로 합병되었습니다.다른 평가자 그룹에 의해 실행 된 이러한 주석은 거친 분할 마스크뿐만 아니라 세분화 유형 사이의 불일치로도 발생했습니다.이 연구에서 우리는 Coco 세분화 주석에 대한 포괄적 인 재평가를 수행합니다.주석 품질을 향상시키고 데이터 세트를 확장하여 5.18m 이상의 Panoptic 마스크가있는 383k 이미지를 포함하여 코코넛 인 Coco Next Universal Segmentation DataSet을 소개합니다.코코넛은 세분화 된 고품질 마스크를 사용하여 시맨틱, 인스턴스 및 팬틱 세분화에 걸쳐 세분화 주석을 조화시키고 모든 세분화 작업에 대한 강력한 벤치 마크를 설정합니다.우리가 아는 한, 코코넛은 인간 평가자에 의해 검증 된 대규모 대규모 범용 세분화 데이터 세트로 서 있습니다.우리는 코코넛의 출시가 새로운 신경망의 진행 상황을 평가하는 지역 사회의 능력에 크게 기여할 것으로 기대합니다.",2024.04.12,Xueqing Deng&&Qihang Yu&&Peng Wang&&Xiaohui Shen&&Liang-Chieh Chen,arxiv,https://arxiv.org/abs/2404.08639
Dataset Reset Policy Optimization for RLHF,"인간 선호도 기반 피드백의 강화 학습 (RL)은 GPT-4 및 Claude3 Opus와 같은 인상적인 모델을 생성 한 미세 조정 생성 모델에 대한 인기있는 패러다임입니다.이 프레임 워크는 종종 오프라인 환경 설정 데이터 세트에서 보상 모델을 배우고 온라인 RL을 실행하여 학습 된 보상 모델을 최적화합니다.이 작업에서는 재설정 아이디어를 활용하여 입증 가능한 보증이있는 새로운 RLHF 알고리즘을 제안합니다.오프라인 환경 설정 데이터 세트가 유익한 상태 (즉, 레이더가 선호하는 데이터), 새로운 알고리즘 인 DR-PO (Dataset Reset Policy Optimization)를 제공한다는 사실에 의해 기존의 오프라인 선호도 데이터 세트를 온라인 정책 교육 절차에 통합한다는 사실에 의해 동기가 부여됩니다.데이터 세트 재설정 : 항상 초기 상태 배포에서 시작하는 대신 오프라인 데이터 세트의 상태에 정책 옵티마이저를 직접 재설정합니다.이론적으로, 우리는 DR-PO가 유한 한 샘플 복잡성으로 일반 함수 근사치에 따라 오프라인 데이터 세트가 다루는 모든 정책만큼 적어도 우수한 성능을 배우는 것을 보여줍니다.실험에서, 우리는 TL; DR 요약 및 인류 유용한 유해 (HH) 데이터 세트에서 DR-PO의 생성이 근위 정책 최적화 (PPO)와 DPO (Direction Preference Optimization)의 생성보다 낫다는 것을 보여줍니다.GPT4 Win-Rate의 메트릭.이 작업에 대한 코드는 HTTPS URL에서 찾을 수 있습니다.",2024.04.12,Jonathan D. Chang&&Wenhao Zhan&&Owen Oertell&&Kianté Brantley&&Dipendra Misra&&Jason D. Lee&&Wen Sun,arxiv,https://arxiv.org/abs/2404.08495
Probing the 3D Awareness of Visual Foundation Models,"대규모 사전 해독의 최근 발전은 강력한 기능을 갖춘 시각적 기초 모델을 산출했습니다.최근 모델은 훈련 작업을 위해 임의의 이미지로 일반화 할 수있을뿐만 아니라, 중간 표현은 탐지 및 세분화와 같은 다른 시각적 작업에 유용합니다.이러한 모델이 2D로 객체를 분류, 묘사 및 로컬화할 수 있다는 점을 감안할 때, 우리는 그들이 3D 구조를 나타내는 지 여부를 묻습니다.이 작업에서는 시각적 기초 모델의 3D 인식을 분석합니다.우리는 3D 인식이 (1) 장면의 3D 구조를 인코딩하고 (2) 표면을 지속적으로 표현한다는 것을 암시한다.우리는 냉동 기능에 대한 작업 별 프로브와 제로 샷 추론 절차를 사용하여 일련의 실험을 수행합니다.우리의 실험은 현재 모델의 몇 가지 한계를 보여줍니다.우리의 코드 및 분석은 https url에서 찾을 수 있습니다.",2024.04.12,Mohamed El Banani&&Amit Raj&&Kevis-Kokitsi Maninis&&Abhishek Kar&&Yuanzhen Li&&Michael Rubinstein&&Deqing Sun&&Leonidas Guibas&&Justin Johnson&&Varun Jampani,arxiv,https://arxiv.org/abs/2404.08636
"Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies","이 논문은 제한된 계산 예산으로 확장 될 때 대조적 인 언어 이미지 사전 훈련 (클립)의 성능을 조사합니다.데이터, 아키텍처 및 교육 전략의 세 가지 차원을 따라 클립을 탐색합니다.데이터와 관련하여 고품질 교육 데이터의 중요성을 보여주고 고품질 데이터의 더 작은 데이터 세트가 품질이 낮은 더 큰 데이터 세트보다 우수 할 수 있음을 보여줍니다.또한 모델 성능이 데이터 세트 크기에 따라 어떻게 변하는 지 살펴 봅니다. 이는 소규모 VIT 모델이 소규모 데이터 세트에 더 적합한 반면, 더 큰 모델은 고정 된 컴퓨팅으로 더 큰 데이터 세트에서 더 잘 작동 함을 시사합니다.또한 CNN 기반 아키텍처 또는 클립 교육을위한 VIT 기반 아키텍처를 선택할시기에 대한 지침을 제공합니다.우리는 미끄러짐, 플립, 클립 및 클립+데이터 증강의 네 가지 클립 훈련 전략을 비교하고 교육 전략의 선택이 사용 가능한 컴퓨팅 리소스에 달려 있음을 보여줍니다.우리의 분석에 따르면 Clip+Data 증강은 교육 데이터의 절반 만 사용하여 Clip과 비슷한 성능을 달성 할 수 있습니다.이 작업은 클립 모델을 효과적으로 훈련하고 배포하는 방법에 대한 실질적인 통찰력을 제공하여 다양한 응용 프로그램에서 실질적으로 사용하기 쉽고 저렴한 가격으로 제공합니다.",2024.04.12,Zichao Li&&Cihang Xie&&Ekin Dogus Cubuk,arxiv,https://arxiv.org/abs/2404.08197
MonoPatchNeRF: Improving Neural Radiance Fields with Patch-based Monocular Guidance,"최신 정규화 된 신경 방사 분야 (NERF) 접근법은 열악한 지오메트리를 생성하고 MVS (Multiview Stereo) 벤치 마크에 대한 외삽을 봅니다.이 논문에서는 정확한 형상 및 뷰 합성을 제공하는 3D 모델을 만들어 NERF와 전통적인 MVS 방법 사이의 대규모 기하학적 성능 간격을 부분적으로 닫는 것을 목표로합니다.우리는 단안 표면 정상 및 상대 깊이 예측을 효과적으로 활용하는 패치 기반 접근법을 제안합니다.패치 기반 광선 샘플링은 또한 무작위로 샘플링 된 가상 및 훈련 뷰 사이의 정규화 된 교차 상관 (NCC) 및 구조적 유사성 (SSIM)의 외관 정규화를 가능하게합니다.우리는 소설 구조에 기초한 ""밀도 제한""이 소설 뷰 합성 메트릭의 약간 감소함으로써 기하학적 정확도를 크게 향상시키는 데 도움이 될 수 있음을 보여줍니다.우리의 실험에 따르면 ETH3D MVS 벤치 마크의 평균 F1@2cm의 Freenerf의 성능은 4 배, NERF 기반 모델의 기하학적 정확도를 향상시키기위한 유익한 연구 방향을 시사하고 NERF를 활성화하기위한 잠재적 인 미래의 접근 방식을 밝힙니다.-결국 기존 MV를 능가하기위한 기반 최적화.",2024.04.12,Yuqun Wu&&Jae Yong Lee&&Chuhang Zou&&Shenlong Wang&&Derek Hoiem,arxiv,https://arxiv.org/abs/2404.08252
Pre-training Small Base LMs with Fewer Tokens,"우리는 기존의 큰 기본 LM에서 시작하여 작은 기본 언어 모델 (LM)을 개발하기위한 간단한 접근 방식의 효과를 연구합니다. 먼저 큰 LM에서 몇 개의 변압기 블록을 상속 한 다음이 작은 모델을 매우 작은 서브 세트 (0.1에서 훈련시킵니다.더 큰 모델의 원시 프리 트레인 데이터의 \%).우리는 간단한 레시피 상인을 호출하고 먼저 1B 토큰 (및 더 큰 LM 3B 매개 변수의 시작 몇 층의 시작)을 사용하여 1.5B 매개 변수가있는 작은베이스 LM을 구축하기 위해 먼저 시연합니다.우리는 반나절 미만 동안 단일 A6000 GPU를 사용하여이를 수행합니다.MMLU 벤치 마크뿐만 아니라 9 가지 다양한 평가 데이터 세트에서 결과 모델은 1B-2B 크기의 공개적으로 사용 가능한 기본 모델과 유리하게 비교되며, 그 중 일부는 50-1000 배 더 많은 토큰을 사용하여 교육을 받았으며 약간 다른 설정에서의 상속을 조사합니다.큰 LMS와 전체 사전 훈련 데이터 세트를 사용하여 소형 LMS를 훈련시킵니다.여기서 우리는 GPT2- 메드 (355m) 및 GPT-2-LARGE (770m)의 일부 층을 사용하여 더 작은 LMS 훈련을받는 것이 더 큰 수의 훈련 단계에 대해 처음부터 훈련 될 때 더 큰 상대방의 VAL 손실과 효과적으로 일치 할 수 있음을 보여줍니다.9B 토큰이있는 OpenWebText 데이터 세트.우리는 광범위한 실험으로 레시피를 분석하고 다양한 설정에서 효능을 보여줍니다.우리의 코드는 https url에서 사용할 수 있습니다.",2024.04.12,Sunny Sanyal&&Sujay Sanghavi&&Alexandros G. Dimakis,arxiv,https://arxiv.org/abs/2404.08634
Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length,"변압기의 2 차 복잡성 및 약한 길이 외삽은 긴 시퀀스로 확장하는 능력을 제한하며, 선형주의 및 상태 공간 모델과 같은 하위 분량 솔루션이 존재하지만, 사전 변형 효율과 다운 스트림 작업 정확도에서 변압기가 경험적으로 저조합니다.우리는 무제한 컨텍스트 길이를 가진 효율적인 서열 모델링을위한 신경 구조 인 Megalodon을 소개합니다.Megalodon은 Mega의 아키텍처 (게이트 된주의를 기울여 지수 이동 평균)의 아키텍처를 상속하고, 복잡한 지수 이동 평균 (CEMA), 타임 스텝 정규화 층, 정규화 된주의 메커니즘 및 두 가지를 포함하여 기능 및 안정성을 향상시키기 위해 여러 기술 구성 요소를 도입합니다.잔류 구성.LLAMA2와의 제어 된 헤드 투 헤드 비교에서 Megalodon은 70 억 파라미터 규모와 2 조 훈련 토큰의 변압기보다 더 나은 효율을 달성합니다.Megalodon은 LLAMA2-7B (1.75)와 13B (1.67) 사이의 중간 쯤에 1.70의 훈련 손실에 도달합니다.코드 :이 https url",2024.04.12,Xuezhe Ma&&Xiaomeng Yang&&Wenhan Xiong&&Beidi Chen&&Lili Yu&&Hao Zhang&&Jonathan May&&Luke Zettlemoyer&&Omer Levy&&Chunting Zhou,arxiv,https://arxiv.org/abs/2404.08801
JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models,"LLM (Lange Language Model)의 확산은 보안 취약점, 특히 탈옥 공격에 대한 우려를 강조했으며, 적대자들은 잠재적 오용을위한 안전 메커니즘을 우회하기 위해 탈옥을 설계하는 프롬프트를 설계합니다.이러한 우려를 해결하려면 LLMS의 방어 능력을 평가하고 잠재적 약점을 식별하기위한 탈옥 프롬프트에 대한 포괄적 인 분석이 필요합니다.그러나 탈옥 성능을 평가하고 신속한 특성을 이해하는 복잡성으로 인해이 분석이 힘들어집니다.우리는 도메인 전문가와 협력하여 문제를 특성화하고 LLM 지원 프레임 워크를 제안하여 분석 프로세스를 간소화합니다.프롬프트의 구성 요소 및 키워드에 대한 성능 평가 및 지원 분석을 용이하게하기 위해 자동 탈옥 평가를 제공합니다.프레임 워크를 기반으로, 우리는 사용자가 대상 모델에 대한 탈옥 성능을 탐색하고, 신속한 특성에 대한 다단계 분석을 수행하고, 신속한 인스턴스를 개선하여 결과를 확인할 수있는 시각적 분석 시스템 인 JailbreakLens를 설계합니다.사례 연구, 기술 평가 및 전문가 인터뷰를 통해 사용자가 모델 보안을 평가하고 모델 약점을 식별하는 데 도움이되는 시스템의 효과를 보여줍니다.",2024.04.12,Yingchaojie Feng&&Zhizhang Chen&&Zhining Kang&&Sijia Wang&&Minfeng Zhu&&Wei Zhang&&Wei Chen,arxiv,https://arxiv.org/abs/2404.08793
On Speculative Decoding for Multimodal Large Language Models,"멀티 모달 대형 언어 모델 (MLLM)과의 추론은 메모리 대역폭 병목으로 고통 받고 토큰을 자동으로 생성하는 대형 모델 백본으로 인해 느리게 진행됩니다.이 논문에서는 MLLM의 추론 효율, 특히 LLAVA 7B 모델의 추론 효율을 향상시키기위한 투기 디코딩의 적용을 탐구합니다.우리는 언어 전용 모델이 LLAVA 7B로 투기 디코딩을위한 좋은 초안 모델 역할을 할 수 있으며, 초안 모델의 이미지 토큰 및 관련 처리 구성 요소를 우회합니다.세 가지 다른 작업에 대한 실험에 따르면 투기 디코딩은 처음부터 훈련 한 115m 매개 변수 언어 모델을 최대 2.37의 메모리 바운드 속도를 달성 할 수 있음을 보여줍니다.또한 이미지 어댑터를 통합 한 컴팩트 한 LLAVA 드래프트 모델을 소개하는데, 이는 이미지 캡션의 한계 성능 이득을 보여 주면서 다른 작업에서 비슷한 결과를 유지합니다.",2024.04.13,Mukul Gagrani&&Raghavv Goel&&Wonseok Jeon&&Junyoung Park&&Mingu Lee&&Christopher Lott,arxiv,https://arxiv.org/abs/2404.08856
TransformerFAM: Feedback attention is working memory,"트랜스포머는 딥 러닝에 혁명을 일으켰지 만, 2 차주의 복잡성은 무한한 입력을 처리하는 능력을 방해합니다.우리는 피드백 루프를 활용하여 네트워크가 자체 잠재적 표현에 참석할 수 있도록 피드백 루프를 활용하는 새로운 변압기 아키텍처 인 피드백주의 메모리 (FAM)를 제안합니다.이 디자인은 변압기 내 작업 메모리의 출현을 촉진하여 무기한 긴 시퀀스를 처리 할 수 있습니다.TransformerFam은 추가 가중치가 필요하지 않으므로 미리 훈련 된 모델과 완벽하게 통합 할 수 있습니다.우리의 실험에 따르면 TransformerFam은 다양한 모델 크기 (1B, 8B 및 24B)에서 장기 텍스트 작업에서 변압기 성능을 크게 향상시킵니다.이 결과는 LLM (Lange Language Model)에 권한을 부여 할 수있는 잠재력을 보여줍니다.",2024.04.14,Dongseong Hwang&&Weiran Wang&&Zhuoyuan Huo&&Khe Chai Sim&&Pedro Moreno Mengibar,arxiv,https://arxiv.org/abs/2404.09173
TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models,"멀티 모달 대형 언어 모델 (MLLM)은 다양한 멀티 모달 작업에 대한 인상적인 결과를 보여주었습니다.그러나 대부분의 기존 MLLM은 문서 지향 작업에 적합하지 않으며, 세밀한 이미지 인식 및 정보 압축이 필요합니다.이 논문에서는 MLLM의 일반적인 기능을 유지하면서 문서 지향 작업을 위해 특별히 설계된 MLLM 인 Texthawk를 제시합니다.Texthawk는 4 개의 전용 구성 요소를 설계하여 효율적인 세밀한 인식을 탐색하는 것을 목표로합니다.첫째, 문서 텍스트의 중복성을 줄이고 MLLM의 계산 비용을 낮추기 위해 리샘플링 및 재 배열 (RESA) 모듈이 제안됩니다.다양한 이미지 크기의 확장 성을 보존 할 수있는 확장 가능한 위치 임베딩 (SPE)을 제시하여 각 로컬 기능의 위치를 인코딩하는 것을 탐색합니다.그런 다음 쿼리 제안 네트워크 (QPN)가 채택되어 다른 하위 이미지간에 쿼리를 동적으로 초기화합니다.MLLM의 세밀한 시각적 지각 능력을 더욱 향상시키기 위해, 우리는 문서 이미지의 계층 적 구조와 의미 론적 관계를 포착하는 다단계 크로스-해소 (MLCA) 메커니즘을 설계합니다.또한 Gemini Pro를 사용하여 멀티 모달 문서 데이터를 풍부하게하여 문서 지향 작업을위한 새로운 명령 조정 데이터 세트를 만듭니다.우리는 일반 및 문서 지향 MLLM 벤치 마크에 대한 광범위한 실험을 수행하고 Texthawk가 최첨단 방법보다 우수하여 세밀한 문서 인식과 일반적인 능력의 효과와 우월성을 보여줍니다.",2024.04.14,Ya-Qi Yu&&Minghui Liao&&Jihao Wu&&Yongxin Liao&&Xiaoyu Zheng&&Wei Zeng,arxiv,https://arxiv.org/abs/2404.09204
Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model,"Controlnets는 깊이 맵, 캐니 가장자리 및 인간 포즈와 같은 다양한 조건을 갖는 이미지 생성에서 공간 제어를 추가하는 데 널리 사용됩니다.그러나 제어 된 비디오 생성을 위해 사전 상환 이미지 컨트롤을 활용할 때 몇 가지 과제가 있습니다.첫째, 사전에 사전 처리 된 Controlnet은 기능 공간의 불일치로 인해 새로운 백본 모델에 직접 연결할 수 없으며 새로운 백본에 대한 컨트롤 훈련 비용은 큰 부담입니다.둘째, 다른 프레임의 Controlnet 기능은 시간적 일관성을 효과적으로 처리하지 못할 수 있습니다.이러한 과제를 해결하기 위해, 우리는 사전 제어 컨트롤을 조정하고 (비디오에 대한 시간적 정렬을 개선함으로써 모든 이미지/비디오 확산 모델에 다양한 컨트롤을 추가하는 효율적이고 다양한 프레임 워크 인 CTRL-ADAPTER를 소개합니다.Ctrl-Adapter는 이미지 제어, 비디오 제어, 희소 프레임이있는 비디오 제어, 다중 조건 제어, 다른 백본과의 호환성, 보이지 않는 제어 조건에 대한 적응 및 비디오 편집 등 다양한 기능을 제공합니다.Ctrl-Adapter에서, 우리는 전례가 된 컨트롤 넷 기능을 다른 이미지/비디오 확산 모델에 융합 시키는데, 컨트롤 넷의 매개 변수와 확산 모델을 동결시키는 어댑터 레이어를 훈련시킵니다.Ctrl-Adapter는 시간 및 공간 모듈로 구성되어 비디오의 시간적 일관성을 효과적으로 처리 할 수 있습니다.또한 강력한 적응 및 드문 제어를 위해 잠재적 인 건너 뛰기 및 역 타임 스텝 샘플링을 제안합니다.또한 Ctrl-Adapter는 단순히 (가중치) 평균의 ControlNet 출력을 취하여 여러 조건의 제어를 가능하게합니다.다양한 이미지/비디오 확산 백본 (SDXL, Hotshot-XL, I2VGEN-XL 및 SVD)을 사용하면 CTRL-ADAPTER가 이미지 제어를위한 Controlnet과 일치하고 비디오 제어를위한 모든 기준 (Davis 2017 데이터 세트의 SOTA 정확도 달성)을 능가합니다.계산 비용 절감 (10GPU 시간 미만).",2024.04.15,Han Lin&&Jaemin Cho&&Abhay Zala&&Mohit Bansal,arxiv,https://arxiv.org/abs/2404.09967
Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization,아티스트와 미디어 직원이 아이디어를 빠르게 생생하게하여 사전 제작 모형을 만들 수 있도록 할 수 있기 때문에 많은 콘텐츠 제작 분야에서 생성적인 멀티 모달 컨텐츠가 점점 더 널리 퍼져 있습니다.텍스트 프롬프트의 오디오 생성은 음악 및 영화 산업에서 이러한 프로세스의 중요한 측면입니다.최근의 확산 기반 텍스트-아우 디오 모델 중 다수는 프롬프트 아우 디오 쌍의 대규모 데이터 세트에서 점점 더 정교한 확산 모델을 훈련시키는 데 중점을 둡니다.이 모델은 입력 프롬프트와 관련하여 출력 오디오에서 개념이나 이벤트의 존재 및 시간 순서에 명시 적으로 초점을 맞추지 않습니다.우리의 가설은 오디오 생성의 이러한 측면이 제한된 데이터가있을 때 오디오 생성 성능을 향상시킬 수있는 방법에 초점을 맞추고 있습니다.따라서이 작업에서 기존의 텍스트-아우 디오 모델 Tango를 사용하여 각 프롬프트에는 승자 오디오 출력 및 확산 모델에 대한 일부 패자 오디오 출력이있는 환경 설정 데이터 세트를 합성 적으로 만듭니다.이론적으로 패자 생산량은 프롬프트 누락 또는 잘못된 순서로 일부 개념이 있습니다.우리는 선호도 데이터 세트에서 확산 -DPO (직접 환경 설정 최적화) 손실을 사용하여 공개적으로 사용 가능한 탱고 텍스트-아우 디오 모델을 미세 조정하고 자동 및 매뉴얼 측면에서 탱고 및 아우디로드 (Audioldm2)보다 오디오 출력이 향상됨을 보여줍니다.-평가 지표.,2024.04.15,Navonil Majumder&&Chia-Yu Hung&&Deepanway Ghosal&&Wei-Ning Hsu&&Rada Mihalcea&&Soujanya Poria,arxiv,https://arxiv.org/abs/2404.09956
CompGS: Efficient 3D Scene Representation via Compressed Gaussian Splatting,"뛰어난 렌더링 품질과 효율성으로 유명한 가우스 스플릿은 3D 장면 표현에서 두드러진 기술로 부상했습니다.그러나 가우스 분할의 상당한 데이터 양은 실제 응용 프로그램에서 실질적인 유용성을 방해합니다.여기, 우리는 압축 가우시안 스플릿 (Comppressed Gaussian Splatting)이라는 효율적인 3D 장면 표현을 제안하며, 이는 데이터 크기가 현저하게 감소한 충실한 3D 장면 모델링을위한 소형 가우시안 프리미티브를 활용합니다.가우시안 프리미티브의 작품을 보장하기 위해, 우리는 서로의 예측 관계를 포착하는 하이브리드 원시 구조를 고안합니다.그런 다음 예측을위한 작은 앵커 프리미티브 세트를 이용하여 대부분의 프리미티브를 고도로 컴팩트 한 잔류 형태로 캡슐화 할 수 있습니다.또한, 우리는 이러한 하이브리드 프리미티브 내에서 중복성을 제거하기 위해 속도 제약 최적화 체계를 개발하여 Bitrate 소비와 표현 효능 사이의 최적의 트레이드 오프로 CompG를 조정합니다.실험 결과에 따르면 제안 된 COMPG는 기존 방법을 훨씬 능가하여 모델 정확도와 렌더링 품질을 손상시키지 않으면 서 3D 장면 표현에서 우수한 소형성을 달성 함을 보여줍니다.우리의 코드는 추가 연구를 위해 Github에서 발표 될 것입니다.",2024.04.15,Xiangrui Liu&&Xinju Wu&&Pingping Zhang&&Shiqi Wang&&Zhu Li&&Sam Kwong,arxiv,https://arxiv.org/abs/2404.09458
"Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video",게임 및 시뮬레이터와 같은 고품질 및 대화식 가상 환경을 만드는 경우 종종 복잡하고 비용이 많이 드는 수동 모델링 프로세스가 포함됩니다.이 논문에서는 실제 장면의 비디오를 사실적이고 대화식 게임 환경으로 자동 변환하는 새로운 접근 방식 인 Video2Game을 제시합니다.우리 시스템의 핵심에는 세 가지 핵심 구성 요소가 있습니다. (i) 장면의 형상 및 시각적 모양을 효과적으로 캡처하는 신경 방사선 (NERF) 모듈;(ii) 더 빠른 렌더링을 위해 NERF에서 지식을 증류하는 메쉬 모듈;및 (iii) 물체 간의 상호 작용과 물리적 역학을 모델링하는 물리 모듈.신중하게 설계된 파이프 라인을 따르면 실제 세계의 상호 작용 가능하고 실행 가능한 디지털 복제본을 구성 할 수 있습니다.우리는 실내 및 대규모 야외 장면 모두에서 시스템을 벤치마킹합니다.우리는 실시간으로 매우 현실적인 렌더링을 생성 할 수있을뿐만 아니라 대화 형 게임을 구축 할 수 있음을 보여줍니다.,2024.04.15,Hongchi Xia&&Zhi-Hao Lin&&Wei-Chiu Ma&&Shenlong Wang,arxiv,https://arxiv.org/abs/2404.09833
HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing,"이 연구는 약 200,000 개의 편집 된 고품질 교육 기반 이미지 편집 데이터 세트 인 HQ-EDIT를 소개합니다.구축 데이터 세트에 대한 속성 안내 또는 인간 피드백에 의존하는 이전 접근 방식과 달리, 우리는 고급 파운데이션 모델을 활용하는 확장 가능한 데이터 수집 파이프 라인, 즉 GPT-4V 및 Dall-E 3을 고안합니다.그런 다음 상세한 텍스트 프롬프트가있는 입력 및 출력 이미지를 특징으로하는 고품질 디티치를 만들었고, 후 처리를 통해 정확한 정렬을 보장합니다.또한 GPT-4V를 사용하여 이미지 편집 쌍의 품질을 정량적으로 평가하기 위해 정렬 및 일관성의 두 가지 평가 메트릭을 제안합니다.HQ EDITS 고해상도 이미지는 세부 사항이 풍부하고 포괄적 인 편집 프롬프트와 함께 기존 이미지 편집 모델의 기능을 크게 향상시킵니다.예를 들어, HQ-EDIT FINETUNED ORTRUCTPIX2PIX는 최첨단 이미지 편집 성능을 얻을 수 있으며, 인간이 주석화 된 데이터로 미세 조정 된 모델을 능가 할 수도 있습니다.프로젝트 페이지는 https url입니다.",2024.04.15,Mude Hui&&Siwei Yang&&Bingchen Zhao&&Yichun Shi&&Heng Wang&&Peng Wang&&Yuyin Zhou&&Cihang Xie,arxiv,https://arxiv.org/abs/2404.09990
Learn Your Reference Model for Real Good Alignment,"정렬 문제의 복잡성은 기존 방법이 불안정하다는 사실에서 비롯됩니다.연구원들은이 단점을 다루기 위해 다양한 트릭을 지속적으로 발명했습니다.예를 들어, 언어 모델 정렬의 인간 피드백 (RLHF) 기술로부터의 기본 강화 학습에서 보상 최대화 외에도 훈련 가능한 정책과 SFT 정책 사이의 Kullback-Leibler 발산이 최소화됩니다.이 추가로 모델이 RM (Reward Model)에 과도하게 장착되고 RM의 도메인이 아닌 텍스트를 생성하는 것을 방지합니다.DPO (Direct Preference Optimization) 메소드는 RLHF의 최적화 작업을 재구성하고 보상 모델을 제거하면서 정책이 SFT 정책에 가까워 지도록 요건을 암묵적으로 유지합니다.우리 논문에서, 우리는 DPO 메소드 에서이 암시 적 제한이 하위 최적의 결과로 이어진다 고 주장한다.우리는 교육 중 참조 정책을 업데이트하는 Trust Region DPO (TR-DPO)라는 새로운 방법을 제안합니다.이러한 간단한 업데이트를 통해 우리는 Anthropic HH 및 TLDR 데이터 세트에서 DPO에 대한 TR-DPO의 효과를 보여줍니다.우리는 TR-DPO가 GPT-4로 자동 평가에 의해 측정 된 DPO보다 최대 19%를 능가한다는 것을 보여줍니다.우리가 제안하는 새로운 정렬 접근법을 통해 일관성, 정확성, 세부 수준, 도움 및 무해함과 같은 여러 매개 변수에서 모델의 품질을 한 번에 개선 할 수 있습니다.",2024.04.15,Alexey Gorbatovski&&Boris Shaposhnikov&&Alexey Malakhov&&Nikita Surnachev&&Yaroslav Aksenov&&Ian Maksimov&&Nikita Balagansky&&Daniil Gavrilov,arxiv,https://arxiv.org/abs/2404.09656
Compression Represents Intelligence Linearly,"잘 압축하는 법을 배우면 지능으로 이어질 것이라는 믿음이 있습니다.최근 언어 모델링은 압축과 동등한 것으로 나타 났으며, 이는 LLMS (Lange Language Models)의 성공을위한 강력한 이론적 근거를 제공합니다.보다 고급 언어 모델의 개발은 본질적으로 압축을 향상시켜 인텔리전스를 용이하게합니다.이러한 매력적인 토론에도 불구하고 압축과 지능 사이의 상호 작용에 대한 경험적 증거는 거의 없습니다.이 작업에서 우리는 LLM의 맥락에서 LLM을 데이터 압축기로 취급하는 관계를 조사합니다.""지능""이라는 추상적 인 개념을 고려할 때, 우리는 평균 다운 스트림 벤치 마크 점수를 대리로, 특히 지식 및 상식, 코딩 및 수학적 추론과 관련된 지능을 대상으로 채택합니다.12 개의 벤치 마크에서, 우리의 연구는 다양한 조직에서 유래 한 30 개의 공개 LLM을 모았습니다.놀랍게도, 우리는 평균 벤치 마크 점수로 반영된 LLMS의 지능이 외부 텍스트 Corpora를 압축하는 능력과 거의 선형 적으로 상관 관계가 있음을 발견했습니다.이 결과는 우수한 압축이 더 큰 지능을 나타내는 신념을 뒷받침하는 구체적인 증거를 제공합니다.또한, 우리의 연구 결과는 원시 텍스트 Corpora에서 파생 된 감독되지 않은 메트릭으로서 압축 효율이 모델 기능과 선형으로 연관된 신뢰할 수있는 평가 측정으로 작용한다는 것을 시사합니다.우리는 압축 데이터 세트와 데이터 수집 파이프 라인을 개방하여 향후 연구원이 압축을 올바르게 평가할 수 있도록합니다.",2024.04.15,Yuzhen Huang&&Jinghan Zhang&&Zifei Shan&&Junxian He,arxiv,https://arxiv.org/abs/2404.09937
Taming Latent Diffusion Model for Neural Radiance Field Inpainting,"NERF (Neural Radiance Field)는 멀티 뷰 이미지로부터의 3D 재구성을위한 표현이다.최근에 확산으로 재구성 된 NERF 편집에서 예비 성공을 보여주는 최근의 일부 작업에도 불구하고, 그들은 완전히 발견되지 않은 지역에서 합리적인 지오메트리를 합성하기 위해 고군분투하고 있습니다.주요 이유 중 하나는 확산 모델의 다양한 합성 함량이 높은 다양한 합성 함량으로, 이는 빛나는 필드가 선명하고 결정적인 기하학으로 수렴하는 것을 방해합니다.또한, 실제 데이터에 잠재 확산 모델을 적용하면 종종 자동 인코딩 오류로 인해 이미지 조건과 일관되지 않는 텍스처 이동이 생성됩니다.이 두 가지 문제는 픽셀 차량 손실을 사용하여 더욱 강화됩니다.이러한 문제를 해결하기 위해, 우리는 장면 별 사용자 정의로 확산 모델의 확률을 강화하고 마스크 된 적대 훈련으로 조직적 변화를 완화 할 것을 제안합니다.분석 과정에서, 우리는 또한 일반적으로 사용되는 픽셀과 지각 손실이 NERF 수입 작업에서 유해하다는 것을 발견했습니다.우리의 프레임 워크는 엄격한 실험을 통해 다양한 실제 장면에서 최첨단 NERF 결과를 제공합니다.프로젝트 페이지 :이 HTTPS URL",2024.04.15,Chieh Hubert Lin&&Changil Kim&&Jia-Bin Huang&&Qinbo Li&&Chih-Yao Ma&&Johannes Kopf&&Ming-Hsuan Yang&&Hung-Yu Tseng,arxiv,https://arxiv.org/abs/2404.09995
MMInA: Benchmarking Multihop Multimodal Internet Agents,"자율 구체화 된 에이전트는 멀티미디어 웹 사이트 인터넷에 살고 있습니다.복잡한 사용자 작업을 완료하기 위해 멀티 모달 웹 사이트를 뛰어 넘을 수 있습니까?기존 벤치 마크는 웹 사이트 전체의 구체화에 대한 현실적이고 진화하는 환경에서 그것들을 평가하지 못합니다.이 질문에 답하기 위해, 우리는 MMINA 인 MMINA, MULTIHOP 및 MULTIMODAL 벤치 마크를 제시하여 구성된 인터넷 작업을위한 구체화 된 에이전트를 평가하며, 몇 가지 매력적인 속성과 함께 : 1) 실제 멀티 모달 웹 사이트 진화.우리의 벤치 마크는 진화하는 실제 웹 사이트에서 고유하게 운영되며, 자연스러운 사용자 작업에 대한 높은 수준의 현실감과 적용 가능성을 보장합니다.우리의 데이터에는 쇼핑 및 여행과 같은 다양한 영역을 다루는 1,050 개의 인간이 작성한 작업이 포함되어 있으며, 각 작업에는 에이전트가 웹 페이지에서 멀티 모달 정보를 관찰로 자율적으로 추출해야합니다.2) Multihop 웹 브라우징.당사의 데이터 세트에는 웹 작업에 대한 장거리 추론 기능을 평가하기 위해 여러 웹 사이트의 정보 또는 작업을 요구하는 자연스럽게 구성 작업을 수행합니다.3) 전체적인 평가.우리는 Multihop 작업을 완료하는 데있어 에이전트의 진행 상황을 평가하기위한 새로운 프로토콜을 제안합니다.우리는 독립형 (멀티 모달) 언어 모델과 휴리스틱 기반 웹 에이전트를 모두 실험합니다.광범위한 실험에 따르면 긴 체인 Multihop 웹 작업은 인간에게는 쉽지만 최첨단 웹 에이전트에게는 도전하고 있습니다.우리는 더 많은 홉의 작업을 해결할 때 에이전트가 초기 홉에서 실패 할 가능성이 높다는 것을 확인하여 작업 성공률이 낮아집니다.이 문제를 해결하기 위해, 우리는 과거의 행동 궤적을 재생하는 간단한 메모리 증강 접근법을 제안합니다.우리의 방법은 에이전트의 싱글 홉 및 멀티 팝 웹 브라우징 능력을 크게 향상시켰다.HTTPS URL에서 우리의 코드 및 데이터를 참조하십시오",2024.04.15,Ziniu Zhang&&Shulin Tian&&Liangyu Chen&&Ziwei Liu,arxiv,https://arxiv.org/abs/2404.09992
VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time,"우리는 단일 정적 이미지와 음성 오디오 클립을 제공하는 매력적인 시각적 정서 기술 (VAS)으로 생명과 같은 말을하는 얼굴을 생성하기위한 프레임 워크 인 VASA를 소개합니다.우리의 프리미어 모델 인 VASA-1은 오디오와 정교하게 동기화 된 립 움직임을 생성 할뿐만 아니라 진정성과 생생함의 인식에 기여하는 많은 얼굴 뉘앙스와 자연적인 머리 운동을 포착 할 수 있습니다.핵심 혁신에는 얼굴 잠재 공간에서 작동하는 전체적인 얼굴 역학 및 헤드 운동 생성 모델과 비디오를 사용하여 표현적이고 분리 된 얼굴 잠재 공간의 개발이 포함됩니다.새로운 메트릭 세트에 대한 평가를 포함한 광범위한 실험을 통해, 우리는 우리의 방법이 다양한 차원에 따라 이전 방법을 상당히 능가한다는 것을 보여줍니다.우리의 방법은 현실적인 얼굴 및 헤드 역학으로 높은 비디오 품질을 제공 할뿐만 아니라 무시할만한 시작 대기 시간으로 최대 40 FPS에서 512x512의 온라인 세대를 지원합니다.그것은 인간의 대화 행동을 모방하는 생명과 같은 아바타와 실시간 참여를위한 길을 열어줍니다.",2024.04.16,Sicheng Xu&&Guojun Chen&&Yu-Xiao Guo&&Jiaolong Yang&&Chong Li&&Zhenyu Zang&&Yizhong Zhang&&Xin Tong&&Baining Guo,arxiv,https://arxiv.org/abs/2404.10667
Long-form music generation with latent diffusion,음악을위한 오디오 기반 생성 모델은 최근에 큰 진전을 보였지만 지금까지 일관된 음악 구조로 전장 음악 트랙을 제작하지 못했습니다.우리는 긴 시간적 맥락에 대한 생성 모델을 훈련함으로써 최대 4M45의 긴 형식 음악을 제작할 수 있음을 보여줍니다.우리의 모델은 고도로 샘플링 된 연속 잠재적 표현 (21.5Hz의 잠재 속도)에서 작동하는 확산 변환기로 구성됩니다.오디오 품질 및 프롬프트 정렬에 대한 지표에 따라 최첨단 세대를 얻고 주관적인 테스트는 코 히어 런트 구조를 가진 전장 음악을 생성한다는 것을 보여줍니다.,2024.04.16,Zach Evans&&Julian D. Parker&&CJ Carr&&Zack Zukowski&&Josiah Taylor&&Jordi Pons,arxiv,https://arxiv.org/abs/2404.10301
MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation,"우리는 텍스트-이미지 확산 모델의 개인화를위한 새로운 아키텍처, MOA (Mix-of-Of-Intention)를 소개합니다.LLM (Lange Language Models)에 사용 된 혼합 운동 메커니즘에서 영감을 얻은 MOA는 개인화 된 지점과 비 개인화 된 사전 지점의 두주의 경로 사이의 생성 워크로드를 배포합니다.MOA는 이전 지점에서주의 레이어를 고정하여 원래 모델의 이전 모델을 유지하도록 설계되었으며, 이전 지점에서 생성 된 레이아웃 및 컨텍스트에 피사체를 포함시키는 개인화 된 지점과 함께 생성 프로세스에 최소한으로 개입합니다.새로운 라우팅 메커니즘은 이들 분기를 가로 지르는 각 층의 픽셀 분포를 관리하여 개인화되고 일반적인 컨텐츠 생성의 혼합을 최적화합니다.일단 훈련을 받으면 MOA는 원래 모델에 의해 생성 된 것만 큼 다양한 구성과 상호 작용을 갖는 여러 과목을 특징으로하는 고품질의 개인화 된 이미지를 촉진합니다.결정적으로, MOA는 모델의 기존 기능과 새로 증강 된 개인화 된 개입 사이의 구별을 향상시켜 이전에 달성 할 수 없었던보다 분리 된 주제-컨텍스트 제어를 제공합니다.프로젝트 페이지 :이 HTTPS URL",2024.04.17,Kuan-Chieh Wang&&Daniil Ostashev&&Yuwei Fang&&Sergey Tulyakov&&Kfir Aberman,arxiv,https://arxiv.org/abs/2404.11565
Dynamic Typography: Bringing Text to Life via Video Diffusion Prior,"텍스트 애니메이션은 표현적인 매체 역할을하며, 정적 커뮤니케이션을 감정을 불러 일으키고 의미를 강조하며 매력적인 이야기를 구성하는 움직임으로 단어를 주입하여 정적 커뮤니케이션을 역동적 인 경험으로 변형시킵니다.의미 적으로 인식하는 애니메이션을 제작하는 것은 그래픽 디자인 및 애니메이션에 대한 전문 지식을 요구하는 중대한 과제를 제기합니다.우리는 두 가지 도전적인 작업을 결합한 ""Dynamic Typography""라는 자동화 된 텍스트 애니메이션 체계를 제시합니다.그것은 의미 론적 의미를 전달하기 위해 글자를 변형시키고 사용자 프롬프트를 기반으로 생생한 움직임에 주입합니다.우리의 기술은 벡터 그래픽 표현과 엔드 투 엔드 최적화 기반 프레임 워크를 활용합니다.이 프레임 워크는 신경 변위 필드를 사용하여 글자를 기본 모양으로 변환하고 프레임당 모션을 적용하여 의도 된 텍스트 개념과 일관성을 장려합니다.모양 보존 기술과 지각 손실 정규화는 애니메이션 프로세스 전반에 걸쳐 가독성과 구조적 무결성을 유지하기 위해 사용됩니다.우리는 다양한 텍스트-비디오 모델에서 접근 방식의 일반화 가능성을 보여주고 별도의 작업을 구성 할 수있는 기준선 방법에 비해 엔드 투 엔드 방법론의 우수성을 강조합니다.양적 및 질적 평가를 통해, 우리는 가독성을 유지하면서 사용자 프롬프트를 충실하게 해석하는 일관된 텍스트 애니메이션을 생성하는 데있어 프레임 워크의 효과를 보여줍니다.우리의 코드는 다음과 같습니다.이 HTTPS URL.",2024.04.17,Zichen Liu&&Yihao Meng&&Hao Ouyang&&Yue Yu&&Bolin Zhao&&Daniel Cohen-Or&&Huamin Qu,arxiv,https://arxiv.org/abs/2404.11614
"Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models","REKA가 처음부터 훈련 한 일련의 강력한 멀티 모달 언어 모델 인 Reka Core, Flash 및 Edge를 소개합니다.REKA 모델은 텍스트, 이미지, 비디오 및 오디오 입력으로 처리 및 이유를 처리 할 수 있습니다.이 기술 보고서는 이러한 모델 중 일부 교육 세부 사항에 대해 설명하고 포괄적 인 평가 결과를 제공합니다.우리는 REKA Edge와 REKA Flash가 최첨단 작가 일뿐 만 아니라 훨씬 더 큰 모델을 능가하여 각 컴퓨팅 클래스에 대한 규모의 값을 전달 함을 보여줍니다.한편, 우리의 가장 유능하고 가장 큰 모델 인 REKA Core는 자동 평가와 맹인 인간 평가 모두에서 최고의 프론티어 모델에 접근합니다.벤치 마크 (예 : MMMU, vqav2)에 대한 이미지 질문에 대한 Core는 GPT4-V와 경쟁적으로 수행합니다.한편, 멀티 모달 채팅에서 Core는 블라인드 타사 휴먼 평가 설정에서 두 번째로 선호되는 모델로 순위를 매 깁니다.텍스트 벤치 마크에서 Core는 잘 정립 된 벤치 마크 세트 (예 : MMLU, GSM8K)에서 다른 프론티어 모델과 경쟁적으로 수행 할뿐만 아니라 인간 평가에서 GPT4-0613을 능가합니다.비디오 질문 답변 (Perception-Test)에서 Core는 Gemini Ultra보다 성능이 우수합니다.이 모델은 HTTP URL에서 생산으로 배송됩니다.비 체리 선택한 질적 사례의 쇼케이스는 HTTP URL에서도 찾을 수 있습니다.",2024.04.18,Reka Team&&Aitor Ormazabal&&Che Zheng&&Cyprien de Masson d'Autume&&Dani Yogatama&&Deyu Fu&&Donovan Ong&&Eric Chen&&Eugenie Lamprecht&&Hai Pham&&Isaac Ong&&Kaloyan Aleksiev&&Lei Li&&Matthew Henderson&&Max Bain&&Mikel Artetxe&&Nishant Relan&&Piotr Padlewski&&Qi Liu&&Ren Chen&&Samuel Phua&&Yazheng Yang&&Yi Tay&&Yuqi Wang&&Zhongkai Zhu&&Zhihui Xie,arxiv,https://arxiv.org/abs/2404.12387
BLINK: Multimodal Large Language Models Can See but Not Perceive,"우리는 다른 평가에서 찾을 수없는 핵심 시각적 지각 능력에 중점을 둔 멀티 모달 언어 모델 (LLMS)의 새로운 벤치 마크 인 Blink를 소개합니다.대부분의 깜박임 작업은 ""깜박임 내에서""인간이 해결할 수 있습니다 (예 : 상대 깊이 추정, 시각적 서신, 법의학 탐지 및 다중 뷰 추론).그러나 우리는 이러한 인식 의료 작업이 자연 언어를 통한 중재에 저항하기 때문에 현재의 다중 모드 LLM에 중대한 어려움을 겪고 있음을 발견했습니다.깜박임 개혁 14 클래식 컴퓨터 비전 작업을 단일 또는 여러 이미지 및 시각적 프롬프트와 짝을 이루는 3,807 개의 객관식 질문으로인간은 평균적으로 95.70% 정확도를 얻는 반면, 기존의 멀티 모달 LLM에는 깜박임이 놀랍게도 어려운 일입니다. 가장 성능이 좋은 GPT-4V와 Gemini조차도 51.26% 및 45.72%의 정확도를 달성합니다.이러한 인식 능력은 최근 다중 모드 LLM에서 ""등장""하지 않았다.우리의 분석은 또한 전문 CV 모델이 이러한 문제를 훨씬 더 잘 해결할 수 있으며 향후 개선을위한 잠재적 경로를 제안합니다.우리는 깜박임이 멀티 모달 LLM이 인간 수준의 시각적 인식을 따라 잡을 수 있도록 커뮤니티를 자극 할 것이라고 생각합니다.",2024.04.18,Xingyu Fu&&Yushi Hu&&Bangzheng Li&&Yu Feng&&Haoyu Wang&&Xudong Lin&&Dan Roth&&Noah A. Smith&&Wei-Chiu Ma&&Ranjay Krishna,arxiv,https://arxiv.org/abs/2404.12390
Introducing v0.5 of the AI Safety Benchmark from MLCommons,"이 백서에서는 MLCommons AI Safety Working Group이 작성한 AI 안전 벤치 마크의 V0.5를 소개합니다.AI 안전 벤치 마크는 채팅 조정 언어 모델을 사용하는 AI 시스템의 안전 위험을 평가하도록 설계되었습니다.우리는 벤치 마크를 지정하고 구성하는 원칙적 접근법을 소개합니다. v0.5의 경우 단일 사용 사례 (영어로 된 일반 목적 조수와의 성인 채팅)와 제한된 페르소나 세트 (예 : 일반 사용자, 악의적 인 악의적 인) 만 포함합니다.사용자 및 취약한 사용자).우리는 13 개의 위험 카테고리의 새로운 분류법을 만들었으며 그 중 7 개는 V0.5 벤치 마크에서 테스트를 받았습니다.우리는 2024 년 말까지 AI 안전 벤치 마크의 버전 1.0을 출시 할 계획입니다. V1.0 벤치 마크는 AI 시스템의 안전에 대한 의미있는 통찰력을 제공 할 것입니다.그러나 V0.5 벤치 마크를 사용하여 AI 시스템의 안전을 평가해서는 안됩니다.우리는 V0.5의 한계, 결함 및 도전을 완전히 문서화하고자했습니다.이 AI 안전 벤치 마크의 V0.5 릴리스에는 (1) 사용 사례, 테스트중인 시스템 유형 (SUT), 언어 및 컨텍스트, 페르소나, 테스트 및 테스트 항목으로 구성된 벤치 마크를 지정하고 구성하는 원칙적 접근 방식이 포함됩니다.;(2) 정의 및 하위 범주가있는 13 개의 위험 범주의 분류;(3) 7 개의 위험 범주에 대한 테스트, 각각 고유 한 테스트 항목 세트, 즉 프롬프트로 구성됩니다.총 43,090 개의 테스트 항목이 있으며,이 테스트 항목은 템플릿으로 만들었습니다.(4) 벤치 마크에 대한 AI 시스템에 대한 등급 시스템;(5) 벤치 마크에서 AI 시스템의 안전을 평가하는 데 사용할 수있는 ModelBench라는 공개적으로 사용 가능한 플랫폼 및 다운로드 가능한 도구;(6) 공개적으로 사용할 수있는 수십 개 이상의 채팅 조정 언어 모델의 성능을 벤치마킹하는 예제 평가 보고서;(7) 벤치 마크에 대한 테스트 사양.",2024.04.18,Bertie Vidgen&&Adarsh Agrawal&&Ahmed M. Ahmed&&Victor Akinwande&&Namir Al-Nuaimi&&Najla Alfaraj&&Elie Alhajjar&&Lora Aroyo&&Trupti Bavalatti&&Borhane Blili-Hamelin&&Kurt Bollacker&&Rishi Bomassani&&Marisa Ferrara Boston&&Siméon Campos&&Kal Chakra&&Canyu Chen&&Cody Coleman&&Zacharie Delpierre Coudert&&Leon Derczynski&&Debojyoti Dutta&&Ian Eisenberg&&James Ezick&&Heather Frase&&Brian Fuller&&Ram Gandikota&&Agasthya Gangavarapu&&Ananya Gangavarapu&&James Gealy&&Rajat Ghosh&&James Goel&&Usman Gohar&&Sujata Goswami&&Scott A. Hale&&Wiebke Hutiri&&Joseph Marvin Imperial&&Surgan Jandial&&Nick Judd&&Felix Juefei-Xu&&Foutse Khomh&&Bhavya Kailkhura&&Hannah Rose Kirk&&Kevin Klyman&&Chris Knotz&&Michael Kuchnik&&Shachi H. Kumar&&Chris Lengerich&&Bo Li&&Zeyi Liao&&Eileen Peters Long&&Victor Lu&&Yifan Mai&&Priyanka Mary Mammen&&Kelvin Manyeki&&Sean McGregor&&Virendra Mehta&&Shafee Mohammed&&Emanuel Moss&&Lama Nachman&&Dinesh Jinenhally Naganna&&Amin Nikanjam&&Besmira Nushi&&Luis Oala&&Iftach Orr&&Alicia Parrish&&Cigdem Patlak&&William Pietri&&Forough Poursabzi-Sangdeh&&Eleonora Presani&&Fabrizio Puletti&&Paul Röttger&&Saurav Sahay&&Tim Santos&&Nino Scherrer&&Alice Schoenauer Sebag&&Patrick Schramowski&&Abolfazl Shahbazi&&Vin Sharma&&Xudong Shen&&Vamsi Sistla&&Leonard Tang&&Davide Testuggine&&Vithursan Thangarasa&&Elizabeth Anne Watkins&&Rebecca Weiss&&Chris Welty&&Tyler Wilbers&&Adina Williams&&Carole-Jean Wu&&Poonam Yadav&&Xianjun Yang&&Yi Zeng&&Wenhui Zhang&&Fedor Zhdanov&&Jiacheng Zhu&&Percy Liang&&Peter Mattson&&Joaquin Vanschoren,arxiv,https://arxiv.org/abs/2404.12241
Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment,"인간 주석 선호도 데이터를 기반으로 언어 모델 (LMS)을 정렬하는 것은 실용적이고 성능있는 LM 기반 시스템을 얻는 데 중요한 단계입니다.그러나 다국어 적 인간 선호 데이터는 규모로 얻기가 어렵 기 때문에이 프레임 워크를 다양한 언어로 확장하기가 어렵습니다.이 작업에서는 제로 샷 교차 언어 정렬에 대한 간단한 접근 방식을 평가합니다. 여기서 보상 모델은 하나의 소스 언어로 선호도 데이터에 대해 교육을 받고 다른 대상 언어에 직접 적용됩니다.요약 및 개방형 대화 상자 생성에 따라, 우리는이 방법이 인간 평가를 포함하여 포괄적 인 평가 설정에서 일관되게 성공했음을 보여줍니다. 교차 언어 정렬 된 모델은 최대 70%의 평가 인스턴스에 대한 조정되지 않은 모델보다 인간이 선호합니다.또한 다른 언어 보상 모델이 때때로 같은 언어 보상 모델보다 더 나은 정렬 모델을 생성한다는 것을 알게됩니다.또한 감독 된 미세 조정에 대한 언어 별 데이터가 없을 때 모범 사례를 식별합니다.",2024.04.18,Zhaofeng Wu&&Ananth Balashankar&&Yoon Kim&&Jacob Eisenstein&&Ahmad Beirami,arxiv,https://arxiv.org/abs/2404.12318
"Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing","다양한 작업에 대한 대형 언어 모델 (LLM)의 인상적인 기능에도 불구하고 여전히 복잡한 추론 및 계획과 관련된 시나리오와 싸우고 있습니다.최근의 작업은 고급 프롬프트 기술과 LLM의 추론 능력을 증대하기 위해 고품질 데이터로 미세 조정의 필요성을 제안했습니다.그러나 이러한 접근 방식은 본질적으로 데이터 가용성과 품질에 의해 제한됩니다.이에 비추어, 자체 수정과 자기 학습은 LLM이 생산량을 개선하고 자기 평가 보상으로부터 배울 수있는 전략을 사용하여 실행 가능한 솔루션으로 등장합니다.그러나, 특히 복잡한 추론 및 계획 과제에서 반응을 자체 정제하는 데있어서 LLM의 효능은 여전히 모호합니다.이 논문에서는 LLMS (Monte Carlo Tree Search)를 LLM과 통합하여 자체 개선 루프를 설정하여 추가 주석없이 LLM의 기능을 향상시키는 LLMS의 자체 개선을위한 Alphallm을 소개합니다.Alphago의 성공으로 인한 영감을 얻은 Alphallm은 MCT를 LLM과 LLM과 결합하여 데이터 부족, 언어 작업의 광대 한 검색 공간 및 언어 작업의 피드백의 주관적 특성을 포함한 독특한 과제를 해결합니다.Alphallm은 프롬프트 합성 구성 요소, 언어 작업에 맞게 조정 된 효율적인 MCTS 접근 및 정확한 피드백을위한 비평가 모델 트리오로 구성됩니다.수학적 추론 작업의 실험 결과는 Alphallm이 추가 주석없이 LLM의 성능을 크게 향상시켜 LLM의 자기 개선 가능성을 보여줍니다.",2024.04.18,Ye Tian&&Baolin Peng&&Linfeng Song&&Lifeng Jin&&Dian Yu&&Haitao Mi&&Dong Yu,arxiv,https://arxiv.org/abs/2404.12253
AniClipart: Clipart Animation with Text-to-Video Priors,"사전 제작 된 그래픽 아트 양식 인 Clipart는 시각적 컨텐츠를 설명하는 편리하고 효율적인 방법을 제공합니다.정적 클립 아트 이미지를 모션 시퀀스로 변환하는 전통적인 워크 플로우는 힘들고 시간이 많이 걸리며 리깅, 주요 애니메이션 및 중간에 수많은 복잡한 단계를 포함합니다.최근 텍스트-비디오 세대의 발전은이 문제를 해결하는 데 큰 잠재력을 가지고 있습니다.그럼에도 불구하고 텍스트-비디오 생성 모델을 직접 적용하면 클립 아트 이미지의 시각적 정체성을 유지하거나 만화 스타일 모션을 생성하기 위해 고군분투하여 불만족스러운 애니메이션 결과를 초래합니다.이 논문에서는 정적 클립 아트 이미지를 텍스트-비디오 사전으로 안내하는 고품질 모션 시퀀스로 변환하는 시스템 인 Aniclipart를 소개합니다.만화 스타일과 부드러운 움직임을 생성하기 위해 먼저 클립 아트 이미지의 키 포인트 위의 베지어 곡선을 모션 정규화 형태로 정의합니다.그런 다음 VSDS (Video Score Distillation Sampling) 손실을 최적화하여 키패 인의 모션 궤적을 제공 한 텍스트 프롬프트와 정렬합니다.차별화 가능한 rigids as-rossible 형태 변형 알고리즘을 사용하면 변형 강성을 유지하면서 우리의 방법은 엔드 투 엔드 최적화를 최적화 할 수 있습니다.실험 결과에 따르면 제안 된 aniclipart는 텍스트 비디오 정렬, 시각적 정체성 보존 및 모션 일관성 측면에서 기존 이미지 간 비디오 생성 모델보다 지속적으로 성능이 뛰어납니다.또한, 우리는 aniclipart의 다양성을 적응하여 계층화 된 애니메이션과 같은 광범위한 애니메이션 형식을 생성하여 토폴로지를 변경할 수 있도록합니다.",2024.04.18,Ronghuan Wu&&Wanchao Su&&Kede Ma&&Jing Liao,arxiv,https://arxiv.org/abs/2404.12347
EdgeFusion: On-Device Text-to-Image Generation,"텍스트-이미지 생성에 대한 안정적인 확산 (SD)의 집중적 인 계산 부담은 실제 적용에 중요한 장애물을 제기합니다.이 과제를 해결하기 위해 최근의 연구는 잠재적 일관성 모델 (LCM)과 같은 샘플링 단계를 줄이고 가지 치기 및 지식 증류를 포함한 아키텍처 최적화를 사용하는 방법에 중점을 둡니다.기존 접근 방식에서 발산으로, 우리는 소형 SD 변형 인 BK-SDM으로 독특하게 시작합니다.일반적으로 사용되는 크롤링 된 데이터 세트로 LCM을 BK-SDM에 직접 적용하면 불만족스러운 결과가 생성됩니다.(1) 주요 생성 모델에서 고품질의 이미지 텍스트 쌍을 활용하고 (2) LCM에 맞게 조정 된 고급 증류 프로세스 설계의 두 가지 전략을 개발하게됩니다.우리는 양자화, 프로파일 링 및 사후 배치에 대한 철저한 탐색을 통해 리소스 제한 에지 장치에서 1 초 미만의 대기 시간을 두 단계로 단 2 단계로 빠르게 생성합니다.",2024.04.18,Thibault Castells&&Hyoung-Kyu Song&&Tairen Piao&&Shinkook Choi&&Bo-Kyeong Kim&&Hanyoung Yim&&Changgwun Lee&&Jae Gon Kim&&Tae-Ho Kim,arxiv,https://arxiv.org/abs/2404.11925
TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding,"최근 긴 콘텐츠 생성에 널리 배포 된 대형 언어 모델 (LLM)으로 인해 효율적인 장기 시퀀스 추론 지원에 대한 수요가 증가하고 있습니다.그러나 재 계산을 피하기 위해 저장된 키 값 (KV) 캐시는 시퀀스 길이로 크기가 선형으로 증가함으로써 중요한 병목 현상으로 등장했습니다.LLM의 자동 중심 특성으로 인해 전체 KV 캐시가 생성 된 모든 토큰에 대해로드되어 계산 코어의 활용도가 낮고 대기 시간이 높아집니다.이 문제를 완화하기 위해 KV 캐시에 대한 다양한 압축 방법이 제안되었지만, 생성 품질의 저하로 고통 받고 있습니다.우리는 긴 시퀀스 생성에 확장 가능한 계층 적 투기 디코딩 시스템 인 Triforce를 소개합니다.이 접근법은 원래 모델 가중치와 동적 희소 KV 캐시를 초안 모델로 검색하여 계층 구조의 중간 층으로 사용하며 드 래프팅 대기 시간을 줄이기 위해 더 작은 모델에 의해 추측됩니다.Triforce는 LLAMA2-7B-128K의 인상적인 속도를 촉진 할뿐만 아니라 최대 2.31 \ Timeson A A100 GPU를 달성 할뿐만 아니라 더 긴 컨텍스트를 처리 할 때 확장 성을 보여줍니다.2 개의 RTX 4090 GPU의 오프로드 설정의 경우 Triforce는 A100의 자동 간주 기준선보다 0.108S/Token \ unicode {x2014}를 달성합니다.또한 Triforce는 단일 RTX 4090 GPU에서 4.86 \ Timesthan DeepSpeed-Zero-inference를 수행합니다.Triforce의 견고성은 다양한 온도에서 지속적으로 뛰어난 성능으로 강조됩니다.이 코드는 https url에서 사용할 수 있습니다.",2024.04.18,Hanshi Sun&&Zhuoming Chen&&Xinyu Yang&&Yuandong Tian&&Beidi Chen,arxiv,https://arxiv.org/abs/2404.11912
MeshLRM: Large Reconstruction Model for High-Quality Mesh,"우리는 1 초 이내에 단지 4 개의 입력 이미지에서 고품질 메쉬를 재구성 할 수있는 새로운 LRM 기반 접근법 인 MeshlRM을 제안합니다.NERF 기반 재구성에 중점을 둔 이전의 대형 재구성 모델 (LRM)과는 달리, MESHLRM은 LRM 프레임 워크 내에서 차별화 가능한 메쉬 추출 및 렌더링을 통합합니다.이를 통해 메쉬 렌더링으로 미리 훈련 된 NERF LRM을 미세 조정하여 엔드 투 엔드 메쉬 재구성이 가능합니다.또한 이전 LRM의 여러 복잡한 디자인을 단순화하여 LRM 아키텍처를 향상시킵니다.Meshlrm의 NERF 초기화는 저해상도 및 고해상도 이미지로 순차적으로 훈련됩니다.이 새로운 LRM 교육 전략은 상당히 빠른 수렴을 가능하게하여 컴퓨팅이 적음으로써 더 나은 품질로 이어집니다.우리의 접근 방식은 희소 뷰 입력에서 최첨단 메쉬 재구성을 달성하고 텍스트-3D 및 단일 이미지에서 3D 세대를 포함한 많은 다운 스트림 응용 프로그램을 허용합니다.프로젝트 페이지 :이 HTTPS URL",2024.04.18,Xinyue Wei&&Kai Zhang&&Sai Bi&&Hao Tan&&Fujun Luan&&Valentin Deschaintre&&Kalyan Sunkavalli&&Hao Su&&Zexiang Xu,arxiv,https://arxiv.org/abs/2404.12385
"OpenBezoar: Small, Cost-Effective and Open Models Trained on Mixes of Instruction Data","다양한 다운 스트림 작업을위한 미세 조정 사전 RLM은 놀라운 성공을 보여 주었고 학계와 실무자 모두의 관심을 끌었습니다.이러한 미세 조정 된 LLM이 인간 선호도와 일치하도록하기 위해 RLHF 및 DPO와 같은 기술이 등장했습니다.동시에, 모델의 더 작은 매개 변수 수에 대한 관심이 높아지고 있습니다.이 작업에서 Openllama 3BV2를 기본 모델로 사용하여 OpenBezoar 모델 제품군을 미세 조정하는 데 사용되는 레시피를 설명합니다.이 레시피에서 : 우리는 먼저 3 가지 체계에서 Falcon-40B 모델의 개방적이고 상업적으로 비 제한적인 명령 미세 조정 변형을 사용하여 Lamini-LM, Wizardlm/Evol-Instruct (데이터 사역)-Dolly-15K는 종자 데이터 세트로서의 Dolly-15K와 ORCA (FLAN 컬렉션을 종자 데이터 세트로), GPT-4를 인간 프록시로 사용하여 이들 세대를 필터링합니다.그런 다음 각 체계마다 순차적으로 비용 효율적인 Qlora 기반 감독 미세 조정을 수행합니다.결과 체크 포인트는 HH-RLHF 데이터 세트의 서브 세트로 더 미세 조정되어 DPO 손실을 사용하기 전에 분포 이동을 최소화하여 최종 체크 포인트를 얻습니다.평가는 LM Eval Harness Tasks/Metrics와 Claude 2.1이있는 ""LLM-as-A-A-Judge""프레임 워크를 사용하여 MT-Bench에서 이루어지며 OpenBezoar-HH-RLHF-DPO를 발견했습니다.""3B 매개 변수 척도에서 많은 모델보다 우수한 성능을 보여 주며 Huggingf""OpenBezoar-Sft"", ""OpenBezoar-HH-RlHF-Sft"", ""OpenBezoar-HH-RlHf-DPO""체크 포인트와 함께 https https https Url에서 https Urland의 포옹에 대한 생성 된 데이터 세트와 함께 https url.",2024.04.18,Chandeepa Dissanayake&&Lahiru Lowe&&Sachith Gunasekara&&Yasiru Ratnayake,arxiv,https://arxiv.org/abs/2404.12195
Does Gaussian Splatting need SFM Initialization?,"3D 가우시안 플래팅은 최근 고품질 결과와 하드웨어 래스터 화와의 호환성으로 인해 장면 재건 및 신규 뷰 합성을위한 다목적이고 효과적인 방법으로 받아 들여졌습니다.장점에도 불구하고 Gaussian Splatting의 고품질 포인트 클라우드 초기화 (SFM) 알고리즘에 의한 고품질 포인트 클라우드 초기화는 극복해야 할 중요한 제한입니다.이를 위해, 우리는 가우시안 스플릿을위한 다양한 초기화 전략을 조사하고 NERF (Neural Radiance Fields)의 부피 재구성을 사용하여 SFM 데이터에 대한 의존성을 우회하는 방법을 탐구합니다.우리의 연구 결과는 신중하게 설계된 경우 무작위 초기화가 훨씬 더 잘 수행 될 수 있으며, 저렴한 NERF 모델의 개선 된 초기화 전략과 구조 증류의 조합을 사용함으로써, 동등한 결과를 얻거나 때로는 획득 한 결과와 동등한 결과를 얻을 수 있음을 보여줍니다.SFM 초기화에서.",2024.04.18,Yalda Foroutan&&Daniel Rebain&&Kwang Moo Yi&&Andrea Tagliasacchi,arxiv,https://arxiv.org/abs/2404.12547
How Far Can We Go with Practical Function-Level Program Repair?,"최근에 수리 성능을 향상시키기 위해 LLM (Lange Language Models)을 기반으로 한 다중 자동 프로그램 수리 (APR) 기술이 제안되었습니다.이러한 기술은 주로 단일 라인 또는 덩어리 수준의 수리에 중점을두고 있지만, 수리 작업 범위와 비용이 많이 드는 명령문 수준의 결함 현지화로 인해 실제 응용 프로그램에서 상당한 문제에 직면 해 있습니다.그러나 전체 버기 함수를 수정하기위한 APR 작업 범위를 확대하고 비용 효율적인 기능 수준 결함 위치 만 필요로하는보다 실용적인 기능 수준 APR은 노출되지 않은 상태로 남아 있습니다.이 논문에서는 소수의 학습 메커니즘과 보조 수리 관련 정보의 효과 조사를 포함하여 LLM 기반 기능 수준 APR에 대한 첫 번째 포괄적 인 연구를 수행합니다.구체적으로, 우리는 6 개의 광범위한 LLM을 채택하고 결함 4J 1.2 및 2.0 데이터 세트 모두에서 벤치 마크를 구성합니다.우리의 연구는 제로 샷 학습을 가진 LLM이 이미 강력한 기능 수준의 APR 기술이며, 소수의 학습 메커니즘을 적용하면 다른 수리 성능을 초래한다는 것을 보여줍니다.또한 보조 수리 관련 정보를 LLM에 직접 적용하면 기능 수준 수리 성능이 크게 증가합니다.우리의 연구 결과에서 영감을 얻은 우리는 LLM 기반 기능 수준 APR 기술, 즉 SREPAIR를 제안합니다. 즉, 수리 성능 발전을위한 보조 수리 관련 정보의 힘을 활용하기 위해 듀얼 -LLM 프레임 워크를 채택하는 SREPAIR를 제안합니다.평가 결과는 SREPAIR가 DefectS4J 데이터 세트에서 300 개의 단일 기능 버그를 올바르게 수정하여 비용이 많이 드는 명령문 수준 결함 위치 정보가 필요하지 않고 이전의 모든 APR 기술을 85%이상 능가 할 수 있음을 보여줍니다.또한 Srepair는 DefectS4J 데이터 세트에서 32 개의 다기능 버그를 성공적으로 수정합니다.",2024.04.19,Jiahong Xiang&&Xiaoyang Xu&&Fanchu Kong&&Mingyuan Wu&&Haotian Zhang&&Yuqun Zhang,arxiv,https://arxiv.org/abs/2404.12833
AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation,"웹 자동화는 일반적인 웹 동작을 자동화하고 운영 효율성을 높이며 수동 개입의 필요성을 줄임으로써 복잡한 웹 작업을 수행하는 중요한 기술입니다.래퍼와 같은 전통적인 방법은 새로운 웹 사이트에 직면 할 때 적응성과 확장 성이 제한되어 있습니다.반면, LLMS (Lange World 시나리오에서 성능이 좋지 않은 성능과 재사용 성을 보여줍니다.이 작업에서는 수직 정보 웹 페이지에 대한 크롤러 생성 작업과 LLM을 크롤러와 결합하는 패러다임을 소개하여 크롤러가 다양한 웹 환경을보다 효율적으로 처리 할 수 있도록 도와줍니다.우리는 진보적 인 이해를 위해 HTML의 계층 구조를 활용하는 2 단계 프레임 워크 인 Autocrawler를 제안합니다.하향식 및 계산 작업을 통해 Autocrawler는 잘못된 행동을 통해 배울 수 있으며 더 나은 액션 생성을 위해 HTML을 지속적으로 정리할 수 있습니다.우리는 여러 LLM으로 포괄적 인 실험을 수행하고 프레임 워크의 효과를 보여줍니다.이 백서의 자료는 \ url {this https url}에서 찾을 수 있습니다.",2024.04.19,Wenhao Huang&&Chenghao Peng&&Zhixu Li&&Jiaqing Liang&&Yanghua Xiao&&Liqian Wen&&Zulong Chen,arxiv,https://arxiv.org/abs/2404.12753
TextSquare: Scaling up Text-Centric Visual Instruction Tuning,"텍스트 중심의 시각적 질문 응답 (VQA)은 멀티 모달 대형 언어 모델 (MLLM)의 개발로 큰 진전을 이루었지만, 오픈 소스 모델은 여전히 GPT4V 및 gemini와 같은 주요 모델에 미치지 못하며 부분적으로는 광범위하고 높은 부족으로 인해 여전히 광범위하고 높은 모델에 미치지 못합니다.-품질 지침 튜닝 데이터.이를 위해, 우리는 폐쇄 소스 MLLM을 사용하여 생성되는 대규모 고품질의 명령 조정 데이터 세트 인 Square-10m을 생성하기위한 새로운 접근법을 소개합니다.정사각형이라고 불리는 데이터 구성 프로세스는 자체 질문, 응답, 추론 및 평가의 네 가지 단계로 구성됩니다.Square-10M을 사용한 우리의 실험은 세 가지 주요 결과를 가져 왔습니다. 1) 우리의 모델, Textsquare는 이전의 최신 텍스트 중심 MLLM을 상당히 능가하고 OCRBENCH (62.2%)에 새로운 표준을 설정합니다.10 개의 텍스트 중심 벤치 마크 중 6 개에서 GPT4V 및 Gemini와 같은 최상위 모델을 능가합니다.2) 또한, 우리는 특정 질문에 대한 포괄적 인 맥락 통찰력을 제공하는 데있어 VQA 추론 데이터의 중요한 역할을 보여줍니다.이것은 정확성을 향상시킬뿐만 아니라 환각을 크게 완화시킵니다.구체적으로, Textsquare는 4 개의 일반 VQA 및 환각 평가 데이터 세트에서 평균 75.1%를 기록하여 이전 최신 모델보다 우수합니다.3) 특히, 텍스트 중심 VQA 데이터 세트 스케일링에서 관찰 된 현상은 생생한 패턴을 나타냅니다. 명령어 튜닝 데이터 볼륨의 지수 증가는 모델 성능의 개선에 직접 비례하여 데이터 세트 규모의 필요성과 고품질의 고품질을 검증합니다.제곱 -10m.",2024.04.19,Jingqun Tang&&Chunhui Lin&&Zhen Zhao&&Shu Wei&&Binghong Wu&&Qi Liu&&Hao Feng&&Yang Li&&Siqi Wang&&Lei Liao&&Wei Shi&&Yuliang Liu&&Hao Liu&&Yuan Xie&&Xiang Bai&&Can Huang,arxiv,https://arxiv.org/abs/2404.12803
PhysDreamer: Physics-Based Interaction with 3D Objects via Video Generation,"현실적인 객체 상호 작용은 몰입 형 가상 경험을 만드는 데 중요하지만 새로운 상호 작용에 대한 현실적인 3D 객체 역학을 종합하는 것은 여전히 중요한 도전입니다.무조건 또는 텍스트 조절 된 역학 생성과 달리, 액션 조건 역학은 물체의 물리적 재료 특성을 인식하고 객체 강성과 같은 이러한 특성에 대한 3D 모션 예측을 접지해야합니다.그러나 실제 물체에 대한 이러한 특성을 측정하는 것이 매우 어렵 기 때문에 물리적 재료 특성을 추정하는 것은 재료지면 데이터의 부족으로 인해 열린 문제입니다.우리는 비디오 생성 모델에서 배운 객체 역학 우선권을 활용하여 인터랙티브 역학으로 정적 3D 객체를 부여하는 물리 기반 접근법 인 Physdreamer를 제시합니다.이러한 우선권을 증류함으로써, Physdreamer는 외부 힘 또는 에이전트 조작과 같은 새로운 상호 작용에 대한 현실적인 객체 응답을 합성 할 수 있습니다.우리는 탄성 대상의 다양한 예에 대한 우리의 접근법을 보여주고 사용자 연구를 통해 합성 된 상호 작용의 현실주의를 평가합니다.Physdreamer는 정적 3D 객체가 물리적으로 그럴듯한 방식으로 대화식 자극에 동적으로 반응 할 수 있도록함으로써보다 매력적이고 현실적인 가상 경험을 향한 단계를 밟습니다.이 https URL의 프로젝트 페이지를 참조하십시오.",2024.04.19,Tianyuan Zhang&&Hong-Xing Yu&&Rundi Wu&&Brandon Y. Feng&&Changxi Zheng&&Noah Snavely&&Jiajun Wu&&William T. Freeman,arxiv,https://arxiv.org/abs/2404.13026
Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models,"우리는 접지되고 세밀한 시각적 지각 능력을 갖춘 멀티 모달 대형 언어 모델 (MLLM) 인 Groma를 소개합니다.전체적인 이미지 이해를 넘어서 Groma는 지역 캡션 및 시각적 접지와 같은 지역 수준의 작업에 능숙합니다.이러한 기능은 현지화 된 시각적 토큰 화 메커니즘에 구축되며, 여기서 이미지 입력이 관심 영역으로 분해 된 후 영역 토큰으로 인코딩됩니다.영역 토큰을 사용자 지침 및 모델 응답에 통합함으로써 Groma는 사용자 지정 영역 입력을 이해하고 텍스트 출력을 이미지에 접지 할 수 있습니다.게다가, Groma의 접지 채팅 능력을 향상시키기 위해, 우리는 강력한 GPT-4V 및 시각적 프롬프트 기술을 활용하여 시각적으로 접지 된 명령 데이터 세트를 선별합니다.Groma는 현지화를위한 언어 모델 또는 외부 모듈에 의존하는 MLLM과 비교하여 표준 참조 및 접지 벤치 마크에서 일관되게 성능을 보여 주며, 현지화를 이미지 토큰 화에 포함시키는 이점을 강조합니다.프로젝트 페이지 :이 https url.",2024.04.19,Chuofan Ma&&Yi Jiang&&Jiannan Wu&&Zehuan Yuan&&Xiaojuan Qi,arxiv,https://arxiv.org/abs/2404.13013
LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency,"쿼리 결과를 변경하지 않고 SQL 쿼리의 구조를 변경하여보다 효율적인 쿼리를 생성하는 것을 목표로하는 쿼리 다시 작성은 중요한 연구 문제였습니다.다시 쓰기 동안 다시 작성된 쿼리와 원래 쿼리 사이의 동등성을 유지하기 위해 기존 쿼리 다시 작성 메소드는 특정 다시 작성 규칙에 따라 항상 쿼리를 다시 작성합니다.그러나 일부 문제는 여전히 남아 있습니다.첫째, 최적의 선택 또는 일련의 재 작성 규칙을 찾는 기존 방법은 여전히 제한되어 있으며 프로세스는 항상 많은 리소스 비용이 듭니다.새로운 다시 쓰기 규칙을 발견하는 방법에는 일반적으로 구조적 논리 또는 광범위한 사용자 상호 작용의 복잡한 증거가 필요합니다.둘째, 현재 쿼리 재 작성 방법은 일반적으로 종종 정확하지 않은 DBMS 비용 추정기에 크게 의존합니다.이 논문에서는 LLM (Langues Rewrite 시스템에 대한 가능한 재 작성 규칙을 제안하기 위해 LLM)을 채택하여 LLM-R2라는 새로운 쿼리 재 작성 방법을 제안함으로써 이러한 문제를 해결합니다.재 작성 규칙을 권장하는 데있어 LLM의 추론 능력을 더욱 향상시키기 위해 커리큘럼의 대조적 모델을 교육하여 쿼리 표현을 배우고 LLM에 대한 효과적인 쿼리 데모를 선택합니다.실험 결과에 따르면 우리의 방법은 쿼리 실행 효율을 크게 향상시키고 기준 방법을 능가 할 수 있습니다.또한, 우리의 방법은 다양한 데이터 세트에서 높은 견고성을 누립니다.",2024.04.19,Zhaodonghui Li&&Haitao Yuan&&Huiming Wang&&Gao Cong&&Lidong Bing,arxiv,https://arxiv.org/abs/2404.12872
The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions,"오늘날의 LLM은 신속한 주사, 탈옥 및 기타 공격으로 인해 적대자가 자신의 악의적 인 프롬프트로 모델의 원래 지침을 덮어 쓸 수 있습니다.이 작업에서, 우리는 이러한 공격의 기초가되는 주요 취약점 중 하나는 LLM이 종종 시스템 프롬프트 (예 : 응용 프로그램 개발자의 텍스트)가 신뢰할 수없는 사용자 및 제 3 자의 텍스트와 동일한 우선 순위라고 생각한다는 것입니다.이를 해결하기 위해, 우리는 다른 우선 순위의 지시가 충돌 할 때 모델이 어떻게 행동 해야하는지 명시 적으로 정의하는 명령 계층 구조를 제안합니다.그런 다음 LLMS가 소외적 인 지시를 선택적으로 무시하도록 가르치는이 계층 적 지시를 보여주는 데이터 생성 방법을 제안합니다.우리는이 방법을 GPT-3.5에 적용하여 표준 기능에 최소한의 저하를 부과하면서 훈련 중에 보이지 않는 공격 유형의 경우에도 견고성이 크게 증가 함을 보여줍니다.",2024.04.19,Eric Wallace&&Kai Xiao&&Reimar Leike&&Lilian Weng&&Johannes Heidecke&&Alex Beutel,arxiv,https://arxiv.org/abs/2404.13208
Music Consistency Models,"일관성 모델은 효율적인 이미지/비디오 생성을 촉진하는 데 현저한 기능을 보여 주어 최소한의 샘플링 단계로 합성을 가능하게했습니다.확산 모델과 관련된 계산 부담을 완화하는 데 유리한 것으로 입증되었습니다.그럼에도 불구하고, 음악 생성에서 일관성 모델의 적용은 크게 탐구되지 않습니다.이 차이를 해결하기 위해 음악 일관성 모델 (\ texttt {musiccm})을 제시하는데, 이는 일관성 모델의 개념을 활용하여 음악 클립에 대한 멜 스피어 그램을 효율적으로 합성하여 고품질을 유지하면서 샘플링 단계 수를 최소화합니다.기존 텍스트-음악 확산 모델을 바탕으로 \ texttt {musiccm} 모델에는 일관성 증류 및 적대적 판별 자 훈련이 포함됩니다.또한, 우리는 여러 확산 프로세스를 공유 제약과 통합하여 확장 된 일관된 음악을 생성하는 것이 유리하다고 생각합니다.실험 결과는 계산 효율, 충실도 및 자연성 측면에서 모델의 효과를 보여줍니다.주목할만한, \ texttt {musiccm}은 단지 4 개의 샘플링 단계, 예를 들어 음악 클립의 분당 1 초에 불과 1 초에 불과한 원활한 음악 합성을 달성하여 실시간 응용 프로그램의 가능성을 보여줍니다.",2024.04.20,Zhengcong Fei&&Mingyuan Fan&&Junshi Huang,arxiv,https://arxiv.org/abs/2404.13358
AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs,"최근 LLM (Large Language Models)이 놀라운 성공을 거두었지만, 부적절하거나 유해한 콘텐츠를 생성하는 특정 탈옥 공격에 취약합니다.수동 레드 팀 밍은 그러한 탈옥을 일으키는 적대적인 프롬프트를 찾아야합니다 (예 :비효율적이고 시간이 많이 걸리는 주어진 지시에 접미사를 추가함으로써.반면, 자동 적대적 프롬프트 생성은 종종 당황 기반 필터로 쉽게 감지 할 수있는 의미 적으로 의미없는 공격으로 이어지거나 TargetLlm의 기울기 정보가 필요하거나 시간이 많이 걸리는 개별 최적화 프로세스로 인해 확장되지 않을 수 있습니다.공간.이 논문에서, 우리는 기존 최적화 기반 접근법보다 \ sim800 \ timesfaster 인 인간이 읽을 수있는 적대적 프롬프트를 생성하기 위해 Advprompter라는 다른 LLM을 사용하는 새로운 방법을 제시합니다.우리는 TargetLLM의 그라디언트에 액세스 할 필요가없는 새로운 알고리즘을 사용하여 AdvPrompter를 훈련시킵니다.이 과정은 두 단계를 번갈아 가며 (1) Advprompter 예측을 최적화하여 고품질 대상 적대 접미사 생성 및 (2) 생성 된 적대적 접미사와 Advprompter의 낮은 순위 미세 조정을 생성합니다.훈련 된 Advprompter는 입력 명령을 의미를 변경하지 않고 베일로 인한 접미사를 생성하여 TargetLlm이 유해한 반응을 줄 수 있도록 유혹됩니다.인기있는 오픈 소스 TargetLlms의 실험 결과는 Advbench 데이터 세트에서 최첨단 결과를 보여 주며 폐쇄 소스 블랙 박스 LLM API로 전송합니다.또한, 우리는 Advprompter에 의해 생성 된 합성 데이터 세트를 미세 조정함으로써 LLM이 성능, 즉 높은 MMLU 점수를 유지하면서 탈옥 공격에 대해보다 강력해질 수 있음을 보여줍니다.",2024.04.21,Anselm Paulus&&Arman Zharmagambetov&&Chuan Guo&&Brandon Amos&&Yuandong Tian,arxiv,https://arxiv.org/abs/2404.16873
Hyper-SD: Trajectory Segmented Consistency Model for Efficient Image Synthesis,"최근에, 일련의 확산 인식 증류 알고리즘이 확산 모델 (DMS)의 다중 단계 추론 프로세스와 관련된 계산 간접비를 완화하기 위해 나타났습니다.현재의 증류 기술은 종종 두 가지 뚜렷한 측면으로 이분법 화됩니다. i) ODE 궤적 보존;및 ii) ODE 궤적 개혁.그러나 이러한 접근법은 심각한 성능 저하 또는 도메인 교대로 어려움을 겪습니다.이러한 한계를 해결하기 위해, 우리는 ODE 궤적 보존 및 재구성의 장점을 상승적으로 합병하는 동시에, 스텝 압축 동안 거의 손이없는 성능을 유지하는 새로운 프레임 워크 인 Hyper-SD를 제안합니다.첫째, 우리는 사전 정의 된 시간 단계 세그먼트 내에서 일관된 증류를 점진적으로 수행하기 위해 궤적 세그먼트 세그먼트 일관성 증류를 도입하여, 이는 고차 관점에서 원래 ODE 궤적의 보존을 용이하게한다.둘째, 우리는 인간 피드백 학습을 통합하여 저 단계 제도에서 모델의 성능을 향상시키고 증류 과정에서 발생하는 성능 손실을 완화합니다.셋째, 점수 증류를 통합하여 모델의 저 단계 생성 기능을 더욱 향상시키고 모든 단계에서 추론 프로세스를 지원하기 위해 통합 LORA를 활용하려는 첫 번째 시도를 제공합니다.광범위한 실험 및 사용자 연구에 따르면 Hyper-SD는 SDXL 및 SD1.5에 대한 1 내지 8의 추론 단계에서 SOTA 성능을 달성한다는 것을 보여줍니다.예를 들어, Hyper-SDXL은 클립 점수에서 +0.68, 1 단계 추론에서 AES 점수에서 +0.51을 능가합니다.",2024.04.21,Yuxi Ren&&Xin Xia&&Yanzuo Lu&&Jiacheng Zhang&&Jie Wu&&Pan Xie&&Xing Wang&&Xuefeng Xiao,arxiv,https://arxiv.org/abs/2404.13686
Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,"우리는 3.3 조의 토큰으로 훈련 된 38 억 개의 매개 변수 언어 모델 인 Phi-3-Mini를 소개합니다.-3-MINI는 전화로 배치 될 정도로 작지만 MMLU에서 69%, MT-Bench에서 8.38)을 달성했습니다.이 혁신은 전적으로 우리의 교육을위한 데이터 세트에 있으며, 필터링 된 웹 데이터 및 합성 데이터로 구성된 PHI-2에 사용 된 것의 확장 버전 인 교육 버전에 있습니다.이 모델은 또한 견고성, 안전 및 채팅 형식을 위해 더욱 정렬됩니다.또한 Phi-3-Small 및 Phi-3-Medium이라는 4.8T 토큰을 위해 훈련 된 7B 및 14B 모델로 초기 매개 변수 스케일링 결과를 제공합니다.MMLU에서 78%, MT 벤치에서는 8.7 및 8.9).",2024.04.22,Marah Abdin&&Sam Ade Jacobs&&Ammar Ahmad Awan&&Jyoti Aneja&&Ahmed Awadallah&&Hany Awadalla&&Nguyen Bach&&Amit Bahree&&Arash Bakhtiari&&Harkirat Behl&&Alon Benhaim&&Misha Bilenko&&Johan Bjorck&&Sébastien Bubeck&&Martin Cai&&Caio César Teodoro Mendes&&Weizhu Chen&&Vishrav Chaudhary&&Parul Chopra&&Allie Del Giorno&&Gustavo de Rosa&&Matthew Dixon&&Ronen Eldan&&Dan Iter&&Amit Garg&&Abhishek Goswami&&Suriya Gunasekar&&Emman Haider&&Junheng Hao&&Russell J. Hewett&&Jamie Huynh&&Mojan Javaheripi&&Xin Jin&&Piero Kauffmann&&Nikos Karampatziakis&&Dongwoo Kim&&Mahoud Khademi&&Lev Kurilenko&&James R. Lee&&Yin Tat Lee&&Yuanzhi Li&&Chen Liang&&Weishung Liu&&Eric Lin&&Zeqi Lin&&Piyush Madan&&Arindam Mitra&&Hardik Modi&&Anh Nguyen&&Brandon Norick&&Barun Patra&&Daniel Perez-Becker&&Thomas Portet&&Reid Pryzant&&Heyang Qin&&Marko Radmilac&&Corby Rosset&&Sambudha Roy&&Olatunji Ruwase&&Olli Saarikivi&&Amin Saied&&Adil Salim&&Michael Santacroce&&Shital Shah&&Ning Shang&&Hiteshi Sharma&&Xia Song&&Masahiro Tanaka&&Xin Wang&&Rachel Ward&&Guanhua Wang&&Philipp Witte&&Michael Wyatt&&Can Xu&&Jiahang Xu&&Sonali Yadav&&Fan Yang&&Ziyi Yang&&Donghan Yu&&Chengruidong Zhang&&Cyril Zhang&&Jianwen Zhang&&Li Lyna Zhang&&Yi Zhang&&Yue Zhang&&Yunan Zhang&&Xiren Zhou,arxiv,https://arxiv.org/abs/2404.14219
SnapKV: LLM Knows What You are Looking for Before Generation,"LLM (Lange Language Models)은 KV (Key-Value) 캐시가 성능을 향상시키는 데 중요한 역할을하는 광범위한 컨텍스트 처리에서 현저한 진전을 이루었습니다.그러나 입력 길이가 증가함에 따라 KV 캐시의 성장은 메모리 및 시간 효율에 어려움을 겪습니다.이 문제를 해결하기 위해이 백서는 KV 캐시 크기를 효율적으로 최소화하면서 실제 애플리케이션에서 비슷한 성능을 제공하는 혁신적이고 미세 조정이없는 접근 방식 인 SnapKV를 소개합니다.세대 동안주의 기능.한편,이 강력한 패턴은 프롬프트 끝에 위치한 '관측'창에서 얻을 수 있습니다.이 통찰력을 바탕으로 SnapKV는 각주의 헤드에 대해 클러스터 된 중요한 KV 위치를 선택하여 KV 캐시를 자동으로 압축합니다.우리의 접근 방식은 긴 입력 시퀀스를 처리 할 때 성장하는 계산 간접 및 메모리 발자국을 크게 줄입니다.특히 SnapKV는 16K 토큰의 입력을 처리 할 때 기준선에 비해 생성 속도가 3.6 배 증가하고 메모리 효율이 8.2 배 향상된 일관된 디코딩 속도를 달성합니다.동시에 16 개의 긴 시퀀스 데이터 세트에서 기준선 모델과 비슷한 성능을 유지합니다.또한 SnapKV는 경미한 변화를 가진 Huggingf추가 포괄적 인 연구에 따르면 Snapkv의 실제 적용 가능성이 시사합니다.",2024.04.22,Yuhong Li&&Yingbing Huang&&Bowen Yang&&Bharat Venkitesh&&Acyr Locatelli&&Hanchen Ye&&Tianle Cai&&Patrick Lewis&&Deming Chen,arxiv,https://arxiv.org/abs/2404.14469
OpenELM: An Efficient Language Model Family with Open Training and Inference Framework,"대형 언어 모델의 재현성과 투명성은 개방형 연구를 발전시키고 결과의 신뢰성을 보장하며 잠재적 위험뿐만 아니라 데이터 및 모델 편견에 대한 조사를 가능하게하는 데 중요합니다.이를 위해 최첨단 오픈 언어 모델 인 OpenElm을 출시합니다.OpenELM은 계층 별 스케일링 전략을 사용하여 변압기 모델의 각 계층 내에 매개 변수를 효율적으로 할당하여 정확도를 높입니다.예를 들어, 약 10 억 개의 매개 변수의 매개 변수 예산으로 OpenELM개인 데이터 세트에 우리의 릴리스에는 교육 로그, 다중 체크 포인트 및 사전 훈련 구성을 포함하여 공개적으로 사용 가능한 데이터 세트에서 언어 모델의 교육 및 평가를위한 전체 프레임 워크가 포함됩니다.또한 Apple 장치의 추론 및 미세 조정을 위해 모델을 MLX 라이브러리로 변환하는 코드를 공개합니다.이 포괄적 인 릴리스는 오픈 리서치 커뮤니티에 권한을 부여하고 강화하는 것을 목표로하며, 미래의 공개 연구 노력을위한 길을 열어주고 소스 코드와 함께 사전 훈련 된 모델 가중치 및 교육 레시피는 \ url {이 https url}에서 제공됩니다.또한 \ 모델 모델은 \ url {this https url}에서 huggingface에서 찾을 수 있습니다.",2024.04.22,Sachin Mehta&&Mohammad Hossein Sekhavat&&Qingqing Cao&&Maxwell Horton&&Yanzi Jin&&Chenfan Sun&&Iman Mirzadeh&&Mahyar Najibi&&Dmitry Belenko&&Peter Zatloukal&&Mohammad Rastegari,arxiv,https://arxiv.org/abs/2404.14619
How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study,"메타의 라마 패밀리는 가장 강력한 오픈 소스 대형 언어 모델 (LLM) 시리즈 중 하나가되었습니다.특히, LLAMA3 모델은 최근 15T 이상의 데이터 토큰에 대한 초대형 스케일 사전 훈련으로 다양한 다양한 성능을 달성했으며 다양한 성능을 달성했습니다.리소스 제한 시나리오에서 LLM에 대한 저 비트 양자화의 광범위한 적용을 고려할 때, 우리는 낮은 비트 폭으로 정량화 될 때 LLAMA3의 기능을 탐색합니다.이 탐사는 LLAMA3 및 기타 다가오는 LLM의 낮은 양자화에 대한 새로운 통찰력과 도전, 특히 LLM 압축에서 겪는 성능 저하 문제를 해결할 수있는 잠재력을 발휘할 수 있습니다.구체적으로, 우리는 1-8 비트 및 다양한 데이터 세트에서 LLAMA3의 10 개의 기존 훈련 후 양자화 및 LORA- 결제 방법을 평가하여 LLAMA3의 저 비트 양자화 성능을 포괄적으로 드러냅니다.우리의 실험 결과에 따르면 LLAMA3은 여전히 이러한 시나리오, 특히 매우 낮은 비트 폭에서 비 음성 분해를 겪고 있음을 나타냅니다.이는 미래의 개발에서 브리지해야 할 낮은 비트 폭의 중대한 성능 차이를 강조합니다.우리는이 경험적 연구가 미래의 모델을 발전시키는 데 가치가있을 것으로 기대하며, LLM을 실용적으로 더 높은 정확도로 비트 폭을 낮추게합니다.우리의 프로젝트는 https rat Quantized llama3 모델이 https url에서 출시됩니다.",2024.04.22,Wei Huang&&Xudong Ma&&Haotong Qin&&Xingyu Zheng&&Chengtao Lv&&Hong Chen&&Jie Luo&&Xiaojuan Qi&&Xianglong Liu&&Michele Magno,arxiv,https://arxiv.org/abs/2404.14047
SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation,"멀티 모달 파운데이션 모델의 빠른 진화는 비전 언어 이해와 세대, 예를 들어 이전의 작품 종자-줄로에서 중요한 진전을 보여 주었다.그러나 다양한 사용자 지침에 효과적으로 대응하고 다양한 시각적 데이터와 상호 작용할 수있는 모델의 제한된 용량으로 인해 주로 기능과 실제 적용 가능성 사이에 차이가 남아 있습니다.이 작업에서, 우리는 두 가지 향상된 기능을 통합 하여이 격차를 해소하는 데 중점을 둡니다.우리는 통합적이고 다재다능한 기초 모델, 즉 Seed-X를 제시하며, 이는 이해력과 세대 작업을위한 다중 부문 시각적 의미를 모델링 할 수 있습니다.Seed-X는 공개 벤치 마크의 경쟁 결과 외에도 교육 튜닝 후 다양한 도메인에서 실제 응용 프로그램을 처리하는 데 효과가 있음을 보여줍니다.우리는 우리의 작업이 실제 응용 프로그램에서 다목적 멀티 모달 파운데이션 모델로 달성 할 수있는 것에 대한 미래의 연구에 영감을주기를 바랍니다.이 모델, 코드 및 데이터 세트는이 HTTPS URL에서 릴리스됩니다.",2024.04.22,Yuying Ge&&Sijie Zhao&&Jinguo Zhu&&Yixiao Ge&&Kun Yi&&Lin Song&&Chen Li&&Xiaohan Ding&&Ying Shan,arxiv,https://arxiv.org/abs/2404.14396
MultiBooth: Towards Generating All Your Concepts in an Image from Text,"이 논문은 텍스트에서 이미지 생성에서 멀티 컨셉 사용자 정의를위한 새로운 및 효율적인 기술 인 멀티 부스를 소개합니다.맞춤형 생성 방법, 특히 확산 모델의 성공에 대한 중요한 발전에도 불구하고, 기존 방법은 종종 개념 충실도와 높은 추론 비용으로 인해 다중 개념 시나리오로 어려움을 겪고 있습니다.멀티 슈트는 다중 개념 생성 프로세스를 단일 개념 학습 단계와 다중 개념 통합 단계의 두 단계로 나누어 이러한 문제를 해결합니다.단일 개념 학습 단계에서, 우리는 다중 모달 이미지 인코더와 효율적인 개념 인코딩 기술을 사용하여 각 개념에 대한 간결하고 차별적 인 표현을 학습합니다.멀티 컨셉 통합 단계에서, 우리는 경계 상자를 사용하여 교차-가지 맵 내 각 개념의 생성 영역을 정의합니다.이 방법을 사용하면 지정된 영역 내에서 개별 개념을 생성 할 수 있으므로 다중 개념 이미지의 형성을 용이하게합니다.이 전략은 개념 충실도를 향상시킬뿐만 아니라 추가 추론 비용을 줄입니다.Multibooth는 질적 및 정량적 평가에서 다양한 기준을 능가하여 우수한 성능과 계산 효율성을 보여줍니다.프로젝트 페이지 :이 https url",2024.04.22,Chenyang Zhu&&Kai Li&&Yue Ma&&Chunming He&&Li Xiu,arxiv,https://arxiv.org/abs/2404.14239
Learning H-Infinity Locomotion Control,"침전 환경에서 안정적인 운동은 4 배의 로봇의 필수 기능으로 다양한 외부 교란에 저항 할 수있는 능력을 요구합니다.그러나 최근의 학습 기반 정책은 기본 도메인 무작위 배정 만 사용하여 학습 된 정책의 견고성을 향상시켜 로봇이 적절한 교란 저항 기능을 가지고 있음을 보장 할 수 없습니다.이 논문에서 우리는 학습 과정을 행위자와 새로 도입 된 Disturber 사이의 대적 상호 작용으로 모델링하고 그들의 최적화와 함께 _ {\ infty} 제약 조건을 보장 할 것을 제안합니다.할인 된 전반적인 보상을 최대화하는 행위자와 달리 Disturber는 효과적인 외부 힘을 생성 할 책임이 있으며, 작업 보상과 Oracle, 즉 각 반복의 ""비용""사이의 오류를 극대화하여 최적화됩니다.액터와 Disturber 안정 사이의 관절 최적화를 유지하기 위해 Ourh _ {\ infty} 제약 조건은 외부 힘의 강도에 대한 비용 사이의 비율 경계를 의무화합니다.훈련 단계 전체에서 상호 상호 작용을 통해 배우는 점점 더 복잡한 신체적 장애를 탐색 할 수있는 능력을 얻을 수 있습니다.우리는 Unitree Aliengo Robot을 사용한 4 차 운동 운동 작업에 대한 우리의 접근 방식의 견고성을 확인하고, Unitree A1 로봇의 더 어려운 작업을 확인합니다. 여기서 4 중 것은 마치 뒷다리에서 단지 뒷다리에서 운동을 수행 할 것으로 예상됩니다.시뮬레이션 된 정량적 결과는 기준선에 대한 개선을 보여 주어 방법의 효과와 각 설계 선택을 보여줍니다.반면에 실제 로봇 실험은 계단, 높은 플랫폼, 경사 및 미끄러운 지형을 포함한 다양한 지형에서 다양한 교란을 방해 할 때 정책이 얼마나 강력한 지 질적으로 나타납니다.모든 코드, 체크 포인트 및 실제 배포 지침이 공개됩니다.",2024.04.22,Junfeng Long&&Wenye Yu&&Quanyi Li&&Zirui Wang&&Dahua Lin&&Jiangmiao Pang,arxiv,https://arxiv.org/abs/2404.14405
Scene Coordinate Reconstruction: Posing of Image Collections via Incremental Learning of a Relocalizer,"장면을 묘사 한 이미지 세트에서 카메라 매개 변수를 추정하는 작업을 다룹니다.인기있는 피처 기반 구조 -Motion (SFM) 도구는 증분 재구성을 통해이 작업을 해결합니다. 희소 3D 포인트의 삼각 측량을 반복하고 더 많은 카메라 뷰를 스파 스 포인트 클라우드에 등록합니다.우리는 분비 된 응용 프로그램과 시각적 이전자의 반복적 인 응용 프로그램, 즉 재구성의 현재 상태에 새로운 견해를 등록하는 방법으로 증분 구조를 다시 해석합니다.이 관점을 통해 로컬 기능 일치에 뿌리를 내리지 않는 대체 시각적 재구성기를 조사 할 수 있습니다.학습 기반 이전 접근 방식 인 Scene 좌표 회귀 분석을 통해 반대 이미지에서 암시 적 신경 장면 표현을 구축 할 수 있습니다.다른 학습 기반 재건 방법과는 달리, 우리는 포즈 사전이나 순차적 입력을 필요로하지 않으며 수천 개의 이미지에 대해 효율적으로 최적화합니다.우리의 방법 인 ACE0 (ACE ZERO)은 새로운 뷰 합성에 의해 입증 된 바와 같이 카메라 포즈가 피처 기반 SFM과 비슷한 정확도로 추정됩니다.프로젝트 페이지 :이 HTTPS URL",2024.04.22,Eric Brachmann&&Jamie Wynn&&Shuai Chen&&Tommaso Cavallari&&Áron Monszpart&&Daniyar Turmukhambetov&&Victor Adrian Prisacariu,arxiv,https://arxiv.org/abs/2404.14351
A Multimodal Automated Interpretability Agent,"이 백서에서는 멀티 모달 자동 해석 가능성 에이전트 인 MAIA에 대해 설명합니다.MAIA는 신경 모델을 사용하여 기능 해석 및 실패 모드 발견과 같은 작업 이해를 자동화하는 시스템입니다.사전 훈련 된 비전 언어 모델에 다른 모델의 하위 구성 요소에 대한 반복 실험을 지원하는 일련의 도구 세트가 있습니다.여기에는 인간 해석 성 연구자들이 일반적으로 사용하는 도구가 포함됩니다 : 입력 합성 및 편집, 실제 데이터 세트에서 최대한의 예시를 계산하고 실험 결과를 요약하고 설명하는 도구가 포함됩니다.MAIA가 제안한 해석 실험은 시스템 행동을 설명하고 설명하기 위해 이러한 도구를 구성합니다.컴퓨터 비전 모델에 대한 MAIA의 응용 프로그램을 평가합니다.우리는 먼저 이미지의 학습 된 표현에서 MAIA의 기능 (뉴런 수준) 기능을 특성화합니다.MAIA는 여러 훈련 된 모델과 쌍의 지상 진실 설명을 갖는 합성 시력 뉴런의 새로운 데이터 세트에서 전문가 인간 실험자가 생성 한 설명과 비슷한 설명을 생성합니다.그런 다음 MAIA는 두 가지 추가 해석 성 작업을 도울 수 있음을 보여줍니다. 스퓨리어스 특징에 대한 민감도를 줄이고 오해 할 수있는 입력을 자동으로 식별합니다.",2024.04.22,Tamar Rott Shaham&&Sarah Schwettmann&&Franklin Wang&&Achyuta Rajaram&&Evan Hernandez&&Jacob Andreas&&Antonio Torralba,arxiv,https://arxiv.org/abs/2404.14394
Align Your Steps: Optimizing Sampling Schedules in Diffusion Models,"확산 모델 (DMS)은 시각적 영역과 그 너머에서 최첨단 생성 모델링 접근법으로 자리 매김했습니다.DMS의 중요한 단점은 샘플링 속도가 느린 느린 샘플링 속도로, 대규모 신경망을 통해 많은 순차적 인 기능 평가에 의존한다는 것입니다.DMS로부터의 샘플링은 샘플링 일정으로 알려진 이산화 된 노이즈 레벨 세트를 통해 미분 방정식을 해결하는 것으로 볼 수 있습니다.과거의 작품은 주로 효율적인 솔버를 도출하는 데 중점을 두었지만 최적의 샘플링 일정을 찾는 데 거의 관심을 기울이지 않았으며 전체 문헌은 수동 제작 된 휴리스틱에 의존합니다.이 작업에서 처음으로, 우리는 \ textit {steps}라고 불리는 고품질 출력에 대한 DMS의 샘플링 일정을 최적화하기위한 일반적이고 원칙적인 접근법을 제안합니다.우리는 확률 적 미적분학에서 방법을 활용하고 다른 솔버, 훈련 된 DM 및 데이터 세트에 맞는 최적의 일정을 찾습니다.다양한 샘플러를 사용하여 여러 이미지, 비디오 및 2D 장난감 데이터 합성 벤치 마크에 대한 새로운 접근 방식을 평가하고 최적화 된 일정이 거의 모든 실험에서 이전의 핸드 스케일 스케줄을 능가하는 것을 관찰합니다.우리의 방법은 특히 몇 단계 합성 체제에서 샘플링 일정 최적화의 미개발 잠재력을 보여줍니다.",2024.04.22,Amirmojtaba Sabour&&Sanja Fidler&&Karsten Kreis,arxiv,https://arxiv.org/abs/2404.14507
Pegasus-v1 Technical Report,"이 기술 보고서는 자연어를 통한 비디오 컨텐츠 이해 및 상호 작용을 전문으로하는 멀티 모달 언어 모델 인 Pegasus-1을 소개합니다.Pegasus-1은 시공간 정보 해석과 같은 비디오 데이터에 의해 제기 된 고유 한 과제를 해결하여 다양한 길이에 걸쳐 미묘한 비디오 컨텐츠 이해를 제공하도록 설계되었습니다.이 기술 보고서는 Pegasus-1의 아키텍처, 교육 전략 및 비디오 대화, 제로 샷 비디오 질문 답변 및 비디오 요약에 대한 벤치 마크의 성능을 개요합니다.우리는 또한 Pegasus-1의 질적 특성을 탐색하여 독자들에게 현재 상태와 미래 방향에 대한 균형 잡힌 견해를 제공하기 위해 그 능력뿐만 아니라 한계를 보여줍니다.",2024.04.23,Raehyuk Jung&&Hyojun Go&&Jaehyuk Yi&&Jiho Jang&&Daniel Kim&&Jay Suh&&Aiden Lee&&Cooper Han&&Jae Lee&&Jeff Kim&&Jin-Young Kim&&Junwan Kim&&Kyle Park&&Lucas Lee&&Mars Ha&&Minjoon Seo&&Abraham Jo&&Ed Park&&Hassan Kianinejad&&SJ Kim&&Tony Moon&&Wade Jeong&&Andrei Popescu&&Esther Kim&&EK Yoon&&Genie Heo&&Henry Choi&&Jenna Kang&&Kevin Han&&Noah Seo&&Sunny Nguyen&&Ryan Won&&Yeonhoo Park&&Anthony Giuliani&&Dave Chung&&Hans Yoon&&James Le&&Jenny Ahn&&June Lee&&Maninder Saini&&Meredith Sanders&&Soyoung Lee&&Sue Kim&&Travis Couture,arxiv,https://arxiv.org/abs/2404.14687
FlashSpeech: Efficient Zero-Shot Speech Synthesis,"대규모 제로 샷 음성 합성의 최근 진보는 언어 모델과 확산 모델에 의해 상당히 발전되었습니다.그러나 두 방법의 생성 프로세스는 느리고 계산 집약적입니다.이전 작업과 동등한 품질을 달성하기 위해 낮은 컴퓨팅 예산을 사용한 효율적인 음성 합성은 여전히 중요한 과제입니다.이 백서에서는 이전 작업과 비교하여 추론 시간의 약 5 \%를 가진 대규모 제로 샷 음성 합성 시스템 인 FlashSpeech를 제시합니다.FlashSpeech는 잠재적 일관성 모델을 기반으로 구축되며 교사로서 미리 훈련 된 확산 모델이 필요없이 처음부터 훈련 할 수있는 새로운 대적 일관성 훈련 접근법을 적용합니다.또한 새로운 번영 생성기 모듈은 프로디의 다양성을 향상시켜 음성의 리듬을 더 자연스럽게 만듭니다.FlashSpeech의 생성 프로세스는 하나 또는 두 개의 샘플링 단계로 효율적으로 달성 할 수 있으며, 오디오 품질이 높고 오디오가 발생하는 오디오 프롬프트와 유사성이 높은 음성 생성을 유지할 수 있습니다.우리의 실험 결과는 FlashSpeech의 우수한 성능을 보여줍니다.특히, FlashSpeech는 다른 제로 샷 음성 합성 시스템보다 약 20 배 빠를 수 있으며, 음성 품질 및 유사성 측면에서 비슷한 성능을 유지할 수 있습니다.또한 FlashSpeech는 음성 변환, 음성 편집 및 다양한 음성 샘플링과 같은 작업을 효율적으로 수행함으로써 다양성을 보여줍니다.이 HTTPS URL에서 오디오 샘플을 찾을 수 있습니다.",2024.04.23,Zhen Ye&&Zeqian Ju&&Haohe Liu&&Xu Tan&&Jianyi Chen&&Yiwen Lu&&Peiwen Sun&&Jiahao Pan&&Weizhen Bian&&Shulin He&&Qifeng Liu&&Yike Guo&&Wei Xue,arxiv,https://arxiv.org/abs/2404.14700
Transformers Can Representn-gram Language Models,기존의 많은 작업이 공식적인 계산 모델로 표현 용량을 설명함으로써 변압기 아키텍처의 능력을 분석했습니다.그러나 지금까지의 초점은 언어 \ orth {수락} 측면에서 아키텍처를 분석하는 데있었습니다.우리는 이것이 문자열에 대한 정의적으로 \ orts {확률 분포} 인 \ orth {Language Models} (LMS)에 대한 연구에서 잘못된 문제라고 주장합니다.이 논문에서는 간단하고 역사적으로 관련된 언어 모델 클래스 인 Transformer LMS Andn-Gram LMS의 관계에 중점을 둡니다.우리는 단단하거나 드문 주의적 메커니즘을 사용하는 변압기 LM이 모든 LM을 나타낼 수 있음을 보여줍니다.이것은 변압기 LMS가 문자열에 대한 확률 분포를 나타내는 데 사용할 수있는 메커니즘을 이해하기위한 첫 번째 단계를 제공합니다.,2024.04.23,Anej Svete&&Ryan Cotterell,arxiv,https://arxiv.org/abs/2404.14994
Multi-Head Mixture-of-Experts,"SMOE (Sparse Mixtures of Experts)는 교육 및 추론 비용이 크게 증가하지 않고 모델 용량을 스케일링하지만 다음과 같은 두 가지 문제를 나타냅니다. (1) 전문가의 작은 부분 집합 만 최적화를 위해 활성화되는 낮은 전문가 활성화.(2) 개별 토큰 내의 여러 의미 론적 개념에 대한 세밀한 분석 능력이 부족합니다.우리는 다중 헤드 혼합물 (MH-MOE)을 제안하는데, 이는 각 토큰을 여러 하위 토크로 분할하기 위해 다중 헤드 메커니즘을 사용합니다.이 하위 토크는 다양한 전문가들에 의해 병렬로 할당되고 처리되며 원래의 토큰 형태로 완벽하게 재 통합됩니다.멀티 헤드 메커니즘을 통해 모델은 다른 전문가 내의 다양한 표현 공간의 정보에 총체적으로 참석할 수있게되며, 전문가 활성화를 크게 향상시켜 상황에 대한 이해를 심화시키고 과적으로 완화시킵니다.또한 MH-Moe는 다른 Smoe 최적화 방법에서 구현하고 분리하기 위해 간단하여 다른 Smoe 모델과 쉽게 통합하여 성능을 향상시킬 수 있습니다.영어 중심 언어 모델링, 다국어 언어 모델링 및 마스크 된 다중 모드 모델링 작업의 세 가지 작업에서 광범위한 실험 결과는 MH-MOE의 효과를 보여줍니다.",2024.04.23,Xun Wu&&Shaohan Huang&&Wenhui Wang&&Furu Wei,arxiv,https://arxiv.org/abs/2404.15045
XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference,컨텍스트 내 학습 (ICL) 접근 방식은 일반적으로 참조 정보에 대한 디코더 전용 언어 모델 생성을 조절하도록 프롬프트를 활용합니다.컨텍스트의 정시 처리는 자체 변환 작업의 2 차 비용으로 인해 비효율적이며 캐싱이 바람직합니다.그러나 캐싱 변압기 상태는 모델 매개 변수만큼 쉽게 많은 공간이 필요할 수 있습니다.올바른 컨텍스트가 미리 알려지지 않으면 ICL 캐싱은 어려울 수 있습니다.이 작업은 인코더 디코더 아키텍처에서 영감을 얻은 모델을 소개하여 프롬프트없이 참조 텍스트에서 조건 생성을 사용하는 모델을 소개함으로써 이러한 제한 사항을 다룹니다.보다 정확하게는 미리 훈련 된 디코더 전용 모델을 활용하고 소수의 추가 레이어 만 훈련합니다.우리는 Test-Anwering (QA)을 테스트 베드로 사용하여 조건부 생성을 수행하고 ICL을 능가하고 미세 조정 된 프롬프트 LLM과 비교할 수 있으며 표준 KV 캐싱에 비해 우주 발자국을 크게 줄이는 모델의 능력을 평가합니다.두 배의 순서.,2024.04.23,João Monteiro&&Étienne Marcotte&&Pierre-André Noël&&Valentina Zantedeschi&&David Vázquez&&Nicolas Chapados&&Christopher Pal&&Perouz Taslakian,arxiv,https://arxiv.org/abs/2404.15420
ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning,"확산 모델의 빠른 개발은 다양한 응용 프로그램을 유발했습니다.ID-T2I (Identity Presisity Presisity Presisity Presisity Presisity Presisity Presisity-intect-to-Image Generation)는 AI 초상화 및 광고와 같은 광범위한 응용 프로그램 시나리오로 인해 상당한 관심을 받았습니다.기존의 ID-T2I 방법은 인상적인 결과를 보여 주었지만 몇 가지 주요 과제는 남아 있습니다. (1) 참조 초상화의 정체성 특성을 정확하게 유지하기가 어렵습니다.) LORA 기반 및 어댑터 기반 방법과 동시에 호환 될 수없는 제한이 있습니다.이러한 문제를 해결하기 위해 ID-T2I 성능을 향상시키기위한 일반적인 피드백 학습 프레임 워크 인 \ textbf {id-aligner}를 제시합니다.정체성 기능이 손실 된 것을 해결하기 위해, 우리는 얼굴 탐지 및 인식 모델의 피드백을 활용하여 생성 된 신원 보존을 개선하기 위해 신원 일관성 보상 미세 조정을 도입합니다.또한, 우리는 인간이 주어진 선호도 데이터와 캐릭터 구조 생성에 대한 피드백을 자동으로 구성하여 미학적 튜닝 신호를 제공하는 정체성 미적 보상 미세 조정을 제안합니다.보편적 인 피드백 미세 조정 프레임 워크 덕분에 우리의 방법은 LORA 및 어댑터 모델 모두에 쉽게 적용되어 일관된 성능 이득을 달성 할 수 있습니다.SD1.5 및 SDXL 확산 모델에 대한 광범위한 실험은 우리의 접근 방식의 효과를 검증합니다.\ textbf {프로젝트 페이지 : \ url {this https url}}",2024.04.23,Weifeng Chen&&Jiacheng Zhang&&Jie Wu&&Hefeng Wu&&Xuefeng Xiao&&Liang Lin,arxiv,https://arxiv.org/abs/2404.15449
CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data,"대조적 학습은 이미지 및 텍스트 임베딩의 정렬을 통해 효과적인 시각적 표현을 학습하기위한 변형적인 방법으로 등장했습니다.그러나 이미지와 텍스트 쌍 사이의 대조적 손실에 대한 쌍별 유사성 계산은 계산 과제를 제기합니다.이 논문은 웹 스케일 이미지 텍스트 데이터에 대한 비전 모델의 사전 훈련 된 새로운 사전 훈련을 제시합니다.제안 된 방법은 분류 작업으로 이미지 텍스트 데이터에 대한 사전 훈련을 재구성합니다.결과적으로, 대조적 인 손실에서 쌍별 유사성 계산이 필요하지 않아 웹 스케일 데이터에 대한 대조적 학습과 비교하여 훈련 속도에서 현저한 2.7 \ TimesAcceleration을 달성합니다.탐지 및 세분화를 포함하여 다양한 비전 작업에 걸친 광범위한 실험을 통해 제안 된 방법이 높은 표현 품질을 유지한다는 것을 보여줍니다.사전 훈련 된 모델 가중치 및 교육 레시피와 함께 소스 코드는 \ url {this https url}에서 제공됩니다.",2024.04.24,Sachin Mehta&&Maxwell Horton&&Fartash Faghri&&Mohammad Hossein Sekhavat&&Mahyar Najibi&&Mehrdad Farajtabar&&Oncel Tuzel&&Mohammad Rastegari,arxiv,https://arxiv.org/abs/2404.15653
MoDE: CLIP Data Experts via Clustering,"대조적 인 언어 이미지 사전 여파 (CLIP)의 성공은 이미지와 캡션 사이의 쌍의 감독에 의존하며, 이는 웹 크롤링 데이터에서 시끄러운 경향이 있습니다.우리는 데이터 전문가 (모드)의 혼합을 제시하고 클러스터링을 통해 클립 데이터 전문가 시스템을 배웁니다.각 데이터 전문가는 하나의 데이터 클러스터에 대한 교육을받으며 다른 클러스터의 잘못된 음성 소음에 덜 민감합니다.추론 시간에, 우리는 작업 메타 데이터와 클러스터 조건 사이의 상관 관계를 통해 결정된 가중치를 적용하여 출력을 뒷받침합니다.상관 관계를 정확하게 추정하기 위해, 한 클러스터의 샘플은 의미 적으로 유사해야하지만 데이터 전문가의 수는 여전히 훈련 및 추론에 합리적이어야합니다.따라서, 우리는 인간 언어의 온톨로지를 고려하고 세분화 된 클러스터 센터를 사용하여 각 데이터 전문가를 거친 수준에서 대표 할 것을 제안합니다.실험적 연구에 따르면 VIT-B/16의 4 개의 클립 데이터 전문가가 Openai Clip으로 VIT-L/14를 능가하고 Zero-Shot 이미지 분류에서 OpenClip이지만 (<35 \%) 교육 비용이 적습니다.한편, 모드는 모든 데이터 전문가를 비동력있게 훈련시킬 수 있으며 새로운 데이터 전문가를 유연하게 포함시킬 수 있습니다.이 코드는 https url에서 사용할 수 있습니다.",2024.04.24,Jiawei Ma&&Po-Yao Huang&&Saining Xie&&Shang-Wen Li&&Luke Zettlemoyer&&Shih-Fu Chang&&Wen-Tau Yih&&Hu Xu,arxiv,https://arxiv.org/abs/2404.16030
BASS: Batched Attention-optimized Speculative Sampling,"투기 디코딩은 대형 언어 모델을 호스팅 할 때 대기 시간과 처리량을 향상시키는 강력한 방법으로 등장했습니다.그러나 대부분의 기존 구현은 단일 시퀀스를 생성하는 데 중점을 둡니다.실제 생성 AI 애플리케이션은 종종 여러 응답이 필요하며 배치 된 설정에서 투기 디코딩을 수행하는 방법이 필요하며 대기 시간 혜택을 보존하면 사소한 문제가 발생합니다.이 논문은 다중 시퀀스 생성 대기 시간에 새로운 최신 기술을 설정하고 시간 예산 내에서 세대의 품질을 보여주는 새로운 최신 기술을 설정하는 배치 투기 디코딩 시스템을 설명합니다.예를 들어, 단일 A100 GPU의 7.8b 크기 모델 및 배치 크기 8 인 각 시퀀스는 토큰 당 평균 속도 5.8ms로 생성되며 전체 처리량은 초당 1.1k 토큰입니다.이러한 결과는 최적의 대기 시간과 최적화 된 일반 디코딩보다 2.15 배 속도를 나타냅니다.정기적 인 디코딩이 완료되지 않는 시간 예산 내에서, 우리의 시스템은 HumaneVal Pass@43%의 첫 번째 및 61%를 모두 통과하여 시퀀스를 생성 할 수 있으며, 단일 시퀀스 투기 디코딩으로 실현 가능한 것을 훨씬 초과합니다.디코딩 중 우리의 피크 GPU 이용률은 15.8%, 정기적 인 디코딩의 3 배 이상, 단일 시퀀스 투기 디코딩의 약 10 배 이상에 도달합니다.",2024.04.24,Haifeng Qian&&Sujan Kumar Gonugondla&&Sungsoo Ha&&Mingyue Shang&&Sanjay Krishna Gouda&&Ramesh Nallapati&&Sudipta Sengupta&&Xiaofei Ma&&Anoop Deoras,arxiv,https://arxiv.org/abs/2404.15778
MaGGIe: Masked Guided Gradual Human Instance Matting,"인간 매트는 이미지 및 비디오 처리의 기초 작업으로, 인간 전경 픽셀이 입력에서 추출됩니다.이전 작업은 추가 지침으로 정확도를 향상 시키거나 프레임에 걸쳐 단일 인스턴스의 시간적 일관성을 향상시킵니다.우리는 새로운 프레임 워크 Maggie, 마스크 가이드 점진적 인간 인스턴스 매트를 제안하는데, 이는 계산 비용, 정밀도 및 일관성을 유지하면서 각 인간 사례에 대해 점차적으로 알파 매트를 예측합니다.우리의 방법은 변압기주의 및 드문 컨볼 루션을 포함한 최신 아키텍처를 활용하여 메모리와 대기 시간을 폭발하지 않고 모든 인스턴스 매트를 동시에 출력합니다.다중 인스턴스 시나리오에서 일정한 추론 비용을 유지하지만 우리의 프레임 워크는 제안 된 합성 벤치 마크에서 강력하고 다재다능한 성능을 달성합니다.고품질 이미지 및 비디오 매트 벤치 마크를 통해 실제 시나리오에서 모델의 일반화를 증가시키기 위해 공개적으로 이용 가능한 소스의 새로운 다중 인스턴스 합성 접근법이 소개됩니다.",2024.04.24,Chuong Huynh&&Seoung Wug Oh&&Abhinav Shrivastava&&Joon-Young Lee,arxiv,https://arxiv.org/abs/2404.16035
PuLID: Pure and Lightning ID Customization via Contrastive Alignment,"우리는 텍스트-이미지 생성을위한 새로운 튜닝 프리 ID 사용자 정의 방법 인 PULID (Pure and Lightning ID Customization)를 제안합니다.Pulid는 표준 확산 브랜치와 번개 T2I 분기를 통합함으로써 대조적 인 정렬 손실과 정확한 ID 손실을 모두 소개하여 원래 모델에 대한 혼란을 최소화하고 높은 ID 충실도를 보장합니다.실험에 따르면 Pulid는 ID 충실도와 편집성 모두에서 우수한 성능을 달성합니다.Pulid의 또 다른 매력적인 특성은 ID 삽입 전후 이미지 요소 (예 : 배경, 조명, 구성 및 스타일)가 가능한 한 일관되게 유지된다는 것입니다.코드 및 모델은 HTTPS URL에서 사용할 수 있습니다",2024.04.24,Zinan Guo&&Yanze Wu&&Zhuowei Chen&&Lang Chen&&Qian He,arxiv,https://arxiv.org/abs/2404.16022
MotionMaster: Training-free Camera Motion Transfer For Video Generation,"확산 모델의 출현은 이미지 및 비디오 생성의 진행을 크게 추진시켰다.최근에, 텍스트-비디오 생성 및 비디오 모션 제어를 포함하여 제어 가능한 비디오 생성에서 일부 노력이 이루어졌으며, 그 중 카메라 모션 제어가 중요한 주제입니다.그러나 기존 카메라 모션 제어 방법은 시간적 카메라 모듈을 훈련시키는 데 의존하며 비디오 생성 모델의 많은 양의 매개 변수로 인해 상당한 계산 리소스가 필요합니다.또한 기존 방법은 훈련 중에 카메라 모션 유형을 사전 정의하여 카메라 제어의 유연성을 제한합니다.따라서 교육 비용을 줄이고 유연한 카메라 제어를 달성하기 위해 소스 비디오의 카메라 모션 및 객체 동작을 분리하고 추출 된 카메라 모션을 새로운 비디오로 전송하는 새로운 교육이없는 비디오 모션 전송 모델 인 Comd를 제안합니다.먼저 하나의 소스 비디오에서 카메라 모션을 추출하기 위해 원샷 카메라 모션 분리 방법을 제안합니다. 이는 단일 소스 비디오에서 카메라 모션을 배경에서 분리하고 Poisson을 해결하여 배경의 움직임에 따라 움직이는 물체 영역의 카메라 모션을 추정합니다.방정식.또한 비슷한 카메라 모션을 사용하여 여러 비디오에서 공통 카메라 모션을 추출하기 위해 소수의 카메라 모션 분리 방법을 제안합니다.이 카메라 모션을 사용하여 창 기반 클러스터링 기술을 사용하여 여러 비디오의 시간적주의 맵에서 일반적인 기능을 추출합니다.마지막으로, 다양한 유형의 카메라 모션을 결합하는 모션 조합 방법을 제안하여 모델에보다 제어 가능하고 유연한 카메라 제어를 가능하게합니다.광범위한 실험은 우리의 훈련이없는 접근 방식이 카메라-객체 모션을 효과적으로 분리하고 분리 된 카메라 모션을 광범위한 제어 가능한 비디오 생성 작업에 적용하여 유연하고 다양한 카메라 모션 제어를 달성 할 수 있음을 보여줍니다.",2024.04.24,Teng Hu&&Jiangning Zhang&&Ran Yi&&Yating Wang&&Hongrui Huang&&Jieyu Weng&&Yabiao Wang&&Lizhuang Ma,arxiv,https://arxiv.org/abs/2404.15789
Editable Image Elements for Controllable Synthesis,"확산 모델은 텍스트 유도 합성 작업에서 상당한 발전을 이루었습니다.그러나 확산 모델의 높은 차원 노이즈 입력 공간이 이미지 역전 또는 공간 편집에 자연스럽게 적합하지 않기 때문에 사용자 제공 이미지 편집은 여전히 어려운 일입니다.이 작업에서는 확산 모델을 사용하여 입력 이미지의 공간 편집을 촉진하는 이미지 표현을 제안합니다.구체적으로, 우리는 입력 이미지를 충실하게 재구성 할 수있는 ""이미지 요소""에 입력을 인코딩하는 법을 배웁니다.이러한 요소는 사용자가 직관적으로 편집 할 수 있으며 확산 모델에 의해 현실적인 이미지로 디코딩됩니다.우리는 객체 크기 조정, 재 배열, 드래그, 탈퇴, 제거, 변형 및 이미지 구성과 같은 다양한 이미지 편집 작업에 대한 표현의 효과를 보여줍니다.프로젝트 페이지 :이 HTTPS URL",2024.04.24,Jiteng Mu&&Michaël Gharbi&&Richard Zhang&&Eli Shechtman&&Nuno Vasconcelos&&Xiaolong Wang&&Taesung Park,arxiv,https://arxiv.org/abs/2404.16029
NeRF-XL: Scaling NeRFs with Multiple GPUs,"우리는 NERF-XL을 여러 GPU에 배포하는 원칙적 방법 인 NERF-XL을 제시하여, 자의적으로 큰 용량으로 NERF의 훈련 및 렌더링을 가능하게합니다.우리는 기존의 멀티 GPU 접근 방식을 다시 방문하는 것으로 시작하여 대규모 장면을 여러 독립적으로 훈련 된 NERF로 분해하고 추가 계산 리소스 (GPU)가 교육에 사용됨에 따라 재구성 품질의 개선을 방해하는 이러한 방법과 함께 몇 가지 기본 문제를 식별합니다.NERF-XL은 이러한 문제를 해결하고 더 많은 하드웨어를 사용하여 임의의 매개 변수로 NERF의 교육 및 렌더링을 가능하게합니다.우리의 방법의 핵심에는 새로운 분산 훈련 및 렌더링 제형이 있으며, 이는 고전적인 단일 GPU 사례와 수학적으로 동등하며 GPU 간의 의사 소통을 최소화합니다.임의로 큰 매개 변수 수를 갖는 NERF를 잠금 해제함으로써, 우리의 접근 방식은 NERF에 대한 다중 GPU 스케일링 법칙을 공개 한 최초의 파라미터 수와 더 많은 GPU로 속도 개선으로 재구성 품질의 개선을 보여줍니다.우리는 25km^2 도시 지역을 포함하는 258k 이미지를 포함하는 MatrixCity를 포함하여 다양한 데이터 세트에서 NERF-XL의 효과를 보여줍니다.",2024.04.24,Ruilong Li&&Sanja Fidler&&Angjoo Kanazawa&&Francis Williams,arxiv,https://arxiv.org/abs/2404.16221
PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning,"비전 언어 사전 훈련은 광범위한 이미지 언어 애플리케이션에서 성능이 상당히 높아졌습니다.그러나 비디오 관련 작업에 대한 사전 훈련 프로세스는 매우 큰 컴퓨팅 및 데이터 리소스를 요구하여 비디오 언어 모델의 진행을 방해합니다.이 논문은 조밀 한 비디오 이해를 위해 기존 이미지 언어 미리 훈련 된 모델을 조정하기위한 간단하고, 매우 효율적이며, 자원 조명 접근법을 조사합니다.우리의 예비 실험은 비디오 데이터 세트의 입력으로 인해 여러 프레임이있는 사전 훈련 된 이미지 언어 모델을 직접 미세 조정하면 성능 포화 또는 하락으로 이어집니다.우리의 추가 조사에 따르면, 그것은 학습 된 높은 시각적 시각적 특징의 편견에 기인 한 것으로 나타났습니다.이 결과에 의해, 우리는 시간 차원을 따라 특징 분포를 매끄럽게하기위한 간단하지만 효과적인 풀링 전략을 제안하고 극단적 인 특징으로부터 지배적 인 영향을 줄입니다.새 모델은 풀링 llava 또는 pllava라고 불립니다.Pllava는 비디오 질문 응답 및 캡션 작업 모두에 대한 최신 벤치 마크 데이터 세트에서 새로운 최첨단 성능을 달성합니다.특히 최근 인기있는 VideoChatGpt 벤치 마크에서 Pllava는 평균 5 개 중 5 개 중 5 개 중 3.48 점을 달성하여 GPT4V (IG-VLM)의 이전 SOTA 결과를 9%초과합니다.최신 멀티 체이스 벤치 마크 MVbench에서 Pllava는 20 개의 하위 작업에서 평균 58.1% 정확도를 달성하며 GPT4V (IG-VLM)보다 14.5% 높습니다.이 https url에서 코드를 사용할 수 있습니다",2024.04.25,Lin Xu&&Yilin Zhao&&Daquan Zhou&&Zhijie Lin&&See Kiong Ng&&Jiashi Feng,arxiv,https://arxiv.org/abs/2404.16994
SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension,"텍스트가 풍부한 시각적 컨텐츠는 멀티 모달 대형 언어 모델 (MLLM)의 실제 적용에 가장 중요합니다. 텍스트가 풍부한 시나리오는 실제 세계에서 유비쿼터스이기 때문에 이미지에 포함 된 광범위한 텍스트가 포함되어 있기 때문입니다.최근에, 인상적인 다양성을 가진 MLLM의 출현은 MLLM에서 기대할 수있는 것에 대한 기준을 높였습니다.그러나 현재의 MLLM 벤치 마크는 주로 일반적인 시각적 이해력을 평가하는 데 중점을두기 때문에 텍스트가 풍부한 시나리오에 대한 숙련도는 아직 포괄적이고 객관적으로 평가되지 않았습니다.이 작업에서 우리는 MLLM의 \ textbf {텍스트가 풍부한 시각적 이해력}를 평가하도록 특별히 설계된 벤치 마크 인 Seed-Bench-2-Plus를 소개합니다.당사의 벤치 마크는 정확한 인간 주석이있는 2.3K 객관식 질문으로, 차트, 맵 및 웹의 세 가지 범주에 걸쳐 있으며 각각은 실제 세계에서 광범위한 텍스트가 풍부한 시나리오를 다룹니다.이러한 범주는 고유 한 복잡성과 다양성으로 인해 실제 텍스트가 풍부한 환경을 효과적으로 시뮬레이션합니다.우리는 또한 34 개의 저명한 MLLM (GPT-4V, Gemini-Pro-Vision 및 Claude-3-Opus 포함)을 포함한 철저한 평가를 수행하고 텍스트가 풍부한 시각적 이해력에서 MLLM의 현재 한계를 강조합니다.우리는 우리의 작업이 기존의 MLLM 벤치 마크에 귀중한 추가로 사용될 수 있기를 바랍니다.HTTPS URL에서 데이터 세트 및 평가 코드에 액세스 할 수 있습니다.",2024.04.25,Bohao Li&&Yuying Ge&&Yi Chen&&Yixiao Ge&&Ruimao Zhang&&Ying Shan,arxiv,https://arxiv.org/abs/2404.16790
"Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and Human Ratings","T2I (Text-to-Image) 생성 모델이 어디에나있게되었지만, 주어진 프롬프트와 일치하는 이미지를 생성하는 것은 아닙니다.이전의 작업은 인간 판단을 수집하기위한 메트릭, 벤치 마크 및 템플릿을 제안하여 T2I 정렬을 평가했지만 이러한 구성 요소의 품질은 체계적으로 측정되지 않습니다.인간 등급의 프롬프트 세트는 일반적으로 작고 등급의 신뢰성 (모델 비교에 사용되는 프롬프트 세트)은 평가되지 않습니다.우리는 자동 이벤 메트릭과 인간 템플릿을 평가하는 광범위한 연구를 수행함으로써 이러한 격차를 해결합니다.우리는 세 가지 주요 기여를 제공합니다. (1) 다른 인간 템플릿에서 모델을 구별 할 수있는 포괄적 인 기술 기반 벤치 마크를 소개합니다.이 기술 기반의 벤치 마크는 하위 기술로 프롬프트를 사용하여 실무자가 어떤 기술이 도전 할뿐만 아니라 기술이 어떤 수준의 복잡성이 어려워지는 지 정확하게 지적 할 수 있습니다.(2) 우리는 총 100K 주석에 대해 4 개의 템플릿과 4 개의 T2I 모델에서 인간 등급을 수집합니다.이를 통해 프롬프트의 고유 한 모호성으로 인해 차이가 발생하는 위치와 메트릭 및 모델 품질의 차이로 인해 발생하는 위치를 이해할 수 있습니다.(3) 마지막으로, 우리는 새로운 데이터 세트, 다른 인간 템플릿 및 TIFA160의 기존 지표보다 인간 등급과 더 잘 상관되는 새로운 QA 기반 자동 이벤 메트릭을 소개합니다.",2024.04.25,Olivia Wiles&&Chuhan Zhang&&Isabela Albuquerque&&Ivana Kajić&&Su Wang&&Emanuele Bugliarello&&Yasumasa Onoe&&Chris Knutsen&&Cyrus Rashtchian&&Jordi Pont-Tuset&&Aida Nematzadeh,arxiv,https://arxiv.org/abs/2404.16820
Make Your LLM Fully Utilize the Context,"많은 현대의 대형 언어 모델 (LLM)은 긴 입력을 처리 할 수 있지만, 중간 도전으로 알려진 긴 맥락에서 정보를 완전히 활용하는 데 어려움을 겪고 있습니다.우리는 장기 텍스트 훈련 중에 명백한 감독이 불충분하다는 가설을 세우고 있으며, 이는 긴 맥락에서 어떤 입장이든 중요한 정보를 보유 할 수 있다는 것을 강조하지 않습니다.이러한 직관에 근거하여, 우리의 연구는 정보 집약적 (IN2) 교육, 중간에 잃어버린 순수한 데이터 중심 솔루션을 제시합니다.구체적으로, IN2 교육은 합성 된 긴 컨텍스트 질문 답변 데이터 세트를 활용합니다. 여기서 답은 합성 된 긴 상황 (4K-32K 토큰) 내에서 짧은 세그먼트 (~ 128 토큰)에 대한 세밀한 정보 인식을 요구합니다.2) 둘 이상의 짧은 세그먼트에서 정보의 통합 및 추론.이 정보 집약적 인 교육을 Mistral-7B에 적용함으로써 필름 -7b (마이너)를 제시합니다.긴 맥락을 활용하기위한 필름 -7B의 능력을 철저히 평가하기 위해 다양한 컨텍스트 스타일 (문서, 코드 및 구조화 된 데이터 컨텍스트) 및 정보 검색 패턴 (전방, 후진 및 양방향 검색)을 포함하는 세 가지 프로빙 작업을 설계합니다..조사 결과는 필름 -7B가 32K 컨텍스트 창에서 다른 위치에서 정보를 강력하게 검색 할 수 있음을 보여줍니다.이러한 조사 작업 외에도 Film-7B는 실제 장기 컨텍스트 작업 (예 : 내러티브 QA의 23.5-> 26.9 F1 점수)의 성능을 크게 향상시키면서 단락 작업 (예 : 59.3-> 59.2)에서 비슷한 성능을 유지합니다.MMLU의 정확도).Github 링크 :이 HTTPS URL.",2024.04.25,Shengnan An&&Zexiong Ma&&Zeqi Lin&&Nanning Zheng&&Jian-Guang Lou,arxiv,https://arxiv.org/abs/2404.16811
Tele-FLM Technical Report,"LLM (Lange Language Models)은 언어 이해 및 생성에서 심오한 기능을 선보이며 다양한 응용 프로그램을 촉진했습니다.그러나 최소한의 시행 착오 비용 및 계산 리소스를 사용하여 LLM을 500 억 개의 매개 변수 이상으로 효율적으로 스케일링하는 데있어 상세하고 개방 소스 방법론의 현저한 부족이 있습니다.이 보고서에서, 우리는 안정적이고 효율적인 사전 훈련 패러다임과 진화 된 사실 판단 기능을 특징으로하는 52B 오픈 소스 다국어 대형 언어 모델 인 Tele-FLM (일명 FLM-2)을 소개합니다.Tele-FLM은 텍스트 코퍼스에서 BPB에 의해 측정 된 우수한 다국어 언어 모델링 능력을 보여줍니다.또한 영어 및 중국 기초 모델 평가에서 LLAMA2-70B 및 DEEPSEEK-67B와 같은 더 큰 사전 훈련 플롭을 포함하는 강력한 오픈 소스 모델과 비교할 수 있습니다.모델 가중치 외에도 핵심 디자인, 엔지니어링 관행 및 교육 세부 사항을 공유하며 학업 및 산업 커뮤니티 모두에 도움이 될 것으로 예상됩니다.",2024.04.25,Xiang Li&&Yiqun Yao&&Xin Jiang&&Xuezhi Fang&&Chao Wang&&Xinzhang Liu&&Zihan Wang&&Yu Zhao&&Xin Wang&&Yuyao Huang&&Shuangyong Song&&Yongxiang Li&&Zheng Zhang&&Bo Zhao&&Aixin Sun&&Yequan Wang&&Zhongjiang He&&Zhongyuan Wang&&Xuelong Li&&Tiejun Huang,arxiv,https://arxiv.org/abs/2404.16645
How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites,"이 보고서에서는 오픈 소스 다중 모드 대형 언어 모델 (MLLM) 인 InternVL 1.5를 소개하여 멀티 모달 이해에서 오픈 소스와 독점 상용 모델 사이의 기능 간격을 연결합니다.우리는 세 가지 간단한 개선 사항을 소개합니다. (1) 강력한 비전 엔코더 : 대규모 비전 비전 재단 모델 인 Internvit-6B, 시각적 이해 기능을 향상시키고 다른 LLM에서 전송 및 재사용 할 수 있도록 지속적인 학습 전략을 탐구했습니다..(2) 동적 고해상도 : 우리는 최대 4K 해상도 입력을 지원하는 입력 이미지의 종횡비 및 해상도에 따라 1 내지 448 \ Times448 픽셀 범위의 타일로 이미지를 나눕니다.(3) 고품질 이중 언어 데이터 세트 : 우리는 일반적인 장면, 문서 이미지를 다루는 고품질 이중 언어 데이터 세트를 신중하게 수집하여 영어 및 중국어 질문 응답 쌍으로 주석을 달아 OCR 및 중국 관련 작업의 성능을 크게 향상 시켰습니다.우리는 일련의 벤치 마크 및 비교 연구를 통해 InternVL 1.5를 평가합니다.오픈 소스 및 독점 모델과 비교하여 InternVL 1.5는 경쟁력있는 성능을 보여 주어 18 개의 벤치 마크 중 8 개에서 최첨단 결과를 달성합니다.이 https url에서 코드가 출시되었습니다.",2024.04.25,Zhe Chen&&Weiyun Wang&&Hao Tian&&Shenglong Ye&&Zhangwei Gao&&Erfei Cui&&Wenwen Tong&&Kongzhi Hu&&Jiapeng Luo&&Zheng Ma&&Ji Ma&&Jiaqi Wang&&Xiaoyi Dong&&Hang Yan&&Hewei Guo&&Conghui He&&Botian Shi&&Zhenjiang Jin&&Chao Xu&&Bin Wang&&Xingjian Wei&&Wei Li&&Wenjian Zhang&&Bo Zhang&&Pinlong Cai&&Licheng Wen&&Xiangchao Yan&&Min Dou&&Lewei Lu&&Xizhou Zhu&&Tong Lu&&Dahua Lin&&Yu Qiao&&Jifeng Dai&&Wenhai Wang,arxiv,https://arxiv.org/abs/2404.16821
List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs,"마크 세트 (SOM)는 모델이 이미지에 삽입 된 태그와 시각적 객체를 연결할 수 있도록하여 GPT-4V의 시각적 접지 기능을 발표합니다.영숫자로 표시된이 태그는 텍스트 토큰을 통해 인덱싱 될 수 있습니다.GPT-4V의 특별한 성능에도 불구하고, 우리는 다른 멀티 모달 대형 언어 모델 (MLLM)이 이러한 시각적 태그를 이해하기 위해 어려움을 겪고 있음을 관찰합니다.오픈 소스 모델에 대한 SOM의 학습을 촉진하기 위해, 우리는 새로운 학습 패러다임을 제안합니다. ""하나씩 목록 항목""을 제안합니다. 이는 모델에 알파 너 음성 태그 순서에 따라 이미지에 배치 된 모든 시각적 태그를 열거하고 설명하도록 요청합니다.선별 된 데이터 세트를 다른 시각적 명령 튜닝 데이터 세트와 통합함으로써 기존 MLLM에 SOM 프롬프트 능력을 장착 할 수 있습니다.또한 5 개의 MLLM 벤치 마크에서 Finetuned SOM 모델을 평가합니다.우리는이 새로운 데이터 세트, 비교적 작은 크기 (태그가있는 10K-30K 이미지)에서도 시각적 추론 기능을 크게 향상시키고 MLLM의 환각을 줄입니다.아마도 놀랍게도, 이러한 개선은 추론 중에 입력 이미지에서 시각적 태그가 생략 된 경우에도 지속됩니다.이것은 훈련 단계에서 시각적 태그를 사용하여 객체 텍스트 정렬을 강화하는 MLLM을위한 새로운 패러다임으로 ""목록 항목 1 씩 하나""의 잠재력을 시사합니다.마지막으로, 우리는 숙련 된 모델을 조사하여 SOM의 작동 메커니즘을 이해하여 분석을 수행합니다.우리의 코드와 데이터는 \ url {this https url}에서 사용할 수 있습니다.",2024.04.25,An Yan&&Zhengyuan Yang&&Junda Wu&&Wanrong Zhu&&Jianwei Yang&&Linjie Li&&Kevin Lin&&Jianfeng Wang&&Julian McAuley&&Jianfeng Gao&&Lijuan Wang,arxiv,https://arxiv.org/abs/2404.16375
ConsistentID: Portrait Generation with Multimodal Fine-Grained Identity Preserving,"확산 기반 기술은 특히 개인화되고 맞춤형 안면 성능에서 상당한 진전을 이루었습니다.그러나 기존의 방법은 안면 영역에 대한 세밀한 제어력이 부족하고 복잡한 얼굴 세부 사항과 전체 얼굴을 완전히 고려함으로써 ID 보존을위한 포괄적 인 전략의 부족으로 인해 고 충실도 및 상세한 정체성 (ID) 일관성을 달성하는 데 어려움을 겪습니다..이러한 한계를 해결하기 위해, 우리는 단일 참조 이미지 만 사용하여 세밀한 다중 모드 페이셜 프롬프트에서 다양성을 예방하는 초상화 생성을 위해 제작 된 혁신적인 방법 인 일관성있는 방법을 소개합니다.일관성있는 두 가지 주요 구성 요소 : 얼굴 특징, 해당 얼굴 설명 및 전체 얼굴 컨텍스트를 결합한 멀티 모달 얼굴 프롬프트 생성기와 얼굴 세부 사항의 정밀성을 향상시키고 ID 일관성을 보존하기 위해 얼굴주의 현지화 전략을 통해 최적화 된 ID 예방 네트워크를 결합합니다.안면 지역에서.함께, 이러한 구성 요소는 얼굴 영역에서 세밀한 멀티 모달 ID 정보를 도입하여 ID 보존의 정확도를 크게 향상시킵니다.일관성이있는 교육을 촉진하기 위해, 우리는 50 만 개가 넘는 얼굴 이미지를 갖춘 미세한 초상화 데이터 세트 인 FGID를 제시하여 기존의 공공 페이셜 데이터 세트보다 더 많은 다양성과 포괄 성을 제공합니다.Laion-Face, Celeba, FFHQ 및 SFHQ와 같은 %.실험 결과는 우리의 일관성이 Mystyle 데이터 세트의 기존 방법을 능가하는 개인화 된 안면 생성에서 탁월한 정밀도와 다양성을 달성한다는 것을 입증합니다.또한 일관성있는 사람들은 더 많은 멀티 모달 ID 정보를 소개하지만 생성 동안 빠른 추론 속도를 유지합니다.",2024.04.25,Jiehui Huang&&Xiao Dong&&Wenhui Song&&Hanhui Li&&Jun Zhou&&Yuhao Cheng&&Shutao Liao&&Long Chen&&Yiqiang Yan&&Shengcai Liao&&Xiaodan Liang,arxiv,https://arxiv.org/abs/2404.16771
LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding,"우리는 LLMS (Large Language Model)의 속도를 높이기위한 엔드 투 엔드 솔루션 인 Layerskip을 제시합니다.먼저, 훈련 중에 우리는 레이어 드롭 아웃을 적용하고, 이전 계층의 낮은 드롭 아웃 속도와 이후 레이어의 경우 더 높은 드롭 아웃 속도와 모든 변압기 계층이 동일한 종료를 공유하는 초기 출구 손실을 적용합니다.둘째, 추론 중에, 우리는이 훈련 레시피가 모델에 보조 층이나 모듈을 추가하지 않고 초기 층에서의 초기 출구의 정확도를 증가 시킨다는 것을 보여줍니다.셋째, 우리는 초기 층에서 나가고 모델의 나머지 레이어를 확인하고 수정하는 새로운 자기 형성 디코딩 솔루션을 제시합니다.우리의 제안 된 자체적 지정 디코딩 접근법은 다른 투기 디코딩 접근법보다 메모리 발자국이 적으며 초안 및 검증 단계의 공유 컴퓨팅 및 활성화로 인한 이점이 있습니다.우리는 서로 다른 유형의 훈련에 대한 다양한 LLAMA 모델 크기에 대한 실험을 실행합니다. 처음부터의 사전 조정, 지속적인 사전 여파, 특정 데이터 도메인에 대한 미세 조정 및 특정 작업에 대한 최종 결합.우리는 추론 솔루션을 구현하고 CNN/DM 문서의 요약에 따라 최대 2.16 배, 코딩의 1.82 배, Topv2 시맨틱 구문 분석 작업에서 2.0x의 속도를 보여줍니다.",2024.04.25,Mostafa Elhoushi&&Akshat Shrivastava&&Diana Liskovich&&Basil Hosmer&&Bram Wasti&&Liangzhen Lai&&Anas Mahmoud&&Bilge Acun&&Saurabh Agarwal&&Ahmed Roman&&Ahmed A Aly&&Beidi Chen&&Carole-Jean Wu,arxiv,https://arxiv.org/abs/2404.16710
Interactive3D: Create What You Want by Interactive 3D Generation,"3D 객체 생성은 상당한 발전을 거쳐 고품질 결과를 얻었습니다.그러나 정확한 사용자 제어를 달성하기에 미치지 못하면서 종종 사용자 기대와 일치하지 않는 결과를 얻으므로 적용 가능성이 제한됩니다.사용자 강화 3D 객체 생성은 제한된 상호 작용 기능으로 인해 현재 생성 모델을 사용하여 개념을 실현하는 데 중요한 과제에 직면합니다.기존 방법은 주로 두 가지 접근법을 제공합니다. (i) 제한된 제어 성으로 텍스트 명령어 해석 또는 (ii) 2D 이미지에서 3D 객체를 재구성합니다.둘 다 2D 참조의 경계에 대한 사용자 정의를 제한하고 3D 리프팅 프로세스 중에 바람직하지 않은 아티팩트를 소개하여 직접적이고 다재다능한 3D 수정 범위를 제한합니다.이 작업에서는 광범위한 3D 상호 작용 기능을 통해 사용자에게 생성 프로세스에 대한 정확한 제어를 제공하는 대화식 3D 세대를위한 혁신적인 프레임 워크 인 Interactive3D를 소개합니다.Interactive3D는 별개의 3D 표현을 사용하여 두 개의 계단식 단계로 구성됩니다.첫 번째 단계는 직접 사용자 상호 작용을 위해 가우시안 스플릿을 사용하여 임의의 중간 단계에서 (i) 구성 요소 추가 및 제거, (ii) 변형 가능하고 강성 드래그, (iii) 기하학적 변환 및 (iv)시맨틱 편집.이어서, 가우스 스플 랏은 instantngp로 변형된다.우리는 소설 (v) 대화식 해시 정제 모듈을 소개하여 세부 사항을 추가로 추가하고 두 번째 단계에서 지오메트리를 추출합니다.우리의 실험은 Interactive3D가 3D 세대의 제어 성과 품질을 현저하게 향상 시킨다는 것을 보여줍니다.프로젝트 웹 페이지는 \ url {this https url}에서 사용할 수 있습니다.",2024.04.25,Shaocong Dong&&Lihe Ding&&Zhanpeng Huang&&Zibin Wang&&Tianfan Xue&&Dan Xu,arxiv,https://arxiv.org/abs/2404.16510
MaPa: Text-driven Photorealistic Material Painting for 3D Shapes,"이 백서는 텍스트 설명에서 3D 메시를위한 재료를 생성하는 것을 목표로합니다.텍스처 맵을 합성하는 기존 방법과 달리, 우리는 고품질 렌더링을 지원하고 편집에 실질적인 유연성을 제공하는 외관 표현으로 세그먼트 별 절차 자재 그래프를 생성 할 것을 제안합니다.재료 그래프 생성 모델을 훈련시키기 위해 광범위한 짝을 이루는 데이터, 즉 재료 그래프 및 해당 텍스트 설명이있는 3D 메시에 의존하는 대신, 사전 훈련 된 2D 확산 모델을 텍스트 및 재료 그래프를 연결하기위한 브리지로 활용할 것을 제안합니다.구체적으로, 우리의 접근법은 일련의 세그먼트로 모양을 분해하고 메쉬 부품과 정렬 된 2D 이미지를 합성하기 위해 세그먼트 제어 확산 모델을 설계합니다.생성 된 이미지를 기반으로, 우리는 재료 그래프의 매개 변수를 초기화하고 차별화 가능한 렌더링 모듈을 통해 그것들을 미세 조정하여 텍스트 설명에 따라 재료를 생성합니다.광범위한 실험은 기존 방법에 대한 사진, 해상도 및 편집 가능성에서 프레임 워크의 우수한 성능을 보여줍니다.프로젝트 페이지 :이 HTTPS URL",2024.04.26,Shangzhan Zhang&&Sida Peng&&Tao Xu&&Yuanbo Yang&&Tianrun Chen&&Nan Xue&&Yujun Shen&&Hujun Bao&&Ruizhen Hu&&Xiaowei Zhou,arxiv,https://arxiv.org/abs/2404.17569
BlenderAlchemy: Editing 3D Graphics with Vision-Language Models,"그래픽 디자인은 영화 제작 및 게임 디자인을 포함한 다양한 응용 프로그램에 중요합니다.고품질 장면을 만들려면 디자이너는 일반적으로 Blender와 같은 소프트웨어에서 몇 시간을 소비해야하며, 여기서 재료 노드 연결과 같은 작업을 수백 번 연결하고 반복해야 할 수도 있습니다.또한 약간 다른 설계 목표는 완전히 다른 시퀀스가 필요할 수 있으므로 자동화가 어려워집니다.이 논문에서는 GPT-4V와 같은 VLM (Vision-Language Models)을 활용하여 설계 동작 공간을 지능적으로 검색하여 사용자의 의도를 충족시킬 수있는 답변에 도달하는 시스템을 제안합니다.구체적으로, 우리는 비전 기반 편집 생성기 및 상태 평가자를 설계하여 목표를 달성하기위한 올바른 조치 순서를 찾기 위해 협력합니다.인간 디자인 프로세스에서 시각적 상상력의 역할에서 영감을 얻은 우리는 이미지 생성 모델의 ""상상 된""참조 이미지로 VLM의 시각적 추론 기능을 보완하여 추상 언어 설명의 시각적 근거를 제공합니다.이 논문에서는 우리 시스템이 텍스트 및/또는 참조 이미지의 절차 자료 편집과 같은 작업에 대한 간단하지만 지루한 블렌더 편집 시퀀스를 생성 할 수 있다는 경험적 증거를 제공하고 복잡한 장면에서 제품 렌더링을위한 조명 구성을 조정합니다.",2024.04.26,Ian Huang&&Guandao Yang&&Leonidas Guibas,arxiv,https://arxiv.org/abs/2404.17672
Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual and Action Representations,"새로운 조작 작업을 배울 수있는 자율적 인 로봇 시스템은 산업을 제조에서 서비스 자동화로 전환 할 준비가되어 있습니다.그러나, 현대의 방법 (예 : VIP 및 R3M)은 여전히 상당한 장애물, 특히 로봇 실시 예들 사이의 도메인 간격과 특정 동작 공간 내에서 성공적인 작업 실행의 희소성에 직면하여 잘못 정렬되고 모호한 작업 표현을 초래합니다.우리는 두 가지 주요 혁신을 통해 이러한 과제를 극복하기위한 프레임 워크 인 AG2Manip (Ager-Agnostic 표현)를 소개합니다. 인간 조작 비디오에서 파생 된 새로운 에이전트-비수성 시각적 표현, 구체화의 세부 사항은 일반화 성을 향상시킵니다.로봇의 운동학을 범용 에이전트 프록시로 추상화하여 엔드-효과와 물체 사이의 중요한 상호 작용을 강조하는 에이전트-공유 행동 표현.Frankakitchen, Maniskill 및 Partmanip과 같은 시뮬레이션 된 벤치 마크에서 AG2Manip의 경험적 검증은 도메인 별 시연없이 325%의 성능 증가를 보여줍니다.절제 연구는이 성공에 대한 시각적 및 행동 표현의 필수 기여를 강조합니다.AG2Manip은 실제 세계로 평가를 확장하여 모방 학습 성공률을 50%에서 77.5%로 크게 향상시켜 시뮬레이션 및 물리적 환경에서 효과와 일반화 성을 보여줍니다.",2024.04.26,Puhao Li&&Tengyu Liu&&Yuyang Li&&Muzhi Han&&Haoran Geng&&Shu Wang&&Yixin Zhu&&Song-Chun Zhu&&Siyuan Huang,arxiv,https://arxiv.org/abs/2404.17521
LEGENT: Open Platform for Embodied Agents,"대형 언어 모델 (LLMS) 및 LMM (Largin Multimodal Models)의 발전에도 불구하고 언어 지상의 인간과 같은 구체화 된 에이전트로의 통합은 불완전한 상태로 남아있어 물리적 환경에서 복잡한 실제 작업 성능을 방해합니다.기존 통합은 종종이 분야에서 제한된 오픈 소싱이 제한되어 있으며 도전적인 집단 발전을 특징으로합니다.우리는 LLM 및 LMM을 사용하여 구체화 된 제제를 개발하기위한 개방적이고 확장 가능한 플랫폼 인 Legent를 소개합니다.Legent는 이중 접근 방식을 제공합니다. 이중 접근 방식은 사용자 친화적 인 인터페이스와 함께 전달할 수 있고 실행 가능한 에이전트를 갖춘 풍부하고 대화식 3D 환경을 제공하며, 고급 알고리즘을 사용하여 정교한 데이터 생성 파이프 라인을 사용하여 규모의 시뮬레이션 된 세계에서 감독을 이용합니다.우리의 실험에서, 레지던트 생성 데이터에 대해 훈련 된 배아 시력-언어-액션 모델은 구현 된 작업에서 GPT-4V를 능가하여 유망한 일반화 기능을 보여줍니다.",2024.04.28,Zhili Cheng&&Zhitong Wang&&Jinyi Hu&&Shengding Hu&&An Liu&&Yuge Tu&&Pengkai Li&&Lei Shi&&Zhiyuan Liu&&Maosong Sun,arxiv,https://arxiv.org/abs/2404.18243
Paint by Inpaint: Learning to Add Image Objects by Removing Them First,"텍스트 조건 확산 모델의 도입으로 이미지 편집이 크게 발전했습니다.이러한 진행 상황에도 불구하고 사용자 제공 입력 마스크가 필요없이 텍스트 지침을 기반으로 이미지에 객체를 원활하게 추가하는 것은 여전히 어려운 일입니다.우리는 객체 (inpaint)를 제거하는 통찰력을 활용 하여이 마스크 내에서 입력하는 인 페인팅 모델과 함께 세분화 마스크 데이터 세트의 활용에 기인 한 객체 (inpaint)가 추가 프로세스 (페인트)보다 훨씬 간단하다는 통찰력을 활용하여이를 해결합니다.이 실현을 활용하면 자동화되고 광범위한 파이프 라인을 구현함으로써 이미지 쌍과 해당 객체에 대한 버전이 포함 된 필터링 된 대규모 이미지 데이터 세트를 선별합니다.이 쌍을 사용하여 확산 모델을 훈련시켜 입학 프로세스를 반전하여 이미지에 객체를 추가합니다.다른 편집 데이터 세트와 달리, 우리는 합성 데이터 대신 자연스러운 대상 이미지를 특징으로합니다.또한 건축 별 소스와 대상 간의 일관성을 유지합니다.또한, 우리는 큰 비전 언어 모델을 사용하여 제거 된 객체와 큰 언어 모델에 대한 자세한 설명을 제공하여 이러한 설명을 다양한 자연 언어 지침으로 변환합니다.우리는 훈련 된 모델이 질적으로나 정량적으로 기존 모델을 능가하고 지역 사회의 훈련 된 모델과 함께 대규모 데이터 세트를 출시한다는 것을 보여줍니다.",2024.04.28,Navve Wasserman&&Noam Rotstein&&Roy Ganz&&Ron Kimmel,arxiv,https://arxiv.org/abs/2404.18212
Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models,"대형 언어 모델 (LLM)이 더욱 발전함에 따라 품질을 정확하게 평가할 수있는 능력을 능가했습니다.특정 모델 속성을 적절하게 조사하기위한 데이터를 찾는 것뿐만 아니라 모델의 자유 형식 생성만으로도 정확성을 평가하는 것은 어려운 일입니다.이를 해결하기 위해 많은 평가는 이제 LLM 자체를 판사로 사용하여 다른 LLM의 출력 품질을 평가하는 데 의존합니다.평가는 가장 일반적으로 GPT4와 같은 단일 대형 모델을 사용합니다.이 방법은 인기가 높아졌지만 비용이 많이 들고, 모드 내 바이어스를 도입하는 것으로 나타 났으며,이 작업에서는 매우 큰 모델이 종종 불필요하다는 것을 알 수 있습니다.대신 LLM 평가자 (Poll) 패널을 사용하여 모델을 평가할 것을 제안합니다.3 개의 별개의 판사 설정과 6 개의 다른 데이터 세트에 걸쳐있어, 우리는 더 많은 수의 소규모 모델로 구성된 여론 조사를 사용하여 단일 대형 판사를 능가하고, 분리 모델 패밀리의 구성으로 인해 모델 내 바이어스가 덜 나타납니다.7 배 이상 저렴합니다.",2024.04.29,Pat Verga&&Sebastian Hofstatter&&Sophia Althammer&&Yixuan Su&&Aleksandra Piktus&&Arkady Arkhangorodsky&&Minjie Xu&&Naomi White&&Patrick Lewis,arxiv,https://arxiv.org/abs/2404.18796
Stylus: Automatic Adapter Selection for Diffusion Models,"더 많은 데이터 또는 매개 변수로 기본 모델을 확장하는 것 외에도 미세 조정 된 어댑터는 비용이 절감되면 높은 충실도, 사용자 정의 이미지를 생성하는 대안적인 방법을 제공합니다.따라서 어댑터는 오픈 소스 커뮤니티에서 널리 채택되어 100k 이상의 어댑터 데이터베이스를 축적하여 불충분 한 설명으로 고도로 사용자 정의됩니다.이 논문은 프롬프트를 어댑터 작곡의 성능 이득을 강조하는 최근 작업을 기반으로하는 관련 어댑터 세트와 프롬프트를 일치시키는 문제를 탐구합니다.프롬프트의 키워드를 기반으로 작업 별 어댑터를 효율적으로 선택하고 자동 구성하는 스타일러스를 소개합니다.스타일러스는 먼저 설명 및 임베딩이 개선 된 어댑터를 요약하고 관련 어댑터를 검색 한 다음 프롬프트의 키워드를 기반으로 어댑터를 추가로 조립하는 3 단계 접근 방식을 설명합니다.스타일러스를 평가하기 위해, 우리는 미리 컴퓨터 어댑터 임베딩이있는 75k 어댑터를 특징으로하는 선별 된 데이터 세트 인 Stylusdocs를 개발했습니다.인기있는 안정적인 확산 체크 포인트에 대한 우리의 평가에서 Stylus는 더 큰 클립 고정 파레토 효율을 달성하고 기본 모델보다 평가자로서 인간과 멀티 모달 모델을 사용하여 선호하는 것보다 두 배입니다.Seethis http urlfor more.",2024.04.29,Michael Luo&&Justin Wong&&Brandon Trabucco&&Yanping Huang&&Joseph E. Gonzalez&&Zhifeng Chen&&Ruslan Salakhutdinov&&Ion Stoica,arxiv,https://arxiv.org/abs/2404.18928
Capabilities of Gemini Models in Medicine,"다양한 의료 응용 프로그램의 우수성은 AI에 대한 상당한 과제를 제기하며, 고급 추론, 최신 의료 지식에 대한 접근 및 복잡한 멀티 모달 데이터에 대한 이해가 필요합니다.다중 모드 및 장기 텍스트 추론에 강력한 일반적인 기능을 갖춘 Gemini 모델은 의학에서 흥미로운 가능성을 제공합니다.우리는 이러한 핵심 강점을 바탕으로 웹 검색을 원활하게 사용할 수있는 의약품을 전문으로하는 유능한 다중 모드 모델의 가족 인 Med-Gemini를 소개합니다.우리는 14 개의 의료 벤치 마크에서 Med-Gemini를 평가하고, 그 중 10 개에 대한 새로운 최첨단 (SOTA) 공연을 확립하고 직접 비교가 가능한 모든 벤치 마크에서 GPT-4 모델 패밀리를 능가합니다.여유.인기있는 MEDQA (USMLE) 벤치 마크에서, 우리의 가장 성능이 좋은 Med-Gemini 모델은 새로운 불확실성 유도 검색 전략을 사용하여 91.1% 정확도의 SOTA 성능을 달성합니다.NEJM Image Challenges 및 MMMU (Health & Medicine)를 포함한 7 개의 멀티 모달 벤치 마크에서 Med-Gemini는 평균 상대 마진이 44.5%로 GPT-4V보다 향상됩니다.우리는 긴 식별 된 건강 기록과 의료 비디오 질문에 대한 바늘-인-하이 스택 검색 작업에서 SOTA 성능을 통해 Med-Gemini의 장기 텍스트 기능의 효과를 보여줍니다.마지막으로, Med-Gemini의 성과는 의료 텍스트 요약과 같은 작업에 대한 인간 전문가를 능가함으로써 실제 의료 대화, 의료 연구 및 교육에 대한 유망한 잠재력에 대한 시연과 함께 실제 유틸리티를 제안합니다.종합하면, 우리의 결과는 Med-Gemini의 잠재력에 대한 강력한 증거를 제공하지만,이 안전 중요 도메인의 실제 배치 전에 더 엄격한 평가가 중요 할 것입니다.",2024.04.29,Khaled Saab&&Tao Tu&&Wei-Hung Weng&&Ryutaro Tanno&&David Stutz&&Ellery Wulczyn&&Fan Zhang&&Tim Strother&&Chunjong Park&&Elahe Vedadi&&Juanma Zambrano Chaves&&Szu-Yeu Hu&&Mike Schaekermann&&Aishwarya Kamath&&Yong Cheng&&David G.T. Barrett&&Cathy Cheung&&Basil Mustafa&&Anil Palepu&&Daniel McDuff&&Le Hou&&Tomer Golany&&Luyang Liu&&Jean-baptiste Alayrac&&Neil Houlsby&&Nenad Tomasev&&Jan Freyberg&&Charles Lau&&Jonas Kemp&&Jeremy Lai&&Shekoofeh Azizi&&Kimberly Kanada&&SiWai Man&&Kavita Kulkarni&&Ruoxi Sun&&Siamak Shakeri&&Luheng He&&Ben Caine&&Albert Webson&&Natasha Latysheva&&Melvin Johnson&&Philip Mansfield&&Jian Lu&&Ehud Rivlin&&Jesper Anderson&&Bradley Green&&Renee Wong&&Jonathan Krause&&Jonathon Shlens&&Ewa Dominowska&&S. M. Ali Eslami&&Katherine Chou&&Claire Cui&&Oriol Vinyals&&Koray Kavukcuoglu&&James Manyika&&Jeff Dean&&Demis Hassabis&&Yossi Matias&&Dale Webster&&Joelle Barral&&Greg Corrado&&Christopher Semturs&&S. Sara Mahdavi&&Juraj Gottweis&&Alan Karthikesalingam&&Vivek Natarajan,arxiv,https://arxiv.org/abs/2404.18416
Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting,"투기 디코딩은 일관된 샘플링 분포를 유지하면서 큰 언어 모델의 추론을 가속화하는 데있어 효과를 입증했습니다.그러나 만족스러운 토큰 수용률을 달성하기 위해 별도의 초안 모델을 훈련시키는 기존의 접근 방식은 비용이 많이들 수 있습니다.초기 출구에서 영감을 얻은 우리는 새로운 자기 구체화 디코딩 프레임 워크 \ orth {kangaroo}를 제안합니다. 이는 고정 된 얕은 하위 네트워크를 셀프 드래프트 모델로 사용하고 나머지 레이어는 더 큰 대상 모델로 사용됩니다.하위 네트워크와 전체 모델의 표현 능력 사이의 간격을 연결하기 위해 하위 네트워크 위에 가볍고 효율적인 어댑터 모듈을 훈련시킵니다.셀프 드래프트 모델의 추론 대기 시간은 대형 모델에 비해 더 이상 무시할 수 없으므로 소규모 모델의 제도 단계를 최소화하면서 토큰 수용률을 높이기위한 전략이 필요합니다.이 도전을 해결하기 위해 초안 토큰을 생성하기위한 추가 초기 출구 메커니즘을 소개합니다.구체적으로, 우리는 현재 토큰에 대한 신뢰 수준이 특정 임계 값 아래로 떨어지면 초안 단계에서 소규모 모델의 후속 예측을 중단시킵니다.사양에 대한 광범위한 실험은 캥거루의 효과를 보여줍니다.단일 시퀀스 검증 하에서 Kangaroo는 최대 1.68 \ Timeson Spec-Bench의 속도를 달성하여 88.7 \% 더 적은 추가 매개 변수 (591m에 비해 67m)로 MEDUSA-1을 능가합니다.Kangaroo 코드는 https url에서 사용할 수 있습니다.",2024.04.29,Fangcheng Liu&&Yehui Tang&&Zhenhua Liu&&Yunsheng Ni&&Kai Han&&Yunhe Wang,arxiv,https://arxiv.org/abs/2404.18911
SAGS: Structure-Aware 3D Gaussian Splatting,"NERFS의 출현으로 3D Gaussian Splatting (3D-GS)은 체적 방법의 계산 부담을 극복하는 실시간 신경 렌더링의 길을 열었습니다.3D-GS의 선구적인 작업에 이어 몇 가지 방법이 압축성 및 고유 성능 성능 대안을 달성하려고 시도했습니다.그러나, 지오메트리-비 공연 최적화 체계를 사용함으로써, 이들 방법은 장면의 고유 한 3D 구조를 무시하여 표현의 표현성과 품질을 제한하여 다양한 부동 소수점과 아티팩트를 초래한다.이 작업에서 우리는 장면의 형상을 암시 적으로 인코딩하는 구조 인식 가우시안 스플 팅 방법 (SAGS)을 제안하며, 이는 최신 렌더링 성능 및 벤치 마크 소설 뷰 합성 데이터 세트의 저장 요구 사항을 반영합니다.SAGS는 복잡한 장면에 대한 학습을 용이하게하고 장면의 기하학을 보존하는 의미있는 포인트 변위를 강화하는 로컬 글로벌 그래프 표현에 기반을두고 있습니다.또한 간단하면서도 효과적인 미드 포인트 보간 체계를 사용하여 경량 버전의 SAG를 소개합니다. 이는 압축 전략에 의존하지 않고 최대 24 \ timessize 감소로 장면의 소형 표현을 보여줍니다.다수의 벤치 마크 데이터 세트에서 광범위한 실험은 렌더링 품질과 모델 크기 모두에서 최첨단 3D-GS 방법에 비해 SAG의 우수성을 보여줍니다.게다가, 우리는 우리의 구조 인식 방법이 정확한 깊이 맵을 얻는 동시에 플로팅 아티팩트와 이전 방법의 불규칙한 왜곡을 효과적으로 완화 할 수 있음을 보여줍니다.프로젝트 pagethis https url.",2024.04.29,Evangelos Ververas&&Rolandos Alexandros Potamias&&Jifei Song&&Jiankang Deng&&Stefanos Zafeiriou,arxiv,https://arxiv.org/abs/2404.19149
"LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report","LORA (Low Rank Adaptation)는 LLM (Lange Language Models)의 PEFT (Parameter Efficiful Fine Tuning)를위한 가장 널리 채택 된 방법 중 하나로 부상했습니다.LORA는 훈련 가능한 매개 변수 및 메모리 사용량 수를 줄이면서 완전한 미세 조정과 비슷한 성능을 달성합니다.우리는 실제 응용 프로그램에서 LORA와 미세 조정 된 LLMS 교육 및 서비스의 생존력을 평가하는 것을 목표로합니다.먼저, 우리는 10 개의베이스 모델에서 양자화 된 저급 어댑터와 총 310 개의 모델에 대한 31 개의 작업에 미세 조정 된 LLM의 품질을 측정합니다.우리는 4 비트 로라 미세 조정 모델이 기본 모델보다 평균적으로 10 점 x 기본 모델을 능가한다는 것을 발견했습니다.둘째, 미세 조정을위한 가장 효과적인 기본 모델을 조사하고 미세 조정의 결과를 예측할 때 작업 복잡성 휴리스틱의 상관 및 예측 용량을 평가합니다.마지막으로, 공유 기본 모델 가중치 및 동적 어댑터 로딩을 사용하여 단일 GPU에 여러 LORA 미세 조정 모델의 배포를 용이하게하는 오픈 소스 멀티 로라 추론 서버 인 Lorax의 대기 시간 및 동시성 기능을 평가합니다.Lorax는 80GB 메모리를 갖춘 단일 NVIDIA A100 GPU에서 25 LORA 미세 조정 된 Mistral-7B LLM을 호스팅하는 웹 응용 프로그램 인 Lora Land를 Powers에 파워합니다.Lora Land는 단일 일반 목적 LLM에 걸쳐 여러 전문 LLM을 사용하는 품질과 비용 효율성을 강조합니다.",2024.04.29,Justin Zhao&&Timothy Wang&&Wael Abid&&Geoffrey Angus&&Arnav Garg&&Jeffery Kinnison&&Alex Sherstinsky&&Piero Molino&&Travis Addair&&Devvret Rishi,arxiv,https://arxiv.org/abs/2405.00732
Better & Faster Large Language Models via Multi-token Prediction,"GPT 및 LLAMA와 같은 대규모 언어 모델은 차세대 예측 손실로 훈련됩니다.이 작업에서 우리는 여러 미래의 토큰을 한 번에 예측하는 교육 모델이 샘플 효율이 높아질 것을 제안합니다.보다 구체적으로, 훈련 코퍼스의 각 위치에서, 우리는 공유 모델 트렁크 위에서 작동하는 N 독립적 인 출력 헤드를 사용하여 다음 n 토큰을 예측하도록 모델에 요청합니다.보조 훈련 작업으로서 멀티 토킹 예측을 고려할 때 코드 및 자연어 모델 모두에 대한 교육 시간이 오버 헤드없이 개선 된 다운 스트림 기능을 측정합니다.이 방법은 더 큰 모델 크기에 점점 더 유용 해지고 있으며 여러 시대에 대한 훈련시 호소력을 유지합니다.이익은 특히 코딩과 같은 생성 벤치 마크에서 두드러지며, 우리의 모델은 강력한 기준선을 몇 퍼센트 포인트로 지속적으로 능가합니다.우리의 13b 매개 변수 모델은 Humaneval에서 12 % 더 많은 문제를 해결하고 MBPP에서는 비슷한 차세대 모델보다 17 % 더 많은 문제를 해결합니다.소규모 알고리즘 작업에 대한 실험은 유도 헤드 및 알고리즘 추론 능력의 개발에 다중 점화 예측이 유리하다는 것을 보여줍니다.추가 혜택으로, 4- 토큰 예측으로 훈련 된 모델은 대량 배치 크기로도 최대 3 배 더 빠릅니다.",2024.04.30,Fabian Gloeckle&&Badr Youbi Idrissi&&Baptiste Rozière&&David Lopez-Paz&&Gabriel Synnaeve,arxiv,https://arxiv.org/abs/2404.19737
Extending Llama-3's Context Ten-Fold Overnight,"우리는 Qlora 미세 조정을 통해 Llama-3-8b-비를 8k에서 80k로 확장합니다.전체 훈련주기는 매우 효율적이며 8xA800 (80G) GPU 기계에서 8 시간이 걸립니다.그 결과 모델은 NIHS, 주제 검색 및 장기 텍스트 언어 이해와 같은 광범위한 평가 작업에서 우수한 성능을 보여줍니다.한편, 그것은 또한 짧은 상황에 비해 원래의 기능을 잘 보존합니다.극적인 맥락 확장은 주로 GPT-4에 의해 생성 된 3.5K 합성 훈련 샘플에 기인하며, 이는 LLMS의 고유 (아직 과소 평가 된) 원래 컨텍스트 길이를 확장 할 가능성을 나타냅니다.실제로, 컨텍스트 길이는 더 많은 계산 자원으로 80k 이상으로 확장 될 수 있습니다.따라서 팀은 커뮤니티의 향후 연구를 용이하게하기 위해 전체 리소스 (데이터, 모델, 데이터 생성 파이프 라인, 교육 코드 포함)를 공개적으로 공개합니다. \ url {this https url}.",2024.04.30,Peitian Zhang&&Ninglu Shao&&Zheng Liu&&Shitao Xiao&&Hongjin Qian&&Qiwei Ye&&Zhicheng Dou,arxiv,https://arxiv.org/abs/2404.19553
Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation,"시각적 컨텐츠를위한 기존 자동 캡션 방법은 세부 사항 부족, 컨텐츠 환각 및 다음과 같은 지침과 같은 문제에 직면합니다.이 작업에서는 2D 이미지와 3D 객체 모두에 대한 고 충실도 및 세부 캡션을 생성하는 유연한 교육이없는 파이프 라인 인 VisualFactchecker (VFC)를 제안합니다.VFC는 세 가지 단계로 구성됩니다. 1) 제안서, 이미지-텍스트 캡션 모델은 여러 초기 캡션을 제안합니다.2) 큰 언어 모델 (LLM)이 객체 감지 및 VQA 모델과 같은 도구를 사용하여 제안 된 캡션을 사실 확인하기 위해 검증;3) 캡션, LLM이 캡션 제안을 요약하고 사실 확인 확인 결과를 요약하여 최종 캡션을 생성합니다.이 단계에서 VFC는 복잡한 지침에 따라 다양한 스타일로 캡션을 유연하게 생성 할 수 있습니다.우리는 네 가지 메트릭을 사용하여 포괄적 인 캡션 평가를 수행합니다. 1) 이미지 텍스트 유사성을위한 클립 스코어;2) 캡션을 사용하여 텍스트-이미지 모델에 의해 생성 된 원본과 재구성 된 이미지 사이의 이미지 이미지 유사성을 측정하기위한 클립 이미지 점수.3) 아마존 기계식 터크에 대한 인간 연구;4) 세분화 된 평가를위한 GPT-4V.평가 결과에 따르면 VFC는 Coco 데이터 세트의 2D 이미지에 대한 최첨단 오픈 소스 캡션 방법을 능가하고 Objaverse 데이터 세트의 3D 자산을 능가합니다.우리의 연구는 오픈 소스 모델을 파이프 라인으로 결합함으로써 모델 크기가 10 배 이상 작음에도 불구하고 GPT-4V와 같은 독점 모델과 비슷한 캡션 기능을 얻을 수 있음을 보여줍니다.",2024.04.30,Yunhao Ge&&Xiaohui Zeng&&Jacob Samuel Huffman&&Tsung-Yi Lin&&Ming-Yu Liu&&Yin Cui,arxiv,https://arxiv.org/abs/2404.19752
Octopus v4: Graph of language models,"언어 모델은 광범위한 응용 분야에서 효과적 이었지만 가장 정교한 모델은 종종 독점적입니다.예를 들어, OpenAI의 GPT-4 및 Anthropic의 다양한 모델은 비싸고 상당한 에너지를 소비합니다.대조적으로, 오픈 소스 커뮤니티는 LLAMA3과 같은 경쟁 모델을 제작했습니다.또한, 법적, 의료 또는 재무 업무를 위해 맞춤화 된 것과 같은 틈새 별 소규모 언어 모델은 독점적 인 상대를 능가했습니다.이 논문은 \ textit {functional tokens}를 사용하여 각각의 특정 작업에 최적화 된 \ textbf {다중 오픈 소스 모델}을 통합하는 새로운 접근법을 소개합니다.새로 개발 된 Octopus v4 모델은 \ textit {functional tokens}를 활용하여 가장 적절한 수직 모델로 사용자 쿼리를 지능적으로 직접 지시하고 최상의 성능을 달성하기 위해 쿼리를 재구성합니다.문어 V1, V2 및 V3 모델의 진화 인 Octopus V4는 선택 및 파라미터 이해 및 개혁이 뛰어납니다.또한 Octopus 모델 및 \ textit {functional tokens}의 기능을 활용하여 여러 개방형 소스 모델을 효과적으로 조정하는 다재다능한 데이터 구조로 그래프 사용을 탐색합니다.Open-Sourced Github (\ url {this https url})을 사용하여 Octopus v4 모델 (\ url {this https url})을 사용하고 더 큰 언어 모델 그래프에 제기하십시오.10B 매개 변수 미만의 모델을 활성화함으로써 동일한 레벨 모델 중에서 SOTA MMLU 점수 74.8을 달성했습니다.",2024.04.30,Wei Chen&&Zhiyuan Li,arxiv,https://arxiv.org/abs/2404.19296
MotionLCM: Real-time Controllable Motion Generation via Latent Consistency Model,"이 작업은 MotionLCM을 소개하여 제어 가능한 모션 생성을 실시간 수준으로 확장합니다.텍스트 통화 모션 생성에서 공간 제어를위한 기존 방법은 상당한 런타임 비 효율성으로 어려움을 겪고 있습니다.이 문제를 해결하기 위해 먼저 잠재 확산 모델 (MLD)을 바탕으로 모션 생성에 대한 모션 잠재적 일관성 모델 (MotionLCM)을 제안합니다.1 단계 (또는 적은 단계) 추론을 사용함으로써, 우리는 모션 생성을위한 모션 잠재 확산 모델의 런타임 효율을 더욱 향상시킵니다.효과적인 제어 가능성을 보장하기 위해 MotionLCM의 잠재적 공간 내에 모션 컨트롤 네트를 통합하고 바닐라 모션 공간에서 명시 적 제어 신호 (예 : 골반 궤적)를 활성화하여 생성 공정을 직접 제어하여 동작을위한 다른 잠재적 인 확산 모델을 제어하는 것과 유사합니다.세대.이러한 기술을 사용함으로써, 우리의 접근 방식은 텍스트와 제어 신호를 실시간으로 인간 운동을 생성 할 수 있습니다.실험 결과는 실시간 런타임 효율을 유지하면서 MotionLCM의 놀라운 생성 및 제어 기능을 보여줍니다.",2024.04.30,Wenxun Dai&&Ling-Hao Chen&&Jingbo Wang&&Jinpeng Liu&&Bo Dai&&Yansong Tang,arxiv,https://arxiv.org/abs/2404.19759
GS-LRM: Large Reconstruction Model for 3D Gaussian Splatting,"우리는 단일 A100 GPU에서 0.23 초 안에 2-4 포즈의 스파 스 이미지에서 고품질 3D 가우시안 프리미티브를 예측할 수있는 확장 가능한 대형 재구성 모델 인 GS-LRM을 제안합니다.우리의 모델은 매우 간단한 변압기 기반 아키텍처를 특징으로합니다.우리는 입력 포즈 이미지를 패치하고, 일련의 변압기 블록을 통해 연결된 멀티 뷰 이미지 토큰을 전달하고, 차별화 가능한 렌더링을 위해 이러한 토큰에서 직접 최종 픽셀 당 가우시안 매개 변수를 디코딩합니다.GS-LRM은 픽셀 당 가우시안을 예측하여 물체 만 재구성 할 수있는 이전 LRM과 달리 자연스럽게 스케일과 복잡성이 큰 장면을 처리합니다.우리는 우리의 모델이 Objaverse 및 Realestate10K에서 각각 훈련하여 객체 및 장면 캡처에서 작동 할 수 있음을 보여줍니다.두 시나리오 모두 에서이 모델은 최첨단 기준선보다 큰 마진보다 성능이 뛰어납니다.또한 다운 스트림 3D 세대 작업에서 모델의 응용 프로그램을 보여줍니다.프로젝트 웹 페이지는 다음과 같습니다.이 HTTPS URL.",2024.04.30,Kai Zhang&&Sai Bi&&Hao Tan&&Yuanbo Xiangli&&Nanxuan Zhao&&Kalyan Sunkavalli&&Zexiang Xu,arxiv,https://arxiv.org/abs/2404.19702
MicroDreamer: Zero-shot 3D Generation in\sim20 Seconds by Score-based Iterative Reconstruction,"스코어 증류 샘플링 (SDS)과 같은 최적화 기반 접근법은 제로 샷 3D 세대에서 약속을 보여 주지만 주로 각 샘플에 필요한 NFES (Noth of Function Evaluations)로 인해 효율이 낮습니다.이 논문에서는 멀티 뷰 스코어 기반 확산 모델을 갖춘 3D 세대를위한 효율적이고 일반적인 알고리즘 인 SIR (Score Based Ierative Reconstruction)을 소개합니다.확산 모델에 의해 생성 된 이미지를 고려할 때, SIR은 3D 재구성 프로세스를 모방하는 SDS의 단일 최적화와 달리 3D 매개 변수를 반복적으로 최적화하여 NFE를 줄입니다.픽셀 공간에서의 최적화를 포함한 다른 개선 사항으로, 우리는 일반적으로 다양한 3D 표현 및 3D 세대 작업에 적용되는 MicrodReamer라는 효율적인 접근법을 제시합니다.특히, 비슷한 성능을 유지하는 Microdreamer는 신경 방사선 필드를 생성 할 때 SDS보다 5-20 배 빠르며 단일 A100 GPU에서 3D 가우시안 분할에서 메쉬를 생성하는 데 약 20 초가 걸리며 가장 빠른 제로 샷 기준선의 시간을 절반으로 줄입니다., Dreamgaussian.우리의 코드는 https url에서 사용할 수 있습니다.",2024.04.30,Luxi Chen&&Zhengyi Wang&&Chongxuan Li&&Tingting Gao&&Hang Su&&Jun Zhu,arxiv,https://arxiv.org/abs/2404.19525
Invisible Stitch: Generating Smooth 3D Scenes with Depth Inpainting,"3D 장면 생성은 2D 생성 확산 모델의 일관된 개선으로 인해 빠르게 도전적인 새로운 연구 방향이되었습니다.이 영역의 대부분의 이전 작업은 기존 형상과 함께 새로 생성 된 프레임을 반복적으로 스티칭하여 장면을 생성합니다.이 작업은 종종 미리 훈련 된 단안 깊이 추정기에 의존하여 생성 된 이미지를 3D로 들어 올려 기존 장면 표현으로 융합합니다.그런 다음 이러한 접근법은 종종 텍스트 메트릭을 통해 평가되어 생성 된 이미지와 주어진 텍스트 프롬프트 사이의 유사성을 측정합니다.이 작업에서 우리는 3D 장면 생성 분야에 두 가지 근본적인 기여를합니다.먼저, 단안 깊이 추정 모델로 이미지를 3D로 들어 올리는 것은 기존 장면의 형상을 무시하기 때문에 차선책이 있습니다.따라서 우리는 교사 증류 및 자체 훈련을 통해 훈련 된 새로운 깊이 완성 모델을 소개하여 3D 퓨전 프로세스를 배우고 장면의 기하학적 일관성이 향상되었습니다.둘째, 지상 진실 지오메트리를 기반으로하는 장면 생성 방법에 대한 새로운 벤치마킹 체계를 소개하므로 장면 구조의 품질을 측정합니다.",2024.04.30,Paul Engstler&&Andrea Vedaldi&&Iro Laina&&Christian Rupprecht,arxiv,https://arxiv.org/abs/2404.19758
KAN: Kolmogorov-Arnold Networks,"Kolmogorov-arnold 표현 정리에서 영감을 얻은 우리는 kolmogorov-arnold 네트워크 (캔)를 다층 퍼셉트론 (MLP)에 대한 유망한 대안으로 제안합니다.MLP는 노드 ( ""뉴런"")에서 고정 활성화 기능을 가지고 있지만 캔자는 가장자리에서 학습 가능한 활성화 기능을 가지고 있습니다 ( ""weights"").Kans는 선형 가중치가 전혀 없습니다. 모든 중량 매개 변수는 스플라인으로 매개 변수화 된 일 변량 기능으로 대체됩니다.우리는이 간단한 변화가 캔스가 정확성과 해석 성 측면에서 MLP를 능가하게 만든다는 것을 보여줍니다.정확도를 위해, 훨씬 작은 캔자는 데이터 피팅 및 PDE 해결에서 훨씬 더 큰 MLP보다 비슷하거나 더 나은 정확도를 달성 할 수 있습니다.이론적으로나 경험적으로 캔자는 MLP보다 빠른 신경 스케일링 법을 보유하고 있습니다.해석 가능성을 위해 캔은 직관적으로 시각화 될 수 있으며 사람과 쉽게 상호 작용할 수 있습니다.수학과 물리학의 두 가지 예를 통해 캔자는 과학자들이 수학적 및 물리 법칙을 발견하는 데 도움이되는 유용한 공동 작업자 인 것으로 나타났습니다.요약하면, 캔은 MLP에 대한 유망한 대안이며 MLP에 크게 의존하는 오늘날의 딥 러닝 모델을 더욱 향상시킬 수있는 기회를 열었습니다.",2024.04.30,Ziming Liu&&Yixuan Wang&&Sachin Vaidya&&Fabian Ruehle&&James Halverson&&Marin Soljačić&&Thomas Y. Hou&&Max Tegmark,arxiv,https://arxiv.org/abs/2404.19756
DOCCI: Descriptions of Connected and Contrasting Images,"비전 언어 데이터 세트는 T2I (Text-to-Image) 및 I2T (Image-to-Text) 연구 모두에 필수적입니다.그러나 현재 데이터 세트에는 세부적인 세부 사항이있는 설명이 부족하여 모델이 더 풍부한 연관성을 배울 수 있습니다.격차를 메우기 위해, 우리는 공간적 관계와 같은 주요 과제를 포착하려는 단일 연구원에 의해 촬영, 큐 레이션 및 기증 된 15K 이미지에 대한 길고 인간이 발표 된 영어 설명이있는 데이터 세트 인 DOCCI (Dataet)에 대한 설명을 소개합니다., 계산, 텍스트 렌더링, 세계 지식 등.우리는 인간 주석기에 각 이미지에 대한 포괄적 인 설명을 만들도록 지시합니다.이 평균 136 단어 길이는 각 이미지를 관련이거나 유사한 단어와 명확하게 구별하도록 제작되었습니다.각 설명은 구성 적이며 일반적으로 여러 가지 과제를 포함합니다.정량적 및 질적 분석을 통해 DOCCI는 이미지-텍스트 생성을위한 효과적인 교육 자원 역할을합니다.그리고 instructblip 7b.또한 DOCCI는 텍스트-이미지 생성에 유용한 테스트 베드임을 보여줍니다. 긴 설명과 세부 사항을 캡처 할 때 현재 텍스트-이미지 모델의 한계를 강조합니다.",2024.04.30,Yasumasa Onoe&&Sunayana Rane&&Zachary Berger&&Yonatan Bitton&&Jaemin Cho&&Roopal Garg&&Alexander Ku&&Zarana Parekh&&Jordi Pont-Tuset&&Garrett Tanzer&&Su Wang&&Jason Baldridge,arxiv,https://arxiv.org/abs/2404.19753
Iterative Reasoning Preference Optimization,"반복적 인 선호도 최적화 방법은 최근 일반 지시 조정 작업에 잘 작동하는 것으로 나타 났지만 일반적으로 추론 작업은 거의 개선되지 않습니다 (Yuan et al., 2024, Chen et al., 2024).이 작업에서 우리는 우승을 최적화함으로써 경쟁 생성 된 체인 (COT) 후보자 간의 선호도를 최적화하는 반복적 인 접근 방식을 개발합니다.우리는 추가적인 음의 로그-원성 용어와 함께 수정 된 DPO 손실 (Rafailov et al., 2023)을 사용하여 훈련합니다.우리는이 체계의 반복적 인 반복에 걸쳐 추론이 개선된다는 것을 보여줍니다.훈련 세트의 예제에만 의존하지만, 우리의 접근 방식은 LLAMA-2-70B-Chat의 GSM8K, Math 및 Arc-Challenge에 대한 정확도를 높이고 다른 LLAMA-2 기반 모델을 능가하는 것도 추가로 공급되는 데이터 세트에 의존하지 않습니다.예를 들어, 우리는 GSM8K에서 55.6%에서 81.6%로 크게 개선되었으며 32 개 샘플 중 대다수의 투표로 88.7%의 정확도가 높아집니다.",2024.04.30,Richard Yuanzhe Pang&&Weizhe Yuan&&Kyunghyun Cho&&He He&&Sainbayar Sukhbaatar&&Jason Weston,arxiv,https://arxiv.org/abs/2404.19733
Lightplane: Highly-Scalable Components for Neural 3D Fields,"특히 재건 및 세대 분야에서 현대 3D 연구는 입력 또는 감독을위한 2D 이미지에 크게 의존합니다.그러나이 2D-3D 매핑에 대한 현재 설계는 메모리 집약적이며 기존 방법에 대한 상당한 병목 현상을 제기하고 새로운 응용 프로그램을 방해합니다.이에 따라, 우리는 3D 신경 필드 : LightPlane Render and Splatter에 대한 고도로 확장 가능한 구성 요소를 제안하여 2D-3D 매핑에서 메모리 사용량을 크게 줄입니다.이러한 혁신으로 인해 메모리와 계산 비용이 작고 훨씬 더 높은 해상도 이미지를 처리 할 수 있습니다.우리는 이미지 수준 손실로 단일 스카네 최적화에 이익을 얻는 것부터 3D 재구성 및 생성을 극적으로 확장하기위한 다용도 파이프 라인 실현에 이르기까지 다양한 응용 분야에서 유틸리티를 보여줍니다.코드 : \ url {this https url}.",2024.04.30,Ang Cao&&Justin Johnson&&Andrea Vedaldi&&David Novotny,arxiv,https://arxiv.org/abs/2404.19760
InstantFamily: Masked Attention for Zero-shot Multi-ID Image Generation,"개인화 된 이미지 생성 분야에서 개념을 유지하는 이미지를 생성하는 기능이 크게 향상되었습니다.자연스럽게 여러 개념을 응집력 있고 시각적으로 매력적인 구성에 자연스럽게 통합하는 이미지를 만드는 것은 실제로 어려울 수 있습니다.이 논문은 ""Instantfamily""를 소개합니다. ""Instantfamily""는 새로운 마스크 교차 변형 메커니즘과 멀티 모달 임베딩 스택을 사용하여 제로 샷 멀티 ID 이미지 생성을 달성하는 접근법을 소개합니다.우리의 방법은 텍스트 조건과 통합 된 미리 훈련 된 얼굴 인식 모델의 글로벌 및 로컬 기능을 활용하므로 ID를 효과적으로 보존합니다.또한, 마스크 된 크로스-해소 메커니즘은 생성 된 이미지에서 다중 ID 및 구성의 정확한 제어를 가능하게합니다.우리는 잘 알려진 다중 생성 문제를 해결하는 동시에 멀티 ID로 이미지를 생성하는 데있어서 우위를 보여주는 실험을 통해 인스턴 패밀리의 효과를 보여줍니다.또한, 우리의 모델은 단일 ID 및 다중 ID 보존 모두에서 최첨단 성능을 달성합니다.또한, 우리의 모델은 원래 훈련을받은 것보다 더 많은 수의 ID 보존으로 현저한 확장 성을 나타냅니다.",2024.04.30,Chanran Kim&&Jeongin Lee&&Shichang Joung&&Bongmo Kim&&Yeul-Min Baek,arxiv,https://arxiv.org/abs/2404.19427
SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound,"LLMS (Lange Language Models)는 오디오 코덱을 통해 오디오 모델링 기술을 오디오 데이터에 적용 할 수 있도록 오디오 코덱을 통해 오디오 처리가 크게 발전했습니다.그러나 전통적인 코덱은 종종 높은 비트 전속기 또는 음성과 같은 좁은 영역 내에서 작동하며 효율적인 언어 모델링에 필요한 의미 론적 단서가 부족합니다.이러한 과제를 해결하면서, 우리는 품질을 손상시키지 않으면 서 Speech, General Audio 및 Music을 포함한 다양한 오디오 유형에 걸쳐 오디오를 초당 100 초 미만의 토큰으로 압축하도록 설계된 새로운 코덱 인 SemanticOdec을 소개합니다.SemanticOdec은 듀얼 인코더 아키텍처를 특징으로하며, 자체 감독 된 오디오 메이를 사용하는 시맨틱 인코더, 광범위한 오디오 데이터에 대한 K- 평균 클러스터링을 사용하여 이산화 된 Semantic Encoder 및 남은 세부 사항을 캡처하기 위해 음향 인코더를 사용합니다.시맨틱 및 음향 인코더 출력은 확산 모델 기반 디코더를 통해 오디오를 재구성하는 데 사용됩니다.Semanticodec은 초당 25, 50 및 100의 토큰 속도를 갖는 3 가지 변형으로 제시되며, 0.31kbps와 1.43kbps 사이의 초저 비트 비율의 범위를 지원합니다.실험 결과 SemanticOdec이 재구성 품질에 대한 최첨단 설명 코덱보다 훨씬 능숙하다는 것을 보여줍니다.우리의 결과 SemanticOdec은 비트 전송률이 상당히 낮아도 모든 평가 된 오디오 코덱보다 시맨틱 정보가 상당히 풍부한 의미 정보를 포함하고 있음을 시사합니다.우리의 코드와 데모는 https url에서 사용할 수 있습니다.",2024.04.30,Haohe Liu&&Xuenan Xu&&Yi Yuan&&Mengyue Wu&&Wenwu Wang&&Mark D. Plumbley,arxiv,https://arxiv.org/abs/2405.00233
STT: Stateful Tracking with Transformers for Autonomous Driving,"3 차원 공간에서 물체를 추적하는 것은 자율 주행에 중요합니다.운전 중 안전을 보장하기 위해 추적기는 프레임에서 객체를 안정적으로 추적하고 현재의 속도 및 가속도와 같은 상태를 정확하게 추정 할 수 있어야합니다.기존 작업은 종종 협회 작업에 중점을 두면서 상태 추정에 대한 모델 성능을 무시하거나 국가를 예측하기 위해 복잡한 휴리스틱을 배치합니다.이 논문에서는 트랜스포머로 제작 된 상태가 풍부한 추적 모델 인 STT를 제안하며, 이는 장면에서 일관되게 추적하면서 상태를 정확하게 예측할 수 있습니다.STT는 장기 탐지 이력을 통해 풍부한 외관, 형상 및 모션 신호를 소비하며 데이터 연관성 및 상태 추정 작업 모두에 공동으로 최적화됩니다.Mota 및 MOTP와 같은 표준 추적 메트릭은 더 넓은 객체 상태에서 두 작업의 결합 된 성능을 캡처하지 않기 때문에이 한계를 해결하는 S-Mota 및 MOTP라는 새로운 메트릭으로 확장합니다.STT는 Waymo Open 데이터 세트에서 경쟁력있는 실시간 성능을 달성합니다.",2024.04.30,Longlong Jing&&Ruichi Yu&&Xu Chen&&Zhengli Zhao&&Shiwei Sheng&&Colin Graber&&Qi Chen&&Qinru Li&&Shangxuan Wu&&Han Deng&&Sangjin Lee&&Chris Sweeney&&Qiurui He&&Wei-Chih Hung&&Tong He&&Xingyi Zhou&&Farshid Moussavi&&Zijian Guo&&Yin Zhou&&Mingxing Tan&&Weilong Yang&&Congcong Li,arxiv,https://arxiv.org/abs/2405.00236
Spectrally Pruned Gaussian Fields with Neural Compensation,"최근 3D 가우시안 스플릿은 새로운 3D 표현으로서 빠른 렌더링 속도와 높은 렌더링 품질에 주목을 받았다.그러나 이것은 높은 메모리 소비와 함께 제공됩니다. 예를 들어, 잘 훈련 된 가우스 필드는 3 백만 개의 가우스 프리미티브와 700MB 이상의 메모리를 활용할 수 있습니다.우리는이 높은 메모리 발자국을 프리미티브 간의 관계에 대한 고려 부족으로 인정합니다.이 논문에서는 스펙트럼 가지 치기 및 신경 보상을 가진 Sundae라는 메모리 효율적인 가우스 필드를 제안합니다.한편으로, 우리는 가우시안 프리미티브 세트에 대한 그래프를 구성하여 관계를 모델링하고 원하는 신호를 보존하면서 프리미티브를 정리하기 위해 스펙트럼 다운 샘플링 모듈을 설계합니다.반면, 가지 치기 가우시안의 품질 손실을 보상하기 위해, 우리는 가벼운 신경망 헤드를 이용하여 플랫 된 특징을 혼합하여 품질 손실을 효과적으로 보완하면서 프리미티브의 원시적 가중치 사이의 관계를 포착합니다.우리는 광범위한 결과로 Sundae의 성능을 보여줍니다.예를 들어, Sundae는 104MB 메모리를 사용하여 145fps에서 26.80 PSNR을 달성 할 수 있으며 Vanilla Gaussian Splatting 알고리즘은 MIP-Nerf360 데이터 세트에서 523MB 메모리를 사용하여 160fps에서 25.60 PSNR을 달성 할 수 있습니다.코드는 HTTPS URL에서 공개적으로 제공됩니다.",2024.05.01,Runyi Yang&&Zhenxin Zhu&&Zhou Jiang&&Baijun Ye&&Xiaoxue Chen&&Yifei Zhang&&Yuantao Chen&&Jian Zhao&&Hao Zhao,arxiv,https://arxiv.org/abs/2405.00676
Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3,"이 연구는 최신 대형 언어 모델 LLAMA-3에 중점을 둔 대상 모델 편집 분석을 제시합니다.우리는 정확한 층 개입을 위해 설계된 인기있는 모델 편집 기술 (Rome, Memit 및 Emmet)의 효능을 탐구합니다.우리는 순차적 편집, 배치 편집 및 순차적 배치 편집이라고하는 세 가지 전략에 걸쳐 최대 4096 편집을 포함하는 평가를 통해 대상 편집을위한 가장 효과적인 계층을 식별합니다.우리의 연구 결과에 따르면 배치 크기 편집이 증가하면 동일한 수의 편집을 위해 소규모 편집 배치를 순차적으로 사용하는 것보다 모델 성능이 더 크게 저하 될 수 있습니다.이를 통해 순차적 모델 편집은 모델 편집 방법을 스케일링하는 데 중요한 구성 요소이며 향후 연구는 배치와 순차 편집을 모두 결합한 방법에 중점을 두어야한다고 주장합니다.이 관찰은 더 큰 편집 배치 크기로 향하는 현재 모델 편집 방법의 잠재적 제한을 시사하며, 배치 크기 및 모델 편집 성능을 최적화하는 데 대한 향후 조사 방법을 포장하기를 희망합니다.",2024.05.01,Junsang Yoon&&Akshat Gupta&&Gopala Anumanchipalli,arxiv,https://arxiv.org/abs/2405.00664
Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge,"대형 언어 모델 (LLMS)은 자동 요정 디코딩 요구 사항과 대부분의 현대 GPU의 설계 사이의 불일치로 효율성이 낮습니다.구체적으로, 계산을 위해 제한된 메모리 대역폭을 통해 수십억 ~ 수십억의 매개 변수를 GPU 캐시에로드해야하지만 실제로 작은 토큰 만 계산됩니다.결과적으로 GPU는 대부분의 시간을 계산 대신 메모리 전송에 소비합니다.최근에, 투기 디코딩 알고리즘의 한 유형 인 병렬 디코딩이 점점 인기를 얻고 있으며 세대의 인상적인 효율성 향상을 보여주었습니다.대형 모델에 추가 디코딩 헤드를 도입하여 여러 후속 토큰을 동시에 예측하고 단일 디코딩 단계에서 이러한 후보 연속을 확인할 수 있습니다.그러나,이 접근법은 사전 훈련 동안 사용 된 다음 토큰 예측의 훈련 목표와 비교하여 후보 토큰의 적중률이 낮습니다.이 논문에서는 순차적 지식을 병렬 디코딩 프로세스에 통합하는 새로운 투기 디코딩 알고리즘 인 Clover를 제안합니다.이러한 향상은 투기자의 적중률을 향상시켜 전체 효율성을 향상시킵니다.Clover는 회귀 적 연결을 통해 사전 지정된 토큰으로부터 순차적 지식을 전달 한 다음, 이러한 추측 된 토큰을 통합하기 위해주의 디코더를 사용합니다.또한, Clover는 숨겨진 상태를 수정하여 다음 토큰 예측보다는 투기 생성의 목적에 더 잘 맞도록 강화 블록을 통합합니다.실험 결과는 Clover가 기준선보다 Baichuan Small에서 최대 91%, Baichuan-Large에서 각각 146%를 능가하며, 이전에 최고 성능이있는 방법 Medusa의 성능을 Baichuan에서 최대 37% 초과합니다.Baichuan-Large에서 각각 작고 57%.",2024.05.01,Bin Xiao&&Chunan Shi&&Xiaonan Nie&&Fan Yang&&Xiangwei Deng&&Lei Su&&Weipeng Chen&&Bin Cui,arxiv,https://arxiv.org/abs/2405.00263
Self-Play Preference Optimization for Language Model Alignment,"인간 피드백 (RLHF)의 전통적인 강화 학습 (RLHF)은 Bradley-Terry 모델과 같은 파라 메트릭 모델에 의존하는 접근 방식이 인간의 선호도에서 내재성과 비합리성을 포착하는 데 부족합니다.최근의 발전에 따르면 선호도 확률로 직접 협력하면 인간 선호도를보다 정확하게 반영하여보다 유연하고 정확한 언어 모델 정렬을 가능하게합니다.이 논문에서는 언어 모델 정렬에 대한 자체 플레이 기반 방법을 제안하는데, 이는 문제를 내쉬 평형 정책을 식별하는 것을 목표로하는 상수 -SUM 2 플레이어 게임으로 취급합니다.\ textit {selfplay preference impation} (SPPO)이라고 불리는 우리의 접근 방식은 반복 정책 업데이트를 통해 내쉬 평형과 비슷하며 이론적 수렴 보증을 누립니다.우리의 방법은 선택된 응답의 로그 불법을 효과적으로 증가시키고 거부 된 응답의 로그 불법을 감소시킬 수 있으며, 이는 직접 환경 설정 (DPO) 및 IDO (Identity Preference Optimization)와 같은 대칭 쌍별 손실에 의해 사소하게 달성 될 수없는 거부 된 응답의 로그-활성화를 감소시킬 수 있습니다.우리의 실험에서, Ultrafeedback 데이터 세트의 60k 프롬프트 (응답없이) 만 사용하고 즉각적인 증강없이 미리 훈련 된 선호도 모델 PairRM을 0.4B 매개 변수로 활용하여 SPPO는 미세 조정 mistral-7b-에서 모델을 얻을 수 있습니다.Alpacaeval 2.0의 GPT-4 터보에 대해 최첨단 길이 제어 승리 28.53%의 최첨단 V0.2.또한 MT- 벤치의 (반복적) DPO 및 IPO보다 성능이 뛰어납니다.특히, SPPO의 강력한 성능은 GPT-4 또는 기타 강력한 언어 모델의 추가 외부 감독 (예 : 응답, 선호도 등)없이 달성됩니다.",2024.05.01,Yue Wu&&Zhiqing Sun&&Huizhuo Yuan&&Kaixuan Ji&&Yiming Yang&&Quanquan Gu,arxiv,https://arxiv.org/abs/2405.00675
A Careful Examination of Large Language Model Performance on Grade School Arithmetic,"대형 언어 모델 (LLM)은 수학적 추론을위한 많은 벤치 마크에서 인상적인 성공을 거두었습니다.그러나이 성능 중 일부는 실제로 데이터 세트 오염을 반영한다는 우려가 커지고 있으며, 여기서 벤치 마크 질문과 매우 유사한 데이터는 진정한 추론 능력 대신 교육 데이터로 유출됩니다.이 주장을 엄격하게 조사하기 위해, 우리는 초등학교 수학 1000 (GSM1K)을 의뢰합니다.GSM1K는 기본 수학적 추론을 측정하기위한 금 표준 인 기존 GSM8K 벤치 마크의 스타일과 복잡성을 반영하도록 설계되었습니다.우리는 인간 해결 속도, 솔루션의 단계 수, 답변 규모 등과 같은 중요한 메트릭에서 두 벤치 마크가 비교할 수 있도록합니다.GSM1K에서 주요 개방 및 폐쇄 소스 LLM을 평가할 때, 우리는 거의 모든 모델 크기에 걸쳐 체계적인 과적합의 증거를 보여주는 여러 모델 (예 : PHI 및 Mistral)과 함께 최대 13%의 정확도 낙하를 관찰합니다.동시에, 많은 모델, 특히 프론티어에있는 모델 (예 : gemini/gpt/claude)은 과적으로 최소한의 징후를 보입니다.추가 분석은 GSM8K로부터 예제를 생성 할 수있는 모델의 확률과 GSM8K와 GSM1K 사이의 성능 간격 사이의 긍정적 인 관계 (Spearman의 R^2 = 0.32)를 시사합니다. 이는 많은 모델이 부분적으로 GSM8K를 가질 수 있음을 시사합니다.",2024.05.01,Hugh Zhang&&Jeff Da&&Dean Lee&&Vaughn Robinson&&Catherine Wu&&Will Song&&Tiffany Zhao&&Pranav Raja&&Dylan Slack&&Qin Lyu&&Sean Hendryx&&Russell Kaplan&&Michele Lunati&&Summer Yue,arxiv,https://arxiv.org/abs/2405.00332
Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models,"GPT-4와 같은 독점적 인 LMS는 종종 다양한 LMS의 응답 품질을 평가하기 위해 사용됩니다.그러나 투명성, 통제 성 및 경제성을 포함한 우려는 평가에 특화된 오픈 소스 LM의 개발에 강력하게 동기를 부여합니다.반면에 기존의 오픈 평가자 LMS는 중요한 단점을 나타냅니다. 1) 인간이 지정된 것과 크게 분기되는 점수를 발행하며 2) 직접 평가와 쌍별 순위를 모두 수행 할 수있는 유연성이 부족합니다..또한, 그들은 도움과 무해함과 같은 일반적인 속성에 중점을 둔 사용자 정의 평가 기준에 따라 평가할 수있는 능력을 가지고 있지 않습니다.이러한 문제를 해결하기 위해, 우리는 인간과 GPT-4 판단을 밀접하게 반영하는 전임자보다 더 강력한 평가자 LM 인 Prometheus 2를 소개합니다.또한 사용자 정의 평가 기준으로 그룹화 된 직접 평가 및 쌍별 순위 형식을 모두 처리 할 수 있습니다.4 개의 직접 평가 벤치 마크와 4 개의 쌍별 순위 벤치 마크에서 Prometheus 2는 테스트 된 모든 공개 평가자 LM 중 가장 높은 상관 관계 및 인간 및 독점적 LM 판사와의 계약을 기록합니다.우리의 모델, 코드 및 데이터는 모두 HTTPS URL에서 공개적으로 제공됩니다.",2024.05.02,Seungone Kim&&Juyoung Suk&&Shayne Longpre&&Bill Yuchen Lin&&Jamin Shin&&Sean Welleck&&Graham Neubig&&Moontae Lee&&Kyungjae Lee&&Minjoon Seo,arxiv,https://arxiv.org/abs/2405.01535
NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment,"대형 언어 모델 (LLM)을 인간의 가치 및 선호도와 정렬하는 것은 도움이되고 안전하게 만드는 데 필수적입니다.그러나 특히 수십만 또는 수억 개의 매개 변수를 포함하는 가장 크고 가장 유능한 LLM의 경우, 정렬을 수행하기위한 효율적인 도구를 구축하는 것은 어려울 수 있습니다.우리는 교육을 위해 수백 개의 GPU를 사용하는 것까지 효율적으로 확장 할 수있는 모델 정렬을위한 툴킷 인 Nemo-Aligner를 만듭니다.Nemo-Aligner는 인간 피드백 (RLHF), DPO (Direct Preverence Optimization), SteerLM 및 자체 플레이 미세 조정 (SPIN)과 같은 모델 정렬의 주요 패러다임에 대한 최적화되고 확장 가능한 구현을 제공합니다.또한, 당사의 툴킷은 PEFT (Parameter Efficial Fine Tuning) 설정에서 대부분의 정렬 기술을 실행하는 것을 지원합니다.Nemo-Aligner는 확장 성을 위해 설계되어 최소한의 노력으로 다른 정렬 기술을 지원할 수 있습니다.Apache 2.0 라이센스로 오픈 소스이며 HTTPS URL에서 커뮤니티 기여를 초대합니다.",2024.05.02,Gerald Shen&&Zhilin Wang&&Olivier Delalleau&&Jiaqi Zeng&&Yi Dong&&Daniel Egert&&Shengyang Sun&&Jimmy Zhang&&Sahil Jain&&Ali Taghibakhshi&&Markel Sanz Ausin&&Ashwath Aithal&&Oleksii Kuchaiev,arxiv,https://arxiv.org/abs/2405.01481
WildChat: 1M ChatGPT Interaction Logs in the Wild,"GPT-4 및 Chatgpt와 같은 챗봇은 현재 수백만 명의 사용자에게 서비스를 제공하고 있습니다.광범위한 사용에도 불구하고 실제로 사용자 인구가 이러한 도구를 사용하는 방법을 보여주는 공개 데이터 세트가 부족합니다.이러한 격차를 해소하기 위해 우리는 온라인 사용자를위한 ChatGpt에 대한 무료 액세스를 제공하여 긍정적이고 합의 된 옵트 인을 익명으로 채팅 전 사자를 수집하고 요청 헤더를 요청했습니다.이것으로부터, 우리는 1 백만 명의 사용자 chatgpt 대화의 코퍼스 인 Wildchat을 컴파일했으며, 이는 250 만 개가 넘는 상호 작용으로 구성됩니다.우리는 WildChat을 다른 인기있는 사용자 chatbot 상호 작용 데이터 세트와 비교하고 데이터 세트가 가장 다양한 사용자 프롬프트를 제공하고, 가장 많은 수의 언어를 포함하며, 연구자들이 연구 할 수있는 가장 풍부한 잠재적 독성 사용 사례를 제시합니다.타임 스탬프 채팅 성적표 외에도 요청 헤더와 함께 주, 국가 및 해시 IP 주소를 포함한 인구 통계 데이터로 데이터 세트를 풍부하게합니다.이 증강은 다양한 지리적 지역과 시간적 차원에서 사용자 행동에 대한 자세한 분석을 가능하게합니다.마지막으로, 광범위한 사용 사례를 캡처하기 때문에 미세 조정 명령어를 따르는 모델에서 데이터 세트의 잠재적 유용성을 보여줍니다.Wildchat은 https urlunder ai2 충격 라이센스에 출시됩니다.",2024.05.02,Wenting Zhao&&Xiang Ren&&Jack Hessel&&Claire Cardie&&Yejin Choi&&Yuntian Deng,arxiv,https://arxiv.org/abs/2405.01470
StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation,"최근의 확산 기반 생성 모델의 경우, 일련의 생성 된 이미지, 특히 대상 및 복잡한 세부 사항을 포함하는 일련의 이미지에서 일관된 컨텐츠를 유지하는 것은 중요한 도전을 제시합니다.이 논문에서, 우리는 일관된 자체 변환이라고 불리는 새로운 자체 변환 계산 방법을 제안하여 생성 된 이미지와 널리 알려진 확산 기반 텍스트-이미지 모델 사이의 일관성을 제로 샷 방식으로 증가시킵니다.우리의 방법을 장거리 비디오 생성으로 확장하기 위해 Semantic Motion Predictor라는 새로운 시맨틱 스페이스 시간 모션 예측 모듈을 더 소개합니다.시맨틱 공간에서 제공된 두 이미지 사이의 모션 조건을 추정하도록 훈련되었습니다.이 모듈은 생성 된 일련의 이미지를 부드러운 전환과 일관된 공간을 기반으로 한 모듈보다 훨씬 안정적 인 일관된 주제를 비디오로 변환합니다.이 두 가지 새로운 구성 요소를 병합함으로써 StoryDiffusion이라고 불리는 우리의 프레임 워크는 다양한 내용을 포함하는 일관된 이미지 또는 비디오로 텍스트 기반 스토리를 설명 할 수 있습니다.제안 된 StoryDiffusion은 이미지와 비디오의 프리젠 테이션을 통해 시각적 스토리 생성의 선구적인 탐구를 포함합니다.우리의 코드는 HTTPS URL에서 공개적으로 제공됩니다.",2024.05.02,Yupeng Zhou&&Daquan Zhou&&Ming-Ming Cheng&&Jiashi Feng&&Qibin Hou,arxiv,https://arxiv.org/abs/2405.01434
LLM-AD: Large Language Model based Audio Description System,"오디오 설명 (AD)의 개발은 비디오 컨텐츠에보다 액세스 할 수 있고 포괄적 인 것을 만드는 데 중추적 인 단계였습니다.전통적으로 광고 생산은 상당한 양의 숙련 된 노동을 요구했지만 기존의 자동화 된 접근 방식은 여전히 멀티 모달 입력을 통합하고 캡션 스타일에서 광고 스타일로 출력을 조정하기위한 광범위한 교육이 필요합니다.이 논문에서는 GPT-4V (ISION)의 강력한 멀티 모드 및 명령어를 따르는 용량을 활용하는 자동 광고 생성 파이프 라인을 소개합니다.특히, 우리의 방법론은 쉽게 이용 가능한 구성 요소를 사용하여 추가 교육이 필요하지 않습니다.추적 기반 문자 인식 모듈이 제공하는 자연 언어 광고 제작 표준을 준수 할뿐만 아니라 프레임 전체에 걸쳐 상황에 따라 일관된 문자 정보를 유지하는 광고를 생성합니다.MAD 데이터 세트에 대한 철저한 분석에 따르면 우리의 접근 방식은 20.5의 사이다 점수로 입증 된 자동 광고 제작에서 학습 기반 방법과 동등한 성능을 달성합니다.",2024.05.02,Peng Chu&&Jiang Wang&&Andre Abrantes,arxiv,https://arxiv.org/abs/2405.00983
FLAME: Factuality-Aware Alignment for Large Language Models,"정렬은 사전 훈련 된 대형 언어 모델 (LLMS)을 미세 조정하여 자연어 지침을 따르고 도움이되는 AI 보조원 역할을하는 표준 절차입니다.그러나 우리는 기존의 정렬 프로세스가 LLM의 사실 정확도를 향상시키지 못하고 종종 더 많은 허위 사실 (즉, 환각)을 생성하는 것으로 관찰했습니다.이 논문에서는 먼저 정렬 단계에서 환각으로 이어지는 요인을 먼저 식별함으로써 LLM 정렬 프로세스를보다 사실을보다 사실보다 더 사실로 만드는 방법을 연구합니다. \ 감독 미세 조정 (SFT) 및 강화 학습 (RL).특히, 우리는 새로운 지식이나 익숙하지 않은 텍스트에 대해 LLM을 훈련시키는 것이 환각을 장려 할 수 있음을 발견했습니다.이것은 LLM에 소설을 할 수있는 인간 라벨이 붙은 데이터를 훈련시키기 때문에 SFT는 사실을 덜 사실입니다.또한 표준 RL에 사용 된 보상 기능은 환각을 장려 할 수 있습니다. 환각을 장려 할 수 있습니다. LLM은 다양한 지시 사항에 대해보다 유용한 응답을 제공하도록 LLM을 안내하며 종종 더 길고 자세한 응답을 선호합니다.이러한 관찰에 기초하여, 우리는 직접 선호도 최적화를 통한 사실상 인식 SFT 및 사실성 인식 RL로 구성된 사실-인식 정렬을 제안합니다.실험에 따르면 우리의 제안 된 사실 인식 조정은 LLM이 교육을 따르는 기능을 유지하면서보다 사실적인 응답을 출력하도록 안내합니다.",2024.05.02,Sheng-Chieh Lin&&Luyu Gao&&Barlas Oguz&&Wenhan Xiong&&Jimmy Lin&&Wen-tau Yih&&Xilun Chen,arxiv,https://arxiv.org/abs/2405.01525
Customizing Text-to-Image Models with a Single Image Pair,"예술 재 해석은 참조 작업의 변형을 만드는 연습으로 독특한 예술적 스타일을 보여주는 쌍을 이루는 예술 작품을 만듭니다.우리는 그러한 이미지 쌍을 사용하여 시연 된 문체 차이를 캡처하기 위해 생성 모델을 사용자 정의하는 데 사용될 수 있는지 묻습니다.우리는 단일 이미지 쌍의 문체 차이를 배우고 획득 된 스타일을 생성 프로세스에 적용하는 새로운 사용자 정의 방법 인 페어 커스터마이제이션을 제안합니다.이미지 모음에서 단일 개념을 모방하는 것을 배우는 기존 방법과 달리, 우리의 방법은 짝을 이루는 이미지 사이의 문체 차이를 포착합니다.이를 통해 예제의 특정 이미지 컨텐츠에 너무 적합하지 않고 문체 변화를 적용 할 수 있습니다.이 새로운 작업을 해결하기 위해 스타일과 컨텐츠를 명시 적으로 구별되는 LORA 웨이트 스페이스로 분리하는 공동 최적화 방법을 사용합니다.우리는 이러한 스타일과 컨텐츠 가중치를 최적화하여 스타일과 컨텐츠 이미지를 재현하면서 직교성을 장려합니다.추론하는 동안, 우리는 학습 된 가중치를 기반으로 새로운 스타일 지침을 통해 확산 과정을 수정합니다.정 성적 및 정량적 실험은 우리의 방법이 이미지 컨텐츠에 과적으로 적합하지 않고 단일 이미지 쌍과의 스타일 차이를 모델링 할 수있는 잠재력을 강조하면서 스타일을 효과적으로 학습 할 수 있음을 보여줍니다.",2024.05.02,Maxwell Jones&&Sheng-Yu Wang&&Nupur Kumari&&David Bau&&Jun-Yan Zhu,arxiv,https://arxiv.org/abs/2405.01536
